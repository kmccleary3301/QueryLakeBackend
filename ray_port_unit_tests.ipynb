{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Functions to Test\n",
    "\n",
    "### User Auth\n",
    "* `add_user`\n",
    "* `login`\n",
    "* `get_available_models`\n",
    "* `set_user_openai_api_key`\n",
    "* `set_organization_openai_id`\n",
    "* `get_openai_api_key`\n",
    "\n",
    "### Collections\n",
    "* `fetch_document_collections_belonging_to`\n",
    "* `create_document_collection`\n",
    "* `fetch_all_collections`\n",
    "* `fetch_collection`\n",
    "* `modify_document_collection`\n",
    "\n",
    "### Documents\n",
    "* `upload_document`\n",
    "* `delete_document`\n",
    "* `get_document_secure`\n",
    "* `query_vector_db`\n",
    "* `craft_document_access_token`\n",
    "* `fetch_document`\n",
    "\n",
    "### Organizations\n",
    "* `create_organization`\n",
    "* `invite_user_to_organization`\n",
    "* `resolve_organization_invitation`\n",
    "* `fetch_memberships`\n",
    "* `fetch_memberships_of_organization`\n",
    "\n",
    "### Web Search\n",
    "* `set_user_serp_key`\n",
    "* `set_organization_serp_key`\n",
    "* `get_serp_key`\n",
    "* `search_google`\n",
    "* `perform_search_query`\n",
    "\n",
    "### Toolchains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# Generate a random UUID\n",
    "\n",
    "\n",
    "USERNAME_1 = str(uuid.uuid4())[:32]\n",
    "USERNAME_2 = str(uuid.uuid4())[:32]\n",
    "\n",
    "PASSWORD_1 = str(uuid.uuid4())[:32]\n",
    "PASSWORD_2 = str(uuid.uuid4())[:32]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `add_user`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"account_made\": true,\n",
      "        \"password_single_hash\": \"1a084fdc5d455042a3bda56497d58d19b7b94c08eb491f8f0545148085400ea5\",\n",
      "        \"memberships\": [],\n",
      "        \"admin\": false,\n",
      "        \"available_models\": {\n",
      "            \"default_model\": \"Mistral 7B Instruct\",\n",
      "            \"local_models\": [\n",
      "                {\n",
      "                    \"name\": \"Mistral 7B Instruct\",\n",
      "                    \"modelcard\": \"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1\",\n",
      "                    \"system_path\": \"/home/kyle_m/QueryLake_Development/llm_models/staging_merges/Mistral-Instruct-8BPW\",\n",
      "                    \"default_parameters\": {\n",
      "                        \"stream\": true,\n",
      "                        \"verbose\": false,\n",
      "                        \"temperature\": 0.5,\n",
      "                        \"top_k\": 0.0,\n",
      "                        \"top_p\": 0.9,\n",
      "                        \"max_tokens\": 1000,\n",
      "                        \"repetition_penalty\": 1.15,\n",
      "                        \"stop\": [\n",
      "                            \"<|im_end|>\"\n",
      "                        ]\n",
      "                    },\n",
      "                    \"max_model_len\": 16384,\n",
      "                    \"padding\": {\n",
      "                        \"system_instruction_wrap\": \"<|im_start|>system\\n{system_instruction}<|im_end|>\\n\",\n",
      "                        \"context_wrap\": \"<<context>>{context}<</context>>\",\n",
      "                        \"question_wrap\": \"<|im_start|>user\\n{question}<|im_end|>\\n<|im_start|>assistant\\n\",\n",
      "                        \"response_wrap\": \"{response}<|im_end|>\\n\"\n",
      "                    },\n",
      "                    \"default_system_instructions\": \"You are a general answering assistant that can comply with any request.\\n\\nYou always answer with markdown formatting. You will be penalized if you do not answer with markdown when it would be possible.\\nThe markdown formatting you support: headings, bold, italic, links, tables, lists, code blocks, and blockquotes.\\nYou do not support images and never include images. You will be penalized if you render images.\\n\\nAlways use markdown code blocks for code, and always use MathJax with LaTeX formatting for pure math expressions.\\nFor example code would look like:\\n```python\\n*Python code here\\n```\\nAnd math expressions would look like:\\n$$P(y|x) = \\\\frac{{P(x|y) \\\\cdot P(y)}}{{P(x)}}$$\"\n",
      "                }\n",
      "            ],\n",
      "            \"external_models\": {\n",
      "                \"openai\": [\n",
      "                    {\n",
      "                        \"name\": \"GPT-4 Turbo\",\n",
      "                        \"id\": \"gpt-4-1106-preview\",\n",
      "                        \"context\": 128000,\n",
      "                        \"modelcard\": \"https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"GPT-3.5 Turbo\",\n",
      "                        \"id\": \"gpt-3.5-turbo-1106\",\n",
      "                        \"context\": 16384,\n",
      "                        \"modelcard\": \"https://platform.openai.com/docs/models/gpt-3-5\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"account_made\": true,\n",
      "        \"password_single_hash\": \"c88853f28c57039f05ac3344dfab8ebca5bebf6e5c9774245ae517f3da074ed7\",\n",
      "        \"memberships\": [],\n",
      "        \"admin\": false,\n",
      "        \"available_models\": {\n",
      "            \"default_model\": \"Mistral 7B Instruct\",\n",
      "            \"local_models\": [\n",
      "                {\n",
      "                    \"name\": \"Mistral 7B Instruct\",\n",
      "                    \"modelcard\": \"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1\",\n",
      "                    \"system_path\": \"/home/kyle_m/QueryLake_Development/llm_models/staging_merges/Mistral-Instruct-8BPW\",\n",
      "                    \"default_parameters\": {\n",
      "                        \"stream\": true,\n",
      "                        \"verbose\": false,\n",
      "                        \"temperature\": 0.5,\n",
      "                        \"top_k\": 0.0,\n",
      "                        \"top_p\": 0.9,\n",
      "                        \"max_tokens\": 1000,\n",
      "                        \"repetition_penalty\": 1.15,\n",
      "                        \"stop\": [\n",
      "                            \"<|im_end|>\"\n",
      "                        ]\n",
      "                    },\n",
      "                    \"max_model_len\": 16384,\n",
      "                    \"padding\": {\n",
      "                        \"system_instruction_wrap\": \"<|im_start|>system\\n{system_instruction}<|im_end|>\\n\",\n",
      "                        \"context_wrap\": \"<<context>>{context}<</context>>\",\n",
      "                        \"question_wrap\": \"<|im_start|>user\\n{question}<|im_end|>\\n<|im_start|>assistant\\n\",\n",
      "                        \"response_wrap\": \"{response}<|im_end|>\\n\"\n",
      "                    },\n",
      "                    \"default_system_instructions\": \"You are a general answering assistant that can comply with any request.\\n\\nYou always answer with markdown formatting. You will be penalized if you do not answer with markdown when it would be possible.\\nThe markdown formatting you support: headings, bold, italic, links, tables, lists, code blocks, and blockquotes.\\nYou do not support images and never include images. You will be penalized if you render images.\\n\\nAlways use markdown code blocks for code, and always use MathJax with LaTeX formatting for pure math expressions.\\nFor example code would look like:\\n```python\\n*Python code here\\n```\\nAnd math expressions would look like:\\n$$P(y|x) = \\\\frac{{P(x|y) \\\\cdot P(y)}}{{P(x)}}$$\"\n",
      "                }\n",
      "            ],\n",
      "            \"external_models\": {\n",
      "                \"openai\": [\n",
      "                    {\n",
      "                        \"name\": \"GPT-4 Turbo\",\n",
      "                        \"id\": \"gpt-4-1106-preview\",\n",
      "                        \"context\": 128000,\n",
      "                        \"modelcard\": \"https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"GPT-3.5 Turbo\",\n",
      "                        \"id\": \"gpt-3.5-turbo-1106\",\n",
      "                        \"context\": 16384,\n",
      "                        \"modelcard\": \"https://platform.openai.com/docs/models/gpt-3-5\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "\n",
    "add_user_input = {\n",
    "    \"username\": USERNAME_1,\n",
    "    \"password\": PASSWORD_1,\n",
    "}\n",
    "\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/add_user\", json=add_user_input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]\n",
    "\n",
    "add_user_input = {\n",
    "    \"username\": USERNAME_2,\n",
    "    \"password\": PASSWORD_2,\n",
    "}\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/add_user\", json=add_user_input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `login`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"password_single_hash\": \"1a084fdc5d455042a3bda56497d58d19b7b94c08eb491f8f0545148085400ea5\",\n",
      "        \"memberships\": [],\n",
      "        \"admin\": false,\n",
      "        \"available_models\": {\n",
      "            \"default_model\": \"Mistral 7B Instruct\",\n",
      "            \"local_models\": [\n",
      "                {\n",
      "                    \"name\": \"Mistral 7B Instruct\",\n",
      "                    \"modelcard\": \"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1\",\n",
      "                    \"system_path\": \"/home/kyle_m/QueryLake_Development/llm_models/staging_merges/Mistral-Instruct-8BPW\",\n",
      "                    \"default_parameters\": {\n",
      "                        \"stream\": true,\n",
      "                        \"verbose\": false,\n",
      "                        \"temperature\": 0.5,\n",
      "                        \"top_k\": 0.0,\n",
      "                        \"top_p\": 0.9,\n",
      "                        \"max_tokens\": 1000,\n",
      "                        \"repetition_penalty\": 1.15,\n",
      "                        \"stop\": [\n",
      "                            \"<|im_end|>\"\n",
      "                        ]\n",
      "                    },\n",
      "                    \"max_model_len\": 16384,\n",
      "                    \"padding\": {\n",
      "                        \"system_instruction_wrap\": \"<|im_start|>system\\n{system_instruction}<|im_end|>\\n\",\n",
      "                        \"context_wrap\": \"<<context>>{context}<</context>>\",\n",
      "                        \"question_wrap\": \"<|im_start|>user\\n{question}<|im_end|>\\n<|im_start|>assistant\\n\",\n",
      "                        \"response_wrap\": \"{response}<|im_end|>\\n\"\n",
      "                    },\n",
      "                    \"default_system_instructions\": \"You are a general answering assistant that can comply with any request.\\n\\nYou always answer with markdown formatting. You will be penalized if you do not answer with markdown when it would be possible.\\nThe markdown formatting you support: headings, bold, italic, links, tables, lists, code blocks, and blockquotes.\\nYou do not support images and never include images. You will be penalized if you render images.\\n\\nAlways use markdown code blocks for code, and always use MathJax with LaTeX formatting for pure math expressions.\\nFor example code would look like:\\n```python\\n*Python code here\\n```\\nAnd math expressions would look like:\\n$$P(y|x) = \\\\frac{{P(x|y) \\\\cdot P(y)}}{{P(x)}}$$\"\n",
      "                }\n",
      "            ],\n",
      "            \"external_models\": {\n",
      "                \"openai\": [\n",
      "                    {\n",
      "                        \"name\": \"GPT-4 Turbo\",\n",
      "                        \"id\": \"gpt-4-1106-preview\",\n",
      "                        \"context\": 128000,\n",
      "                        \"modelcard\": \"https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"GPT-3.5 Turbo\",\n",
      "                        \"id\": \"gpt-3.5-turbo-1106\",\n",
      "                        \"context\": 16384,\n",
      "                        \"modelcard\": \"https://platform.openai.com/docs/models/gpt-3-5\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"password_single_hash\": \"c88853f28c57039f05ac3344dfab8ebca5bebf6e5c9774245ae517f3da074ed7\",\n",
      "        \"memberships\": [],\n",
      "        \"admin\": false,\n",
      "        \"available_models\": {\n",
      "            \"default_model\": \"Mistral 7B Instruct\",\n",
      "            \"local_models\": [\n",
      "                {\n",
      "                    \"name\": \"Mistral 7B Instruct\",\n",
      "                    \"modelcard\": \"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1\",\n",
      "                    \"system_path\": \"/home/kyle_m/QueryLake_Development/llm_models/staging_merges/Mistral-Instruct-8BPW\",\n",
      "                    \"default_parameters\": {\n",
      "                        \"stream\": true,\n",
      "                        \"verbose\": false,\n",
      "                        \"temperature\": 0.5,\n",
      "                        \"top_k\": 0.0,\n",
      "                        \"top_p\": 0.9,\n",
      "                        \"max_tokens\": 1000,\n",
      "                        \"repetition_penalty\": 1.15,\n",
      "                        \"stop\": [\n",
      "                            \"<|im_end|>\"\n",
      "                        ]\n",
      "                    },\n",
      "                    \"max_model_len\": 16384,\n",
      "                    \"padding\": {\n",
      "                        \"system_instruction_wrap\": \"<|im_start|>system\\n{system_instruction}<|im_end|>\\n\",\n",
      "                        \"context_wrap\": \"<<context>>{context}<</context>>\",\n",
      "                        \"question_wrap\": \"<|im_start|>user\\n{question}<|im_end|>\\n<|im_start|>assistant\\n\",\n",
      "                        \"response_wrap\": \"{response}<|im_end|>\\n\"\n",
      "                    },\n",
      "                    \"default_system_instructions\": \"You are a general answering assistant that can comply with any request.\\n\\nYou always answer with markdown formatting. You will be penalized if you do not answer with markdown when it would be possible.\\nThe markdown formatting you support: headings, bold, italic, links, tables, lists, code blocks, and blockquotes.\\nYou do not support images and never include images. You will be penalized if you render images.\\n\\nAlways use markdown code blocks for code, and always use MathJax with LaTeX formatting for pure math expressions.\\nFor example code would look like:\\n```python\\n*Python code here\\n```\\nAnd math expressions would look like:\\n$$P(y|x) = \\\\frac{{P(x|y) \\\\cdot P(y)}}{{P(x)}}$$\"\n",
      "                }\n",
      "            ],\n",
      "            \"external_models\": {\n",
      "                \"openai\": [\n",
      "                    {\n",
      "                        \"name\": \"GPT-4 Turbo\",\n",
      "                        \"id\": \"gpt-4-1106-preview\",\n",
      "                        \"context\": 128000,\n",
      "                        \"modelcard\": \"https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"GPT-3.5 Turbo\",\n",
      "                        \"id\": \"gpt-3.5-turbo-1106\",\n",
      "                        \"context\": 16384,\n",
      "                        \"modelcard\": \"https://platform.openai.com/docs/models/gpt-3-5\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "\n",
    "add_user_input = {\n",
    "    \"username\": USERNAME_1,\n",
    "    \"password\": PASSWORD_1,\n",
    "}\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/login\", json=add_user_input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]\n",
    "\n",
    "USER_ARGS_1 = {\"username\": USERNAME_1, \"password_prehash\": result[\"result\"][\"password_single_hash\"]}\n",
    "USER_ARGS_1 = {\"auth\": USER_ARGS_1}\n",
    "\n",
    "\n",
    "add_user_input = {\n",
    "    \"username\": USERNAME_2,\n",
    "    \"password\": PASSWORD_2,\n",
    "}\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/login\", json=add_user_input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]\n",
    "\n",
    "USER_ARGS_2 = {\"username\": USERNAME_2, \"password_prehash\": result[\"result\"][\"password_single_hash\"]}\n",
    "USER_ARGS_2 = {\"auth\": USER_ARGS_2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `and_`\n",
    "this should fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": false,\n",
      "    \"note\": \"Function not available\",\n",
      "    \"trace\": \"Traceback (most recent call last):\\n  File \\\"/home/kyle_m/QueryLake_Development/QueryLakeBackend/./server_ray.py\\\", line 690, in api_general_call\\n    assert rest_of_path in api.remaining_independent_api_functions, \\\"Function not available\\\"\\nAssertionError: Function not available\\n\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "\n",
    "input = {\n",
    "    \"username\": \"test\",\n",
    "    \"password\": \"test\",\n",
    "}\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/and_\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert (\"success\" in result and result[\"success\"] == False), \"Test succeeded when it should have failed\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X `get_available_models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"available_models\": {\n",
      "            \"default_model\": \"Mistral 7B Instruct\",\n",
      "            \"local_models\": [\n",
      "                {\n",
      "                    \"name\": \"Mistral 7B Instruct\",\n",
      "                    \"modelcard\": \"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1\",\n",
      "                    \"system_path\": \"/home/kyle_m/QueryLake_Development/llm_models/staging_merges/Mistral-Instruct-8BPW\",\n",
      "                    \"default_parameters\": {\n",
      "                        \"stream\": true,\n",
      "                        \"verbose\": false,\n",
      "                        \"temperature\": 0.5,\n",
      "                        \"top_k\": 0.0,\n",
      "                        \"top_p\": 0.9,\n",
      "                        \"max_tokens\": 1000,\n",
      "                        \"repetition_penalty\": 1.15,\n",
      "                        \"stop\": [\n",
      "                            \"<|im_end|>\"\n",
      "                        ]\n",
      "                    },\n",
      "                    \"max_model_len\": 16384,\n",
      "                    \"padding\": {\n",
      "                        \"system_instruction_wrap\": \"<|im_start|>system\\n{system_instruction}<|im_end|>\\n\",\n",
      "                        \"context_wrap\": \"<<context>>{context}<</context>>\",\n",
      "                        \"question_wrap\": \"<|im_start|>user\\n{question}<|im_end|>\\n<|im_start|>assistant\\n\",\n",
      "                        \"response_wrap\": \"{response}<|im_end|>\\n\"\n",
      "                    },\n",
      "                    \"default_system_instructions\": \"You are a general answering assistant that can comply with any request.\\n\\nYou always answer with markdown formatting. You will be penalized if you do not answer with markdown when it would be possible.\\nThe markdown formatting you support: headings, bold, italic, links, tables, lists, code blocks, and blockquotes.\\nYou do not support images and never include images. You will be penalized if you render images.\\n\\nAlways use markdown code blocks for code, and always use MathJax with LaTeX formatting for pure math expressions.\\nFor example code would look like:\\n```python\\n*Python code here\\n```\\nAnd math expressions would look like:\\n$$P(y|x) = \\\\frac{{P(x|y) \\\\cdot P(y)}}{{P(x)}}$$\"\n",
      "                }\n",
      "            ],\n",
      "            \"external_models\": {\n",
      "                \"openai\": [\n",
      "                    {\n",
      "                        \"name\": \"GPT-4 Turbo\",\n",
      "                        \"id\": \"gpt-4-1106-preview\",\n",
      "                        \"context\": 128000,\n",
      "                        \"modelcard\": \"https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"GPT-3.5 Turbo\",\n",
      "                        \"id\": \"gpt-3.5-turbo-1106\",\n",
      "                        \"context\": 16384,\n",
      "                        \"modelcard\": \"https://platform.openai.com/docs/models/gpt-3-5\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/get_available_models\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `set_user_openai_api_key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update({\n",
    "    \"openai_api_key\": \"sk-11111111111111111111111\"\n",
    "})\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/set_user_openai_api_key\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `set_organization_openai_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": false,\n",
      "    \"note\": \"set_organization_openai_id() missing 2 required positional arguments: 'openai_organization_id' and 'organization_hash_id'\",\n",
      "    \"trace\": \"Traceback (most recent call last):\\n  File \\\"/home/kyle_m/QueryLake_Development/QueryLakeBackend/./server_ray.py\\\", line 706, in api_general_call\\n    args_get = function_actual(**true_args)\\nTypeError: set_organization_openai_id() missing 2 required positional arguments: 'openai_organization_id' and 'organization_hash_id'\\n\"\n",
      "}\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "set_organization_openai_id() missing 2 required positional arguments: 'openai_organization_id' and 'organization_hash_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[122], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m result \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(result, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m result \u001b[38;5;129;01mand\u001b[39;00m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m), result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnote\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mAssertionError\u001b[0m: set_organization_openai_id() missing 2 required positional arguments: 'openai_organization_id' and 'organization_hash_id'"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update({\n",
    "    \"openai_api_key\": \"org-1111111111111111111111111\"\n",
    "})\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/set_organization_openai_id\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `get_openai_api_key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"api_key\": \"sk-11111111111111111111111\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/get_openai_api_key\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `fetch_document_collections_belonging_to`\n",
    "* ✅ `user`\n",
    "* `organization`\n",
    "* `global`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"collections\": []\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/fetch_document_collections_belonging_to\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `create_document_collection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"hash_id\": \"35c97744abe8d5c98660a634789fd47e46e5e70afad3203f0db561e0c07414f3\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update({\n",
    "    \"name\": \"test_collection_1\"\n",
    "})\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/create_document_collection\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"trace\"]\n",
    "\n",
    "COLLECTION_ARGS = {\"hash_id\": result[\"result\"][\"hash_id\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `fetch_all_collections`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"collections\": {\n",
      "            \"global_collections\": [],\n",
      "            \"user_collections\": [\n",
      "                {\n",
      "                    \"name\": \"test_collection_1\",\n",
      "                    \"hash_id\": \"35c97744abe8d5c98660a634789fd47e46e5e70afad3203f0db561e0c07414f3\",\n",
      "                    \"document_count\": 0,\n",
      "                    \"type\": \"user\"\n",
      "                }\n",
      "            ],\n",
      "            \"organization_collections\": {}\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "response = requests.post(\"http://localhost:8000/api/fetch_all_collections\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `fetch_collection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"title\": \"test_collection_1\",\n",
      "        \"description\": \"\",\n",
      "        \"type\": \"user\",\n",
      "        \"owner\": \"personal\",\n",
      "        \"public\": false,\n",
      "        \"document_list\": []\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update({\n",
    "    \"collection_hash_id\": COLLECTION_ARGS[\"hash_id\"],\n",
    "})\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/fetch_collection\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `modify_document_collection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update({\n",
    "    \"collection_hash_id\": COLLECTION_ARGS[\"hash_id\"],\n",
    "    \"title\": \"test_collection_1_modified\",\n",
    "    \"description\": \"test description please ignore\"\n",
    "})\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/modify_document_collection\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `upload_document`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n",
      "true\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from urllib.parse import urlencode\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update({\n",
    "    \"collection_hash_id\": COLLECTION_ARGS[\"hash_id\"]\n",
    "})\n",
    "\n",
    "encoded_params = urlencode({\"parameters\": json.dumps(input)})\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    with open('/home/kyle_m/QueryLake_Development/ray_testing/test_files_for_upload/HNRS3035_08_22_2023_MLIntro.pdf', 'rb') as f:\n",
    "        # Define the files parameter for the POST request\n",
    "        files = {'file': f}\n",
    "        input_json = json.dumps(input)\n",
    "        response = requests.post(\"http://localhost:8000/upload_document?\"+encoded_params, files=files)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        result = response.json()\n",
    "        f.close()\n",
    "\n",
    "        print(json.dumps(result, indent=4))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get new doc_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"title\": \"test_collection_1_modified\",\n",
      "        \"description\": \"test description please ignore\",\n",
      "        \"type\": \"user\",\n",
      "        \"owner\": \"personal\",\n",
      "        \"public\": false,\n",
      "        \"document_list\": [\n",
      "            {\n",
      "                \"title\": \"text_classification_slides.pdf\",\n",
      "                \"hash_id\": \"d021b56b43dc72877d5538aef3e3a6a287df136404069c3147c54ef9604bbb07\"\n",
      "            },\n",
      "            {\n",
      "                \"title\": \"HNRS3035_08_22_2023_MLIntro.pdf\",\n",
      "                \"hash_id\": \"2b5b0b31adde2555d193105567a192844f51fe0f63abce62e83ceefed2a675a2\"\n",
      "            },\n",
      "            {\n",
      "                \"title\": \"HNRS3035_08_22_2023_MLIntro.pdf\",\n",
      "                \"hash_id\": \"2e045338c05ab32dc51077b5c4bc050da223393407a2ac06f4c7c08f0cfafe35\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "add_user_input = deepcopy(USER_ARGS_1)\n",
    "add_user_input.update({\n",
    "    \"collection_hash_id\": COLLECTION_ARGS[\"hash_id\"],\n",
    "})\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/fetch_collection\", json=add_user_input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]\n",
    "\n",
    "DOC_ARGS_1 = {\"hash_id\": result[\"result\"][\"document_list\"][0][\"hash_id\"]}\n",
    "DOC_ARGS_2 = {\"hash_id\": result[\"result\"][\"document_list\"][1][\"hash_id\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `delete_document`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update(DOC_ARGS_1)\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/delete_document\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `get_document_secure`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"auth\": {\n",
      "        \"username\": \"0e491eb3-7000-4fa4-8d19-3215c07e\",\n",
      "        \"password_prehash\": \"1a084fdc5d455042a3bda56497d58d19b7b94c08eb491f8f0545148085400ea5\"\n",
      "    },\n",
      "    \"hash_id\": \"2b5b0b31adde2555d193105567a192844f51fe0f63abce62e83ceefed2a675a2\"\n",
      "}\n",
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"password\": \"7bd129430f35900cbcd274d1f745839d00d2ac860b32ca70e11d77d289a012f4\",\n",
      "        \"database_path\": \"/home/kyle_m/QueryLake_Development/QueryLakeBackend/user_db/files/669bd2cd82a6e1c8550ce170625e676fb8f12b4cfa4490f1ec0525b37c0e2a5a.7z\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update(DOC_ARGS_2)\n",
    "\n",
    "print(json.dumps(input, indent=4))\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/get_document_secure\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `query_vector_db`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"result\": [\n",
      "            {\n",
      "                \"document_id\": \"2e045338c05ab32dc51077b5c4bc050da223393407a2ac06f4c7c08f0cfafe35\",\n",
      "                \"collection_type\": \"user\",\n",
      "                \"parent_collection_hash_id\": \"35c97744abe8d5c98660a634789fd47e46e5e70afad3203f0db561e0c07414f3\",\n",
      "                \"document_name\": \"HNRS3035_08_22_2023_MLIntro.pdf\",\n",
      "                \"document_integrity\": \"f9fedd6b309833c6a40d1a63cc03bc930586308af06504408e103540278c98a0\",\n",
      "                \"text\": \"uses artificial neural networks (ANNs)    \\n to perform    representation learning    on    \\n data.   \\n \\u2022   Representation learning, also called    \\n feature learning, is any method that    \\n learns to recognize salient    features   \\n without human input and quantify    \\n their    importance   .         \\n    Data   \\n Science   Artificial Intelligence   \\n Machine   \\n Learning   \\n Deep   \\n Learning     Expert   \\n Systems    What is It? Continued.\",\n",
      "                \"website_url\": null,\n",
      "                \"private\": false,\n",
      "                \"rerank_score\": 2030.7294921875\n",
      "            },\n",
      "            {\n",
      "                \"document_id\": \"2b5b0b31adde2555d193105567a192844f51fe0f63abce62e83ceefed2a675a2\",\n",
      "                \"collection_type\": \"user\",\n",
      "                \"parent_collection_hash_id\": \"35c97744abe8d5c98660a634789fd47e46e5e70afad3203f0db561e0c07414f3\",\n",
      "                \"document_name\": \"HNRS3035_08_22_2023_MLIntro.pdf\",\n",
      "                \"document_integrity\": \"f9fedd6b309833c6a40d1a63cc03bc930586308af06504408e103540278c98a0\",\n",
      "                \"text\": \"Machine   \\n Learning   \\n Deep   \\n Learning     Expert   \\n Systems    What is It? Continued.   \\n   image source: https://blog.kthais.com/representation-learning-the-core-of-machine-learning-e25fab0f3ac0            Artificial Neural Networks (ANNs)   \\n \\u2022   ANNs are composed of one or more layers of artificial functional    units   , also    \\n referred to as    neurons   .   \\n \\u2022   Each neuron integrates information from one or more other units, applies a    \\n nonlinear function to those inputs, and outputs the result.\",\n",
      "                \"website_url\": null,\n",
      "                \"private\": false,\n",
      "                \"rerank_score\": 1.819108247756958\n",
      "            },\n",
      "            {\n",
      "                \"document_id\": \"2e045338c05ab32dc51077b5c4bc050da223393407a2ac06f4c7c08f0cfafe35\",\n",
      "                \"collection_type\": \"user\",\n",
      "                \"parent_collection_hash_id\": \"35c97744abe8d5c98660a634789fd47e46e5e70afad3203f0db561e0c07414f3\",\n",
      "                \"document_name\": \"HNRS3035_08_22_2023_MLIntro.pdf\",\n",
      "                \"document_integrity\": \"f9fedd6b309833c6a40d1a63cc03bc930586308af06504408e103540278c98a0\",\n",
      "                \"text\": \"predictions or other tasks.   \\n \\u2022   Expert systems    : Rule and logic-based systems developed manually by human    \\n experts.   \\n \\u2022   Learning systems    : Systems that learn from data (\\u201cmachine learning\\u201d)    What is it? Continued.   \\n \\u2022   Machine learning (ML) \\u2260 Artificial Intelligence (AI)   \\n \\u2022   ML is a subset of AI, which overlaps with data science   \\n \\u2022   This course focuses specifically on ML   \\n \\u2022   Deep learning    is a subset of ML that    \\n uses artificial neural networks (ANNs)    \\n to perform    representation learning    on    \\n data.\",\n",
      "                \"website_url\": null,\n",
      "                \"private\": false,\n",
      "                \"rerank_score\": 0.09384489059448242\n",
      "            },\n",
      "            {\n",
      "                \"document_id\": \"2b5b0b31adde2555d193105567a192844f51fe0f63abce62e83ceefed2a675a2\",\n",
      "                \"collection_type\": \"user\",\n",
      "                \"parent_collection_hash_id\": \"35c97744abe8d5c98660a634789fd47e46e5e70afad3203f0db561e0c07414f3\",\n",
      "                \"document_name\": \"HNRS3035_08_22_2023_MLIntro.pdf\",\n",
      "                \"document_integrity\": \"f9fedd6b309833c6a40d1a63cc03bc930586308af06504408e103540278c98a0\",\n",
      "                \"text\": \"relationship between said variables from data.   \\n \\u2022   Classification    : Models that predict the categorical class label of data that    \\n are presented.   \\n \\u2022   Dimensionality Reduction    : Models that reduce the dimensionality of data    \\n without losing much information.   \\n \\u2022   Clustering   : Models that can cluster data points into distinct groups based    \\n on similarities in the data   \\n Note   : These are not exclusive definitions.     Types of Learning   \\n \\u2022   Supervised Learning    : uses labeled data to train the model\",\n",
      "                \"website_url\": null,\n",
      "                \"private\": false,\n",
      "                \"rerank_score\": 0.000385037885280326\n",
      "            },\n",
      "            {\n",
      "                \"document_id\": \"2e045338c05ab32dc51077b5c4bc050da223393407a2ac06f4c7c08f0cfafe35\",\n",
      "                \"collection_type\": \"user\",\n",
      "                \"parent_collection_hash_id\": \"35c97744abe8d5c98660a634789fd47e46e5e70afad3203f0db561e0c07414f3\",\n",
      "                \"document_name\": \"HNRS3035_08_22_2023_MLIntro.pdf\",\n",
      "                \"document_integrity\": \"f9fedd6b309833c6a40d1a63cc03bc930586308af06504408e103540278c98a0\",\n",
      "                \"text\": \"\\u2022   Supervised Learning    : uses labeled data to train the model    \\n \\u2022   Unsupervised learning    involves training a model on unlabeled data with the    \\n goal of finding inherent patterns, structures, or relationships within the    \\n data   \\n \\u2022   Semi-supervised Learning    is a learning paradigm that uses a combination of    \\n labeled and unlabeled data for training.    \\n \\u2022   Self-supervised Learning    is a machine learning approach where a model    \\n learns from the data itself by creating its own supervisory signal. A part\",\n",
      "                \"website_url\": null,\n",
      "                \"private\": false,\n",
      "                \"rerank_score\": 0.00011557059042388573\n",
      "            },\n",
      "            {\n",
      "                \"document_id\": \"2b5b0b31adde2555d193105567a192844f51fe0f63abce62e83ceefed2a675a2\",\n",
      "                \"collection_type\": \"user\",\n",
      "                \"parent_collection_hash_id\": \"35c97744abe8d5c98660a634789fd47e46e5e70afad3203f0db561e0c07414f3\",\n",
      "                \"document_name\": \"HNRS3035_08_22_2023_MLIntro.pdf\",\n",
      "                \"document_integrity\": \"f9fedd6b309833c6a40d1a63cc03bc930586308af06504408e103540278c98a0\",\n",
      "                \"text\": \"meaning from human language data:   \\n \\u2022   text classification   \\n \\u2022   language generation   \\n \\u2022   sentiment analysis   \\n \\u2022   conversation   \\n \\u2022   machine translation   \\n \\u2022   Large Language Models    are deep learning models designed to understand    \\n and generate human language, capable of learning patterns, context, and    \\n semantics from vast amounts of text data.   \\n \\u2022   Probabilistic word generation   \\n \\u2022   Recent advances enabled by    transformer    architecture    LLM History   \\n \\u2022   Recurrent Neural Networks    (Rumelhart et. al., 1986): ANN architecture\",\n",
      "                \"website_url\": null,\n",
      "                \"private\": false,\n",
      "                \"rerank_score\": 0.00010686494351830333\n",
      "            },\n",
      "            {\n",
      "                \"document_id\": \"2e045338c05ab32dc51077b5c4bc050da223393407a2ac06f4c7c08f0cfafe35\",\n",
      "                \"collection_type\": \"user\",\n",
      "                \"parent_collection_hash_id\": \"35c97744abe8d5c98660a634789fd47e46e5e70afad3203f0db561e0c07414f3\",\n",
      "                \"document_name\": \"HNRS3035_08_22_2023_MLIntro.pdf\",\n",
      "                \"document_integrity\": \"f9fedd6b309833c6a40d1a63cc03bc930586308af06504408e103540278c98a0\",\n",
      "                \"text\": \"Introduction to AI/ML:    \\n Looking towards LLMs   \\n HNRS 3035   \\n Dr. James Ghawaly    What is it?   \\n \\u2022   Data science    : Study of methods and mechanisms to extract knowledge    \\n from, develop new insights, and make predictions from unstructured or    \\n structured data.   \\n \\u2022   Structured data    : Defined common format (often stored in SQL, HDF5, etc.)   \\n \\u2022   Unstructured data    : Conglomeration of native formats within defined organization    \\n structure.   \\n \\u2022   Artificial Intelligence    : Non-biological systems that \\u201cintelligently\\u201d perform    \\n predictions or other tasks.\",\n",
      "                \"website_url\": null,\n",
      "                \"private\": false,\n",
      "                \"rerank_score\": 0.00010636094521032646\n",
      "            },\n",
      "            {\n",
      "                \"document_id\": \"2e045338c05ab32dc51077b5c4bc050da223393407a2ac06f4c7c08f0cfafe35\",\n",
      "                \"collection_type\": \"user\",\n",
      "                \"parent_collection_hash_id\": \"35c97744abe8d5c98660a634789fd47e46e5e70afad3203f0db561e0c07414f3\",\n",
      "                \"document_name\": \"HNRS3035_08_22_2023_MLIntro.pdf\",\n",
      "                \"document_integrity\": \"f9fedd6b309833c6a40d1a63cc03bc930586308af06504408e103540278c98a0\",\n",
      "                \"text\": \"learns from the data itself by creating its own supervisory signal. A part    \\n of the data is used to generate labels or targets, and the model learns to    \\n predict these targets from the remaining data.   \\n \\u2022   Reinforcement Learning    : Models trained to maximize receipt of reward    \\n signals. Rewards are given for desirable behaviors/traits. Often used for    \\n control problems.    ML Model Training   \\n \\u2022   A deep learning model is trained to minimize a user-defined    loss function    \\n using    gradient descent    through an algorithm called    backpropagation\",\n",
      "                \"website_url\": null,\n",
      "                \"private\": false,\n",
      "                \"rerank_score\": 0.00010219876276096329\n",
      "            },\n",
      "            {\n",
      "                \"document_id\": \"2e045338c05ab32dc51077b5c4bc050da223393407a2ac06f4c7c08f0cfafe35\",\n",
      "                \"collection_type\": \"user\",\n",
      "                \"parent_collection_hash_id\": \"35c97744abe8d5c98660a634789fd47e46e5e70afad3203f0db561e0c07414f3\",\n",
      "                \"document_name\": \"HNRS3035_08_22_2023_MLIntro.pdf\",\n",
      "                \"document_integrity\": \"f9fedd6b309833c6a40d1a63cc03bc930586308af06504408e103540278c98a0\",\n",
      "                \"text\": \"\\u2022   Recurrent Neural Networks    (Rumelhart et. al., 1986): ANN architecture    \\n comprising neuron models that maintain hidden memory state.   \\n \\u2022   Short-term memory   \\n \\u2022   Impossible to parallelize & unstable training   \\n \\u2022   Long Short-term Memory    (Hochreiter et. al., 1997): More complicated RNN    \\n models with gates that modulate the flow of temporal information    \\n through the cell   \\n \\u2022   Both short and long-term memory   \\n \\u2022   Impossible to parallelize & unstable training   \\n \\u2022   Transformers    : \\u201cAttention is all you Need\\u201d (Vaswani, 2017)\",\n",
      "                \"website_url\": null,\n",
      "                \"private\": false,\n",
      "                \"rerank_score\": 0.00010102824307978153\n",
      "            },\n",
      "            {\n",
      "                \"document_id\": \"2b5b0b31adde2555d193105567a192844f51fe0f63abce62e83ceefed2a675a2\",\n",
      "                \"collection_type\": \"user\",\n",
      "                \"parent_collection_hash_id\": \"35c97744abe8d5c98660a634789fd47e46e5e70afad3203f0db561e0c07414f3\",\n",
      "                \"document_name\": \"HNRS3035_08_22_2023_MLIntro.pdf\",\n",
      "                \"document_integrity\": \"f9fedd6b309833c6a40d1a63cc03bc930586308af06504408e103540278c98a0\",\n",
      "                \"text\": \"nonlinear function to those inputs, and outputs the result.   \\n \\u2022   Each neuron-to-neuron connection (    synapse   ) scales the input signal by a    \\n tunable weight.   \\n \\u2022   Other types of layers are often embedded between neuronal layers for various    \\n purposes.                                                                  \\n    Main Types of Models   \\n \\u2022   Regression   : Models that acts as a function that predicts the value of a    \\n variable given any number of independent variables, by learning the    \\n relationship between said variables from data.\",\n",
      "                \"website_url\": null,\n",
      "                \"private\": false,\n",
      "                \"rerank_score\": 9.216085891239345e-05\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update({\n",
    "    \"query\": \"What is representation learning?\",\n",
    "    \"collection_hash_ids\": [COLLECTION_ARGS[\"hash_id\"]],\n",
    "    \"use_rerank\": True\n",
    "})\n",
    "\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/query_vector_db\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "if \"trace\" in result:\n",
    "    print(result[\"trace\"])\n",
    "assert not (\"success\" in result and result[\"success\"] == False), json.dumps(result[\"trace\"], indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `craft_document_access_token`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/craft_document_access_token\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `fetch_document`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/fetch_document\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `create_organization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/create_organization\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `invite_user_to_organization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/invite_user_to_organization\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `resolve_organization_invitation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_2)\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/resolve_organization_invitation\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `fetch_memberships`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "input = {\n",
    "    \"username\": \"test_1\",\n",
    "    \"password_prehash\": PASSWORD_PREHASH\n",
    "}\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/fetch_memberships\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `fetch_memberships_of_organization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "input = {\n",
    "    \"username\": \"test_1\",\n",
    "    \"password_prehash\": PASSWORD_PREHASH\n",
    "}\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/fetch_memberships_of_organization\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `set_user_serp_key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "input = {\n",
    "    \"username\": \"test_1\",\n",
    "    \"password_prehash\": PASSWORD_PREHASH\n",
    "}\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/set_user_serp_key\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `set_organization_serp_key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "input = {\n",
    "    \"username\": \"test_1\",\n",
    "    \"password_prehash\": PASSWORD_PREHASH\n",
    "}\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/set_organization_serp_key\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `get_serp_key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "input = {\n",
    "    \"username\": \"test_1\",\n",
    "    \"password_prehash\": PASSWORD_PREHASH\n",
    "}\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/get_serp_key\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `search_google`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "input = {\n",
    "    \"username\": \"test_1\",\n",
    "    \"password_prehash\": PASSWORD_PREHASH\n",
    "}\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/search_google\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `perform_search_query`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "input = {\n",
    "    \"username\": \"test_1\",\n",
    "    \"password_prehash\": PASSWORD_PREHASH\n",
    "}\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/perform_search_query\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QL_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
