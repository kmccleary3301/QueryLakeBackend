{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Functions to Test\n",
    "\n",
    "### User Auth\n",
    "* `add_user`\n",
    "* `login`\n",
    "* `get_available_models`\n",
    "* `set_user_openai_api_key`\n",
    "* `set_organization_openai_id`\n",
    "* `get_openai_api_key`\n",
    "\n",
    "### Collections\n",
    "* `fetch_document_collections_belonging_to`\n",
    "* `create_document_collection`\n",
    "* `fetch_all_collections`\n",
    "* `fetch_collection`\n",
    "* `modify_document_collection`\n",
    "\n",
    "### Documents\n",
    "* `upload_document`\n",
    "* `delete_document`\n",
    "* `get_document_secure`\n",
    "* `query_vector_db`\n",
    "* `craft_document_access_token`\n",
    "* `fetch_document`\n",
    "\n",
    "### Organizations\n",
    "* `create_organization`\n",
    "* `invite_user_to_organization`\n",
    "* `resolve_organization_invitation`\n",
    "* `fetch_memberships`\n",
    "* `fetch_memberships_of_organization`\n",
    "\n",
    "### Web Search\n",
    "* `set_user_serp_key`\n",
    "* `set_organization_serp_key`\n",
    "* `get_serp_key`\n",
    "* `search_google`\n",
    "* `perform_search_query`\n",
    "\n",
    "### Toolchains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# Generate a random UUID\n",
    "\n",
    "\n",
    "USERNAME_1 = str(uuid.uuid4())[:32]\n",
    "PASSWORD_1 = str(uuid.uuid4())[:32]\n",
    "\n",
    "# USERNAME_1 = \"rag_project\"\n",
    "# PASSWORD_1 = \"rag_project\"\n",
    "\n",
    "USERNAME_2 = str(uuid.uuid4())[:32]\n",
    "PASSWORD_2 = str(uuid.uuid4())[:32]\n",
    "\n",
    "PDF_TO_UPLOAD_PATH = '/shared_folders/querylake_server/other/HNRS3035_08_22_2023_MLIntro.pdf'\n",
    "MD_FILE_TO_UPLOAD_PATH = '/shared_folders/querylake_server/other/Primary_2.md'\n",
    "LARGE_PDF_TO_UPLOAD_PATH = '/shared_folders/querylake_server/other/stats_book.pdf'\n",
    "# LARGE_PDF_TO_UPLOAD_PATH = '/home/kmccleary/projects/other/HNRS3035_08_22_2023_MLIntro.pdf'\n",
    "\n",
    "print(f'USERNAME_1: {USERNAME_1}')\n",
    "print(f'USERNAME_2: {USERNAME_2}')\n",
    "print(f'PASSWORD_1: {PASSWORD_1}')\n",
    "print(f'PASSWORD_2: {PASSWORD_2}')\n",
    "\n",
    "ALL_RESPONSES = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `add_user`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "add_user_input = {\n",
    "    \"username\": USERNAME_1,\n",
    "    \"password\": PASSWORD_1,\n",
    "}\n",
    "\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/add_user\", json=add_user_input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "add_user_input = {\n",
    "    \"username\": USERNAME_2,\n",
    "    \"password\": PASSWORD_2,\n",
    "}\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/add_user\", json=add_user_input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "ALL_RESPONSES[\"add_user\"] = result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `login`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "add_user_input = {\"auth\":{\n",
    "    \"username\": USERNAME_1,\n",
    "    \"password\": PASSWORD_1,\n",
    "}}\n",
    "\n",
    "print(add_user_input)\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/login\", json=add_user_input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "# USER_ARGS_1 = {\"username\": USERNAME_1, \"password_prehash\": result[\"result\"][\"password_pre_hash\"]}\n",
    "# USER_ARGS_1 = {\"auth\": USER_ARGS_1}\n",
    "USER_ARGS_1 = {\"auth\":  result[\"result\"][\"auth\"]}\n",
    "\n",
    "\n",
    "add_user_input = {\"auth\":{\n",
    "    \"username\": USERNAME_2,\n",
    "    \"password\": PASSWORD_2,\n",
    "}}\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/login\", json=add_user_input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "USER_ARGS_2 = {\"auth\":  result[\"result\"][\"auth\"]}\n",
    "\n",
    "print(json.dumps(USER_ARGS_1, indent=4))\n",
    "\n",
    "ALL_RESPONSES[\"login\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `and_`\n",
    "this should fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "input = {\n",
    "    \"username\": \"test\",\n",
    "    \"password\": \"test\",\n",
    "}\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/and_\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert (\"success\" in result and result[\"success\"] == False), \"Test succeeded when it should have failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `get_available_models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/get_available_models\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "ALL_RESPONSES[\"get_available_models\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `create_api_key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "def create_api_key(title : str):\n",
    "    input = deepcopy({\"auth\": {\"username\": USERNAME_1, \"password\": PASSWORD_1}})\n",
    "    input.update({\"title\": title})\n",
    "\n",
    "    response = requests.get(\"http://localhost:8000/api/create_api_key\", json=input)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    result = response.json()\n",
    "\n",
    "    print(json.dumps(result, indent=4))\n",
    "    if \"trace\" in result:\n",
    "        print(result[\"trace\"])\n",
    "    assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "    \n",
    "    return result[\"result\"]\n",
    "\n",
    "API_KEY_1_INFO = create_api_key(\"API Key 1\")\n",
    "API_KEY_2_INFO = create_api_key(\"API Key 2\")\n",
    "\n",
    "API_KEY_1 = API_KEY_1_INFO[\"api_key\"]\n",
    "\n",
    "print(\"API_KEY_1:\", [API_KEY_1])\n",
    "\n",
    "ALL_RESPONSES[\"create_api_key\"] = {\"success\": True, \"result\": API_KEY_1_INFO}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `fetch_api_keys`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy({\"auth\": {\"username\": USERNAME_1, \"password\": PASSWORD_1}})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/fetch_api_keys\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "ALL_RESPONSES[\"fetch_api_keys\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `delete_api_key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy({\"auth\": {\"username\": USERNAME_1, \"password\": PASSWORD_1}})\n",
    "input.update({\"api_key_id\": API_KEY_2_INFO[\"id\"]})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/delete_api_key\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "ALL_RESPONSES[\"delete_api_key\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `create_oauth2_token`\n",
    "\n",
    "Create an OAuth2 token for logging in.\n",
    "Note that all oauth2 tokens will be invalid if the backend is restarted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = {\"auth\": {\"username\": USERNAME_1, \"password\": PASSWORD_1}}\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/create_oauth2_token\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "OAUTH2_TOKEN = result[\"result\"]\n",
    "\n",
    "ALL_RESPONSES[\"create_oauth2_token\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ Using OAuth2 Token\n",
    "\n",
    "You can login with oauth2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = {\"auth\": {\"username\": USERNAME_1, \"password\": PASSWORD_1}}\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/login\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `function_help`\n",
    "\n",
    "Get the specs of all available api endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = {\"auth\": {\"username\": USERNAME_1, \"password\": PASSWORD_1}}\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/function_help\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "if \"result\" in result:\n",
    "\tprint(json.dumps([r[\"function_name\"] for r in result[\"result\"]], indent=4))\n",
    " \n",
    "ALL_RESPONSES[\"function_help\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `fetch_document_collections_belonging_to`\n",
    "* ✅ `user`\n",
    "* `organization`\n",
    "* `global`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/fetch_document_collections_belonging_to\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "ALL_RESPONSES[\"fetch_document_collections_belonging_to\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `create_document_collection`\n",
    "\n",
    "Create a searchable collection of documents, similar to a playlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update({\n",
    "    \"name\": \"rag_collection\"\n",
    "})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/create_document_collection\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"trace\"]\n",
    "\n",
    "COLLECTION_ARGS = {\"hash_id\": result[\"result\"][\"hash_id\"]}\n",
    "\n",
    "ALL_RESPONSES[\"create_document_collection\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `fetch_all_collections`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "response = requests.get(\"http://localhost:8000/api/fetch_all_collections\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "ALL_RESPONSES[\"fetch_all_collections\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `fetch_collection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update({\n",
    "    \"collection_hash_id\": COLLECTION_ARGS[\"hash_id\"],\n",
    "})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/fetch_collection\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "ALL_RESPONSES[\"fetch_collection\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `fetch_collection_documents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = {\n",
    "    \"auth\": {\"api_key\": API_KEY_1},\n",
    "    \"collection_hash_id\": COLLECTION_ARGS[\"hash_id\"],\n",
    "}\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/fetch_collection_documents\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "ALL_RESPONSES[\"fetch_collection_documents\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `modify_document_collection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update({\n",
    "    \"collection_hash_id\": COLLECTION_ARGS[\"hash_id\"],\n",
    "    \"title\": \"test_collection_1_modified\",\n",
    "    \"description\": \"test description please ignore\"\n",
    "})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/modify_document_collection\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "ALL_RESPONSES[\"modify_document_collection\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `trigger_database_sql_error`\n",
    "\n",
    "This is supposed to fail, so we can check that calls continue functioning and the server database engine doesn't get locked up by a bad transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = {\n",
    "\t\"auth\": {\"api_key\": API_KEY_1}\n",
    "}\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/trigger_database_sql_error\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == True)\n",
    "\n",
    "ALL_RESPONSES[\"trigger_database_sql_error\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `upload_document`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from urllib.parse import urlencode\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update({\n",
    "    \"collection_hash_id\": COLLECTION_ARGS[\"hash_id\"],\n",
    "    \"await_embedding\": True\n",
    "})\n",
    "\n",
    "# encoded_params = urlencode({\"parameters\": json.dumps(input)})\n",
    "\n",
    "for i, path in enumerate([PDF_TO_UPLOAD_PATH, PDF_TO_UPLOAD_PATH, LARGE_PDF_TO_UPLOAD_PATH]):\n",
    "    with open(path, 'rb') as f:\n",
    "        # Define the files parameter for the POST request\n",
    "        files = {'file': f}\n",
    "        input_json = json.dumps(input)\n",
    "        new_inputs = {**input, \"create_embeddings\": (i != 2)}\n",
    "        encoded_params = urlencode({\"parameters\": json.dumps(new_inputs)})\n",
    "        \n",
    "        \n",
    "        # response = requests.post(\"http://localhost:8000/upload_document\", json=new_inputs, files=files)\n",
    "        response = requests.post(\"http://localhost:8000/upload_document?\"+encoded_params, files=files)\n",
    "        response.raise_for_status()\n",
    "\t\t\n",
    "        result = response.json()\n",
    "        f.close()\n",
    "\n",
    "        print(json.dumps(result, indent=4))\n",
    "\n",
    "ALL_RESPONSES[\"upload_document\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `upload_document` [Archive]\n",
    "\n",
    "Upload a zip file of documents to be added to a collection in a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import io\n",
    "\n",
    "def upload_file_archive(file_obj, args : dict):\n",
    "    files = {'file': file_obj}\n",
    "    encoded_params = urlencode({\"parameters\": json.dumps(args)})\n",
    "    response = requests.post(\"http://localhost:8000/upload_document?\" + encoded_params, files=files)\n",
    "    response.raise_for_status()\n",
    "    result = response.json()\n",
    "    \n",
    "    if (\"success\" in result and result[\"success\"] == False):\n",
    "        print(result[\"trace\"])\n",
    "    assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "file_paths = [PDF_TO_UPLOAD_PATH, PDF_TO_UPLOAD_PATH, LARGE_PDF_TO_UPLOAD_PATH]\n",
    "\n",
    "# Create a BytesIO object to hold the zip archive in memory\n",
    "zip_buffer = io.BytesIO()\n",
    "\n",
    "with zipfile.ZipFile(zip_buffer, 'w') as zipf:\n",
    "\tfor file in file_paths:\n",
    "\t\tzipf.write(file, arcname=\"archive_\"+file.split('/')[-1])\n",
    "\n",
    "\n",
    "# Seek to the beginning of the BytesIO buffer\n",
    "zip_buffer.seek(0)\n",
    "zip_buffer.name = \"test.zip\"\n",
    "\n",
    "result = upload_file_archive(\n",
    "    zip_buffer,\n",
    "    {\n",
    "        \"auth\": {\"api_key\": API_KEY_1}, \n",
    "        \"collection_hash_id\": COLLECTION_ARGS[\"hash_id\"],\n",
    "        \"await_embedding\": True\n",
    "    }\n",
    ")\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "\n",
    "TARGET_DOCS = [e[\"hash_id\"] for e in result[\"result\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `update_documents`\n",
    "\n",
    "Update document metadata and/or text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "update_field = {\n",
    "\t\"document_id\": TARGET_DOCS[2],\n",
    "\t\"metadata\": {\n",
    "\t\t\"test_field\": \"test_value\"\n",
    "\t},\n",
    "\t\"text\": \"TEST TEST TEST TEST TEST\"\n",
    "}\n",
    "\n",
    "all_entries = [update_field]\n",
    "\n",
    "jsonl_bytes = io.BytesIO()\n",
    "jsonl_bytes.write(\"\\n\".join([json.dumps(e) for e in all_entries]).encode())\n",
    "jsonl_bytes.seek(0)\n",
    "jsonl_bytes.name = \"metadata.jsonl\"\n",
    "\n",
    "\n",
    "# new_args = {\n",
    "# \t\"auth\": {\"api_key\": API_KEY_1},\n",
    "# \t\"data\": update_field,\n",
    "# \t\"await_embedding\": True\n",
    "# }\n",
    "\n",
    "# response = requests.post(\"http://localhost:8000/api/update_documents\", json=new_args)\n",
    "# response.raise_for_status()\n",
    "\n",
    "# result = response.json()\n",
    "\n",
    "args_file_version = {\n",
    "\t\"auth\": {\"api_key\": API_KEY_1},\n",
    "\t\"await_embedding\": True\n",
    "}\n",
    "\n",
    "files = {'file': jsonl_bytes}\n",
    "encoded_params = urlencode({\"parameters\": json.dumps(args_file_version)})\n",
    "response = requests.post(\"http://localhost:8000/update_documents?\" + encoded_params, files=files)\n",
    "response.raise_for_status()\n",
    "result = response.json()\n",
    "\n",
    "if (\"success\" in result and result[\"success\"] == False):\n",
    "\tprint(result[\"trace\"])\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"note\"]\n",
    "\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get new doc ids\n",
    "\n",
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "add_user_input = deepcopy(USER_ARGS_1)\n",
    "add_user_input.update({\n",
    "    \"collection_hash_id\": COLLECTION_ARGS[\"hash_id\"],\n",
    "})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/fetch_collection_documents\", json=add_user_input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "DOC_ARGS_1 = {\"hash_id\": result[\"result\"][0][\"hash_id\"]}\n",
    "DOC_ARGS_2 = {\"hash_id\": result[\"result\"][1][\"hash_id\"]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `delete_document`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update(DOC_ARGS_1)\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/delete_document\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "ALL_RESPONSES[\"delete_document\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `get_document_secure`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update(DOC_ARGS_2)\n",
    "\n",
    "print(json.dumps(input, indent=4))\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/get_document_secure\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "ALL_RESPONSES[\"get_document_secure\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `query_database`\n",
    "\n",
    "This is deprecated, as we now use `search_bm25` and `search_hybrid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests, json\n",
    "# from copy import deepcopy\n",
    "\n",
    "# # input = deepcopy(USER_ARGS_1)\n",
    "\n",
    "# input = {\n",
    "#     \"auth\": {\"api_key\": API_KEY_1}\n",
    "# }\n",
    "\n",
    "# # input.update({\n",
    "# #     # \"query\": [\"Riemann Roch Theorem\"],\n",
    "# #     \"query\": [\"Huey Newton\", \"What is representation learning?\", \"What is an artificial neural network?\"],\n",
    "# #     # \"query\": \"Who is Catherine?\",\n",
    "# #     \"collection_ids\": [COLLECTION_ARGS[\"hash_id\"]],\n",
    "# #     \"use_lexical\": True,\n",
    "# #     \"use_embeddings\": True,\n",
    "# #     # \"rerank_question\": \"What is the purpose of the Riemann Roch Theorem?\",\n",
    "# #     # \"rerank_question\": \"What is Representation Learning?\",\n",
    "# #     \"rerank_question\": \"Who is Huey Newton?\",\n",
    "# #     \"use_rerank\": True,\n",
    "# #     \"use_web\": True,\n",
    "# #     \"k\": 20,\n",
    "# #     \"minimum_relevance\": 0,\n",
    "# # })\n",
    "\n",
    "# input.update({\n",
    "#     # \"query\": \"Who is Huey Newton?\",\n",
    "#     \"query\": [\"Huey Newton\", \"What is representation learning?\", \"What is an artificial neural network?\"],\n",
    "#     # \"collection_ids\": [],\n",
    "# \t\"collection_ids\": [COLLECTION_ARGS[\"hash_id\"]],\n",
    "#     \"k\": 5,\n",
    "#     \"use_lexical\": True,\n",
    "#     \"use_embeddings\": True,\n",
    "#     \"use_rerank\": True,\n",
    "#     # \"use_web\": True,\n",
    "#     \"rerank_question\": \"What is representation learning?\",\n",
    "#     \"ratio\": 0.5,\n",
    "#     \"minimum_relevance\": 0\n",
    "# })\n",
    "\n",
    "# print(\"Collection Hash:\", COLLECTION_ARGS[\"hash_id\"])\n",
    "\n",
    "# response = requests.get(\"http://localhost:8000/api/query_database\", json=input)\n",
    "# response.raise_for_status()\n",
    "\n",
    "# result = response.json()\n",
    "\n",
    "# print(json.dumps(result, indent=4))\n",
    "# if \"trace\" in result:\n",
    "#     print(result[\"trace\"])\n",
    "    \n",
    "# assert not (\"success\" in result and result[\"success\"] == False), json.dumps(result[\"trace\"], indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `search_hybrid`\n",
    "\n",
    "Search over document collections with hybrid bm25+vector search, and optionally with a reranker.\n",
    "You can optionally control the seperate queries for bm25, embedding, and reranking if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "# input = deepcopy(USER_ARGS_1)\n",
    "\n",
    "input = {\n",
    "    \"auth\": {\"api_key\": API_KEY_1}\n",
    "}\n",
    "\n",
    "input.update({\n",
    "    # \"query\": \"Who is Huey Newton?\",\n",
    "    \"query\": {\n",
    "        \"bm25\": \"Scores and Other Normal Curve\",\n",
    "        \"embedding\": \"Scores and Other Normal Curve\",\n",
    "        # \"rerank\": \"Scores and Other Normal Curve\"\n",
    "    },\n",
    "\t\"collection_ids\": [COLLECTION_ARGS[\"hash_id\"]],\n",
    "    \"limit_bm25\": 10,\n",
    "    \"limit_similarity\": 10,\n",
    "    \"bm25_weight\": 0.9,\n",
    "    \"similarity_weight\": 0.1,\n",
    "    \"group_chunks\": False\n",
    "    # \"return_statement\": True\n",
    "})\n",
    "\n",
    "print(\"Collection Hash:\", COLLECTION_ARGS[\"hash_id\"])\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/search_hybrid\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "if \"trace\" in result:\n",
    "    print(result[\"trace\"])\n",
    "\n",
    "assert not (\"success\" in result and result[\"success\"] == False), json.dumps(result[\"trace\"], indent=4)\n",
    "\n",
    "ALL_RESPONSES[\"search_hybrid\"] = result\n",
    "\n",
    "# print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `search_bm25`\n",
    "\n",
    "Search over specified document collections with BM25 given a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "# input = deepcopy(USER_ARGS_1)\n",
    "\n",
    "input = {\n",
    "    \"auth\": {\"api_key\": API_KEY_1}\n",
    "}\n",
    "\n",
    "input.update({\n",
    "    # \"query\": \"Who is Huey Newton?\",\n",
    "    # \"query\": \"were compared with students who had had an introductory\",\n",
    "    # \"query\": \"Scores and Other Normal Curve\",\n",
    "    \"query\": \"document_md.test_field:\\\"test_value\\\"\",\n",
    "\t\"collection_ids\": [COLLECTION_ARGS[\"hash_id\"]],\n",
    "\t# \"collection_ids\": [\"yQl406UQAvhAzKlPCdOs0GsrtPJSzB63\"],\n",
    "    \"limit\": 10,\n",
    "    # \"return_statement\": True\n",
    "})\n",
    "\n",
    "print(\"Collection Hash:\", COLLECTION_ARGS[\"hash_id\"])\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/search_bm25\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "if \"trace\" in result:\n",
    "    print(result[\"trace\"])\n",
    "\n",
    "assert not (\"success\" in result and result[\"success\"] == False), json.dumps(result[\"trace\"], indent=4)\n",
    "\n",
    "ALL_RESPONSES[\"search_bm25\"] = result\n",
    "\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `craft_document_access_token`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update(DOC_ARGS_2)\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/craft_document_access_token\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "DOCUMENT_AUTH_ACCESS = {\"document_auth_access\": result[\"result\"][\"access_encrypted\"]}\n",
    "\n",
    "ALL_RESPONSES[\"craft_document_access_token\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `download_document`\n",
    "\n",
    "Returns a link to open or download a document. Meant to be used with `craft_document_access_token`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from urllib.parse import urlencode\n",
    "from copy import deepcopy\n",
    "\n",
    "# input = deepcopy(USER_ARGS_1)\n",
    "input = deepcopy(DOCUMENT_AUTH_ACCESS)\n",
    "\n",
    "encoded_params = urlencode({\"parameters\": json.dumps(input)})\n",
    "\n",
    "new_url = \"http://localhost:8000/download_document?\"+encoded_params\n",
    "print(new_url)\n",
    "\n",
    "# response = requests.get(\"http://localhost:8000/api/download_document?\"+encoded_params)\n",
    "# response.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `fetch_document`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "response = requests.get(f\"http://localhost:8000/api/fetch_document\", json={\n",
    "    \"auth\": {\"api_key\": API_KEY_1},\n",
    "    \"document_id\": DOC_ARGS_2[\"hash_id\"],\n",
    "    \"get_chunk_count\": True,\n",
    "}, stream=False)\n",
    "response.raise_for_status()\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `create_organization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update({\n",
    "    \"organization_name\": \"test_org\",\n",
    "})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/create_organization\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "ORG_ARGS = result[\"result\"][\"organization_dict\"]\n",
    "\n",
    "ALL_RESPONSES[\"create_organization\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `set_organization_openai_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update({\n",
    "    \"openai_organization_id\": \"org-1111111111111111111111111\"\n",
    "})\n",
    "input.update({\n",
    "    \"organization_hash_id\": ORG_ARGS[\"hash_id\"]\n",
    "})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/set_organization_openai_id\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `invite_user_to_organization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update({\n",
    "    \"username_to_invite\": USERNAME_2,\n",
    "    \"organization_id\": ORG_ARGS[\"id\"],\n",
    "    \"member_class\": \"member\"\n",
    "})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/invite_user_to_organization\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "ALL_RESPONSES[\"invite_user_to_organization\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `fetch_memberships`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_2)\n",
    "input.update({\n",
    "    \"return_subset\" : \"all\"\n",
    "})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/fetch_memberships\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "INVITATION = result[\"result\"][\"memberships\"][0]\n",
    "\n",
    "ALL_RESPONSES[\"fetch_memberships\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `resolve_organization_invitation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_2)\n",
    "input.update({\n",
    "    \"organization_id\": INVITATION[\"organization_id\"],\n",
    "    \"accept\": True\n",
    "})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/resolve_organization_invitation\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "ALL_RESPONSES[\"resolve_organization_invitation\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `fetch_memberships_of_organization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update({\n",
    "    \"organization_id\": INVITATION[\"organization_id\"],\n",
    "})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/fetch_memberships_of_organization\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "ALL_RESPONSES[\"fetch_memberships_of_organization\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `change_collection_ownership`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {\"auth\":{\n",
    "    \"username\": USERNAME_1,\n",
    "    \"password\": PASSWORD_1,\n",
    "}}\n",
    "input.update({\n",
    "    \"collection_id\": COLLECTION_ARGS[\"hash_id\"],\n",
    "    \"organization_id\": INVITATION[\"organization_id\"],\n",
    "})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/change_collection_ownership\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "ALL_RESPONSES[\"change_collection_ownership\"] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {\"auth\":{\n",
    "    \"username\": USERNAME_1,\n",
    "    \"password\": PASSWORD_1,\n",
    "}}\n",
    "input.update({\n",
    "    \"collection_hash_id\": COLLECTION_ARGS[\"hash_id\"],\n",
    "})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/fetch_collection\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(\"First user result:\")\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "\n",
    "input = {\"auth\":{\n",
    "    \"username\": USERNAME_2,\n",
    "    \"password\": PASSWORD_2,\n",
    "}}\n",
    "input.update({\n",
    "    \"collection_hash_id\": COLLECTION_ARGS[\"hash_id\"],\n",
    "})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/fetch_collection\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(\"\\nSecond user result:\")\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {\"auth\":{\n",
    "    \"username\": USERNAME_2,\n",
    "    \"password\": PASSWORD_2,\n",
    "}}\n",
    "input.update({\n",
    "    \"collection_ids\": [COLLECTION_ARGS[\"hash_id\"]],\n",
    "    \"organization_id\": INVITATION[\"organization_id\"],\n",
    "    \"table\": \"document\",\n",
    "    \"limit\": 10,\n",
    "    \"offset\": 0,\n",
    "    \"sort_by\": \"id\",\n",
    "    \"query\": \"\",\n",
    "})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/search_bm25\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `set_user_serp_key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User external provider data has been changed. This functionality is deprecated.\n",
    "if False:\n",
    "    import requests, json\n",
    "    from copy import deepcopy\n",
    "\n",
    "    input = deepcopy(USER_ARGS_1)\n",
    "    input.update({\n",
    "        \"serp_key\" : \"test_serp_key\"\n",
    "    })\n",
    "\n",
    "    response = requests.get(\"http://localhost:8000/api/set_user_serp_key\", json=input)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    result = response.json()\n",
    "\n",
    "    print(json.dumps(result, indent=4))\n",
    "    assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `set_organization_serp_key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User external provider data has been changed. This functionality is deprecated.\n",
    "if False:\n",
    "    import requests, json\n",
    "    from copy import deepcopy\n",
    "\n",
    "    input = deepcopy(USER_ARGS_1)\n",
    "    input.update({\n",
    "        \"serp_key\" : \"test_serp_key\",\n",
    "        \"organization_hash_id\": ORG_ARGS[\"hash_id\"]\n",
    "    })\n",
    "\n",
    "    response = requests.get(\"http://localhost:8000/api/set_organization_serp_key\", json=input)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    result = response.json()\n",
    "\n",
    "    print(json.dumps(result, indent=4))\n",
    "    assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `get_serp_key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User external provider data has been changed. This functionality is deprecated.\n",
    "if False:\n",
    "    import requests, json\n",
    "    from copy import deepcopy\n",
    "\n",
    "    input = deepcopy(USER_ARGS_1)\n",
    "\n",
    "    response = requests.get(\"http://localhost:8000/api/get_serp_key\", json=input)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    result = response.json()\n",
    "\n",
    "    print(json.dumps(result, indent=4))\n",
    "    assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ❌ `search_google`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # Not implemented yet\n",
    "    import requests, json\n",
    "    from copy import deepcopy\n",
    "\n",
    "    input = deepcopy(USER_ARGS_1)\n",
    "\n",
    "    response = requests.get(\"http://localhost:8000/api/search_google\", json=input)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    result = response.json()\n",
    "\n",
    "    print(json.dumps(result, indent=4))\n",
    "    assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ❌ `perform_search_query`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # Not implemented yet.\n",
    "    import requests, json\n",
    "    from copy import deepcopy\n",
    "\n",
    "    input = deepcopy(USER_ARGS_1)\n",
    "\n",
    "    response = requests.get(\"http://localhost:8000/api/perform_search_query\", json=input)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    result = response.json()\n",
    "\n",
    "    print(json.dumps(result, indent=4))\n",
    "    assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ❌ `embed_urls`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(f\"http://localhost:8000/api/embed_urls\", json={\n",
    "    \"auth\": {\"api_key\": API_KEY_1},\n",
    "    \"urls\": [\n",
    "        \"https://en.wikipedia.org/wiki/Riemann%E2%80%93Roch_theorem\",\n",
    "        \"https://en.wikipedia.org/wiki/Huey_P._Newton\"\n",
    "    ]\n",
    "}, stream=False)\n",
    "response.raise_for_status()\n",
    "result = response.json()\n",
    "\n",
    "# print(result)\n",
    "\n",
    "if \"error\" in result:\n",
    "    print(result[\"error\"])\n",
    "    print(result[\"trace\"])\n",
    "else:\n",
    "    for c in result[\"result\"][\"content\"]:\n",
    "        print(c[\"text\"][:min(2000, len(c[\"text\"]))])\n",
    "        print(c[\"metadata\"], end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `llm` [Streaming]\n",
    "\n",
    "Call an LLM with streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json, time\n",
    "from copy import deepcopy\n",
    "\n",
    "prompt = \"What is the Riemann-Roch theorem?\"\n",
    "\n",
    "def run_llm_test(prompt_input, parameters={}):\n",
    "\tsystem_instruction = \"You are a general answering assistant that can comply with any request.\\n\\nYou always answer with markdown formatting. You will be penalized if you do not answer with markdown when it would be possible.\\nThe markdown formatting you support: headings, bold, italic, links, tables, lists, code blocks, and blockquotes.\\nYou do not support images and never include images. You will be penalized if you render images.\\n\\nAlways use markdown code blocks for code, and always use MathJax with LaTeX formatting for pure math expressions.\\nFor example code would look like:\\n```python\\n*Python code here\\n```\\nAnd math expressions would look like:\\n$$P(y|x) = \\\\frac{{P(x|y) \\\\cdot P(y)}}{{P(x)}}$$\"\n",
    "\tprompt_formatted = f\"<s>[INST] <<SYS>>\\n{system_instruction}\\n<</SYS>>\\n{prompt_input} [/INST] \"\n",
    "\tsample_input = {\n",
    "\t\t# \"model_choice\": \"mistral-7b-instruct-v0.1\",\n",
    "\t\t\"stream\": True, \n",
    "\t\t\"max_tokens\": 1000, \n",
    "\t\t\"temperature\": 0.5, \n",
    "\t\t\"top_p\": 0.9, \n",
    "\t\t\"repetition_penalty\": 1.15\n",
    "\t}\n",
    "\tsample_input.update(parameters)\n",
    " \n",
    "\t# input = deepcopy(USER_ARGS_1)\n",
    "\tinput = {\n",
    "\t\t\"auth\": {\n",
    "\t\t\t\"api_key\": API_KEY_1\n",
    "\t\t}\n",
    "\t}\n",
    "\tinput.update({\n",
    "\t\t\"model_parameters\": sample_input,\n",
    "\t\t\"question\": prompt_input, \n",
    "\t})\n",
    "\n",
    "\n",
    "\tglobal_start_time = time.time()\n",
    "\n",
    "\tresponse = requests.get(f\"http://localhost:8000/api/llm\", json=input, stream=True)\n",
    "\tresponse.raise_for_status()\n",
    "\tresponse_completed = \"\"\n",
    "\tstart_time, token_count = time.time(), 0\n",
    "\tfor chunk_raw in response.iter_content(chunk_size=None, decode_unicode=False):\n",
    "\t\t# print(chunk_raw)\n",
    "\t\tif token_count == 0:\n",
    "\t\t\tstart_time = time.time()\n",
    "\t\ttoken_count += 1\n",
    "\t\tchunk_decoded = chunk_raw.decode(\"utf-8\")\n",
    "\t\t# print(chunk_decoded)\n",
    "\t\t# chunk = json.loads(chunk_decoded)[\"text\"]\n",
    "\t\tchunk = chunk_decoded\n",
    "\t\tresponse_completed += chunk\n",
    "\t\tprint(chunk, end=\"\")\n",
    "\t\t\n",
    "\tend_time = time.time()\n",
    "\ttime_taken = end_time - start_time\n",
    "\tprint(\"\\n\\n\\nFINISHED RESPONSE WITH %5d tokens, %7.2f t/s, (%7.4f - %7.4f):\" % (token_count, (token_count-1) / time_taken, start_time - global_start_time, end_time - global_start_time), [prompt, response_completed])\n",
    " \n",
    "run_llm_test(prompt)\n",
    "\n",
    "ALL_RESPONSES[\"llm_streaming\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `llm` [Static]\n",
    "\n",
    "Call an llm, no token streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(f\"http://localhost:8000/api/llm\", json={\n",
    "    \"auth\": {\n",
    "\t\t\"api_key\": API_KEY_1\n",
    "\t}, \n",
    "    \"question\": \"What is the Riemann-Roch theorem?\",\n",
    "    \n",
    "})\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "ALL_RESPONSES[\"llm_static\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `llm` [Structured Output]\n",
    "\n",
    "Call an LLM with typescript/pydantic scheme enforcement on the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_scheme = \"\"\"\n",
    "type User = {\n",
    "    name: string;\n",
    "    age: number;\n",
    "    isActive: boolean;\n",
    "};\n",
    "\"\"\"\n",
    "\n",
    "response = requests.get(f\"http://localhost:8000/api/llm\", json={\n",
    "    \"auth\": {\"api_key\": API_KEY_1},\n",
    "    \"model_parameters\": {\n",
    "        \"grammar\": [\"typescript\", ts_scheme]\n",
    "    },\n",
    "    \"question\": \"Give me a current NBA player. Respond as a JSON.\",\n",
    "})\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "if \"trace\" in result:\n",
    "\tprint(result[\"trace\"])\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "ALL_RESPONSES[\"llm_structured_output\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `llm` [Regex Output]\n",
    "\n",
    "Call an LLM with response being forced to a provided regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_scheme = r'(0?[1-9]|1[0-2])\\/(0?[1-9]|1\\d|2\\d|3[01])\\/(19|20)\\d{2}'\n",
    "# regex_scheme = r'(.*?)'\n",
    "\n",
    "response = requests.get(f\"http://localhost:8000/api/llm\", json={\n",
    "    \"auth\": {\"api_key\": API_KEY_1},\n",
    "    \"model_parameters\": {\n",
    "        \"grammar\": [\"regex\", regex_scheme],\n",
    "        # \"max_tokens\": 100\n",
    "    },\n",
    "    \"question\": \"Who is Oda? Write it as a JSON.\",\n",
    "})\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "if \"trace\" in result:\n",
    "\tprint(result[\"trace\"])\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "ALL_RESPONSES[\"llm_regex_output\"] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json, time\n",
    "\n",
    "\n",
    "response = requests.get(f\"http://localhost:8000/api/llm\", json={\n",
    "    \"auth\": {\"api_key\": API_KEY_1},\n",
    "    \"question\": \"What is the Riemann-Roch theorem?\"\n",
    "}, stream=True)\n",
    "response.raise_for_status()\n",
    "response_completed = \"\"\n",
    "start_time, token_count = time.time(), 0\n",
    "for chunk_raw in response.iter_content(chunk_size=None, decode_unicode=True):\n",
    "    chunk_decoded = chunk_raw\n",
    "    print(chunk_decoded)\n",
    "    chunk : dict = json.loads(chunk_decoded)\n",
    "    # print(chunk[\"result\"].keys())\n",
    "    \n",
    "    response_completed += chunk[\"result\"][\"output\"]\n",
    "    print(chunk[\"result\"][\"output\"], end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `llm_isolate_question`\n",
    "\n",
    "Extract and isolate the most recent request from a chat history.\n",
    "Very useful for RAG, so that context can be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json, time\n",
    "\n",
    "\n",
    "e_1 = \"\"\"\n",
    "Which theorem allows us to measure the extent to which the fundamental theorem of calculus fails at high dimensional manifolds?\n",
    "\"\"\".strip()\n",
    "\n",
    "e_2 = \"\"\"\n",
    "The theorem you're referring to is likely the **Asymptotic Formula** or **Logarithmic Correction**, also known as the **Gaussian Integral Asymptotics**.\n",
    "\n",
    "This result provides an estimate on how well the Fundamental Theorem of Calculus (FTC) approximates the integral of a function over a high-dimensional manifold. Specifically, it shows that the FTC's error grows logarithmically with the dimensionality of the manifold.\n",
    "\n",
    "In more detail, let's consider a compact Riemannian manifold M of dimension n. Suppose we have a smooth function f on M. Then, the asymptotic formula states that:\n",
    "\n",
    "$$\\int_M f(x) dx = \\frac{1}{(2\\pi)^{\\frac{n}{2}}} \\int_{\\mathbb{R}^n} f(\\exp_x(y)) J_y dy + O(n^{-1})$$\n",
    "\n",
    "Here, exp_x is the exponential map from the tangent space TxM to M, J_y denotes the Jacobian determinant of this map evaluated at y, and O(n^-1) represents the leading-order term in the large-n expansion.\n",
    "\n",
    "This result shows that the FTC approximation becomes increasingly inaccurate as the dimension n increases. The logarithmic correction term captures this failure of the FTC at high dimensions.\n",
    "\n",
    "Keep in mind that this result has important implications in various areas, such as differential geometry, geometric analysis, and machine learning, where high-dimensional data often arises naturally.\n",
    "\n",
    "Would you like me to elaborate on this topic further or provide references for those interested in exploring the subject in greater depth?\n",
    "\"\"\".strip()\n",
    "\n",
    "e_3 = \"\"\"\n",
    "Tell me more about FTC.\n",
    "\"\"\".strip()\n",
    "\n",
    "e_4 = \"\"\"\n",
    "**The Fundamental Theorem of Calculus (FTC)** is one of the most important and influential results in mathematical history. It establishes a deep connection between two branches of calculus: **differential calculus**, which deals with rates of change and slopes of curves, and **integral calculus**, which studies accumulation of quantities.\n",
    "\n",
    "### Statement of the FTC\n",
    "\n",
    "Let f(x) be a continuous function on [a,b] and let F(x) be the antiderivative of f(x). Then:\n",
    "\n",
    "$$\\int_{a}^{b}f(x)dx=F(b)-F(a)$$\n",
    "\n",
    "In other words, the definite integral of a function can be evaluated by computing the difference between its antiderivative at the upper limit and lower limit.\n",
    "\n",
    "### Underlying Principles\n",
    "\n",
    "1. **Antiderivatives**: The FTC relies heavily on the concept of an antiderivative, which is a function that, when differentiated, returns the original function. Antiderivatives play a crucial role in evaluating definite integrals.\n",
    "2. **Chain Rule**: The chain rule from differential calculus allows us to differentiate composite functions. This is essential in relating derivatives to indefinite integrals.\n",
    "3. **Fundamental Principle of Integration**: This principle states that if F(x) is an antiderivative of f(x), then $\\frac{d}{dx}(c+F(x))=c+f(x)$ for any constant c. This helps connect indefinite integration with definite integration.\n",
    "\n",
    "### Applications of the FTC\n",
    "\n",
    "1. **Area under Curves**: The FTC enables us to calculate the area under curves using definite integrals, making it a powerful tool in physics, engineering, economics, and many other fields.\n",
    "2. **Volume of Solids**: By integrating volumes of solids bounded by surfaces described by functions, we can compute their total volume or surface area.\n",
    "3. **Work and Energy**: In mechanics, the FTC helps determine work done by forces acting along a path, leading to insights into energy transfer and conservation.\n",
    "4. **Optimization Problems**: The FTC is used to solve optimization problems involving maximums or minimums of functions, such as finding the shortest distance or the maximum value of a function.\n",
    "5. **Physics and Engineering**: The FTC has numerous applications in these fields, including modeling population growth, electrical circuits, and fluid dynamics.\n",
    "\n",
    "### Historical Significance\n",
    "\n",
    "The FTC was first formulated by Sir Isaac Newton and German mathematician Gottfried Wilhelm Leibniz independently in the late 17th century. Their work laid the foundation for calculus as we know it today, revolutionizing mathematics, science, and engineering.\n",
    "\n",
    "I hope this introduction to the Fundamental Theorem of Calculus has sparked your interest! Do you have any specific questions or topics related to the FTC you'd like me to elaborate on?\n",
    "\"\"\".strip()\n",
    "\n",
    "e_5 = \"\"\"\n",
    "Who discovered it?\n",
    "\"\"\".strip()\n",
    "\n",
    "e_6 = \"\"\"\n",
    "The discovery of the Fundamental Theorem of Calculus (FTC) is attributed to both Sir Isaac Newton and German mathematician Gottfried Wilhelm Leibniz, who developed calculus independently of each other in the late 17th century.\n",
    "\n",
    "**Isaac Newton's Contribution**\n",
    "\n",
    "Newton developed his method of fluxions, which is equivalent to modern-day differentiation. He recognized that the derivative of a position function represents velocity and the second derivative represents acceleration. His work on calculus appeared in his book \"Method of Fluxions\" in 1671.\n",
    "\n",
    "However, Newton did not publish his findings until much later, in 1736, when they were included in his famous book \"Philosophiæ Naturalis Principia Mathematica\". Even then, his work remained largely unknown outside England.\n",
    "\n",
    "**Gottfried Wilhelm Leibniz' Contribution**\n",
    "\n",
    "Leibniz, on the other hand, published his work on calculus in 1684, introducing the notation of dx and dy for infinitesimal changes in x and y, respectively. He also introduced the notation of the integral sign ∫, which is still widely used today.\n",
    "\n",
    "Leibniz communicated his discoveries to the Royal Academy of Sciences in Paris, where they gained popularity among European mathematicians. As a result, he is often credited with being the first to publish the fundamental theorem of calculus.\n",
    "\n",
    "**Collaboration and Controversy**\n",
    "\n",
    "Although both Newton and Leibniz worked independently, there is evidence suggesting that they may have influenced each other's work indirectly through correspondence with common acquaintances. However, the exact nature of their collaboration remains unclear due to limited documentation.\n",
    "\n",
    "A bitter dispute over priority and credit for the invention of calculus ensued between Newton and Leibniz, with some mathematicians siding with Newton and others with Leibniz. Today, both men are acknowledged as co-developers of calculus, and their contributions continue to shape our understanding of the world around us.\n",
    "\n",
    "Would you like to explore more about the development of calculus or its applications?\n",
    "\"\"\"\n",
    "\n",
    "e_7 = \"\"\"\n",
    "What is a recursive neural network? How does it compare to LSTMs?\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "TEST_CHAT_HISTORY = [\n",
    "    # {\"role\": \"user\", \"content\": \"Where is Afghanistan?\"},\n",
    "    # {\"role\": \"assistant\", \"content\": \"Afghanistan is located in south-central Asia\"},\n",
    "    # {\"role\": \"user\", \"content\": \"What is the capital?\"},\n",
    "    {\"role\": \"user\", \"content\": e_1},\n",
    "    {\"role\": \"assistant\", \"content\": e_2},\n",
    "    {\"role\": \"user\", \"content\": e_3},\n",
    "    {\"role\": \"assistant\", \"content\": e_4},\n",
    "    {\"role\": \"user\", \"content\": e_5},\n",
    "    {\"role\": \"assistant\", \"content\": e_6},\n",
    "    {\"role\": \"user\", \"content\": e_7},\n",
    "]\n",
    "print(TEST_CHAT_HISTORY[-1])\n",
    "\n",
    "response = requests.get(f\"http://localhost:8000/api/llm_isolate_question\", json={\n",
    "    \"auth\": {\"api_key\": API_KEY_1},\n",
    "    \"chat_history\": TEST_CHAT_HISTORY\n",
    "}, stream=False)\n",
    "response.raise_for_status()\n",
    "result = response.json()\n",
    "\n",
    "print(result)\n",
    "\n",
    "if \"error\" in result:\n",
    "    print(result[\"error\"])\n",
    "    print(result[\"trace\"])\n",
    "    \n",
    "ALL_RESPONSES[\"llm_isolate_question\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `llm_multistep_search`\n",
    "\n",
    "Connects an LLM to RAG search with tooling, and allows it to search until it finds the necessary information.\n",
    "\n",
    "Currently being refactored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, textwrap\n",
    "\n",
    "response = requests.get(f\"http://localhost:8000/api/llm_multistep_search\", json={\n",
    "    \"auth\": {\"api_key\": API_KEY_1},\n",
    "    \"chat_history\": TEST_CHAT_HISTORY,\n",
    "    \"collection_ids\": [COLLECTION_ARGS[\"hash_id\"]],\n",
    "    \"max_searches\": 2,\n",
    "    # \"search_web\": True\n",
    "}, stream=False)\n",
    "response.raise_for_status()\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "\n",
    "if \"error\" in result:\n",
    "    print(result[\"error\"])\n",
    "    print(result[\"trace\"])\n",
    "else:\n",
    "    result = result[\"result\"]\n",
    "    for r in result[\"sources\"]:\n",
    "        # print(json.dumps(r, indent=4))\n",
    "        if \"text\" in r:\n",
    "            print(textwrap.fill(r[\"text\"].replace(\"\\n\", \"\"), width=100), end=\"\\n\\n\")\n",
    "    for command in result[\"commands\"]:\n",
    "        print(command)\n",
    "\n",
    "ALL_RESPONSES[\"llm_multistep_search\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `llm_make_conversation_title`\n",
    "\n",
    "Come up with a conversation title from chat history using an LLM.\n",
    "Used to create chat labels for the sidebar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(f\"http://localhost:8000/api/llm_make_conversation_title\", json={\n",
    "    \"auth\": {\"api_key\": API_KEY_1},\n",
    "    \"chat_history\": TEST_CHAT_HISTORY\n",
    "}, stream=False)\n",
    "response.raise_for_status()\n",
    "result = response.json()\n",
    "\n",
    "print(result)\n",
    "\n",
    "if \"error\" in result:\n",
    "    print(result[\"error\"])\n",
    "    print(result[\"trace\"])\n",
    "    \n",
    "ALL_RESPONSES[\"llm_make_conversation_title\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `llm_count_tokens`\n",
    "\n",
    "Count the tokens for a given string using the tokenizer of a given model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json, time\n",
    "\n",
    "\n",
    "response = requests.get(f\"http://localhost:8000/api/llm_count_tokens\", json={\n",
    "    \"auth\": {\"api_key\": API_KEY_1},\n",
    "    \"model_id\": \"llama-3.1-8b-instruct\",\n",
    "    \"input_string\": \"Where is Afghanistan?\"\n",
    "}, stream=False)\n",
    "response.raise_for_status()\n",
    "result = response.json()\n",
    "\n",
    "print(result)\n",
    "\n",
    "if \"error\" in result:\n",
    "    print(result[\"error\"])\n",
    "    print(result[\"trace\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `rerank`\n",
    "\n",
    "Call a reranker model to rate the answer relevance of question-answer pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from threading import Thread\n",
    "import time, json\n",
    "from copy import deepcopy\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "prompts_rerank = [\n",
    "    [\n",
    "        [\"What is the square root of 169?\", \"The square root of 169 is 13.\"],\n",
    "        [\"What is the derivative of sin(cos(x))?\", \"What is the derivative of sin(cos(x))? Well, it's a bit complicated. The derivative of sin(cos(x)) is cos(cos(x)) * -sin(x).\"],\n",
    "    ], [\n",
    "        [\"What is the square root of 169?\", \"cupcake\"],\n",
    "        [\"What is the derivative of sin(cos(x))?\", \"math\"],\n",
    "        [\"What is the square root of 169?\", \"math\"],\n",
    "        [\"What is the derivative of sin(cos(x))?\", \"math\"],\n",
    "    ]\n",
    "]\n",
    "\n",
    "def get_response(prompt_input):\n",
    "    \n",
    "    # nonlocal ALL_RESPONSES\n",
    "    print(\"Get response with:\", prompt_input)\n",
    "    input = {\"auth\": {\"api_key\": API_KEY_1}}\n",
    "    input.update({\n",
    "        \"inputs\": prompt_input\n",
    "    })\n",
    "    \n",
    "    time_start = time.time()\n",
    "    response = requests.get(f\"http://localhost:8000/api/rerank\", json=input)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    response_value = response.json()\n",
    "    print(response_value)\n",
    "    ALL_RESPONSES[\"rerank\"] = response_value\n",
    "    response_value = response_value[\"result\"]\n",
    "    time_end = time.time()\n",
    "    time_taken = time_end - time_start\n",
    "    \n",
    "    assert not (\"success\" in response_value and response_value[\"success\"] == False), response_value[\"error\"]\n",
    "    print(\"FINISHED RESPONSE in %5.2fs:\" % (time_taken), [prompt_input, response_value])\n",
    "\n",
    "print(\"RUNNING RERANK\")\n",
    "# for p in prompts_rerank:\n",
    "#     # time.sleep(0.5)\n",
    "#     Thread(target=get_response, args=(p,)).start()\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    executor.map(get_response, prompts_rerank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `embedding`\n",
    "\n",
    "Call a text to vector embedding model like BGE-M3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from threading import Thread\n",
    "import time, json\n",
    "from copy import deepcopy\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "prompts_embeddings = [\n",
    "    [\n",
    "        \"What is the square root of 169?\",\n",
    "        \"What is the derivative of sin(cos(x))?\",\n",
    "    ], [\n",
    "        \"What is the square root of 169?\",\n",
    "        \"What is the derivative of sin(cos(x))?\",\n",
    "        \"What is the square root of 169?\",\n",
    "        \"What is the derivative of sin(cos(x))?\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "def get_response_embeddings(prompt_input):\n",
    "    # nonlocal ALL_RESPONSES\n",
    "    \n",
    "    time_start = time.time()\n",
    "    # input = deepcopy({USER_ARGS_1})\n",
    "    input = {\"auth\": {\"api_key\": API_KEY_1}}\n",
    "    input.update({\n",
    "        \"inputs\": prompt_input\n",
    "    })\n",
    "    \n",
    "    response = requests.get(f\"http://localhost:8000/api/embedding\", json=input)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    response_value = response.json()\n",
    "    ALL_RESPONSES[\"embedding\"] = result\n",
    "    response_value = response_value[\"result\"]\n",
    "    time_end = time.time()\n",
    "    time_taken = time_end - time_start\n",
    "    print(response_value)\n",
    "    \n",
    "    print(\"FINISHED RESPONSE in %5.2fs:\" % (time_taken), [prompt_input, len(response_value), len(response_value[0])])\n",
    "\n",
    "# for p in prompts_embeddings:\n",
    "#     # time.sleep(0.5)\n",
    "#     Thread(target=get_response_embeddings, args=(p,)).start()\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    executor.map(get_response_embeddings, prompts_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `get_usage_tally`\n",
    "\n",
    "Get the recent model usage stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(f\"http://localhost:8000/api/get_usage_tally\", json={\n",
    "    \"auth\": {\"api_key\": API_KEY_1},\n",
    "    \"window\": \"day\",\n",
    "    \"start_timestamp\": 1722470400,\n",
    "    \"end_timestamp\": int(time.time())+1000\n",
    "}, stream=False)\n",
    "response.raise_for_status()\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "\n",
    "if \"error\" in result:\n",
    "    print(result[\"error\"])\n",
    "    print(result[\"trace\"])\n",
    "    \n",
    "ALL_RESPONSES[\"get_usage_tally\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toolchains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `get_available_toolchains`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/get_available_toolchains\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "ALL_RESPONSES[\"get_available_toolchains\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `fetch_toolchain_sessions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/fetch_toolchain_sessions\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "ALL_RESPONSES[\"fetch_toolchain_sessions\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ Toolchain Static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from websockets.sync.client import connect, Connection\n",
    "from copy import deepcopy\n",
    "import time\n",
    "from typing import List, Union, Any\n",
    "from toolchain_efficient_receiver import wait_for_command_finish\n",
    "\n",
    "model_params_static = {\n",
    "    # \"model_choice\": \"mistral-7b-instruct-v0.1\",\n",
    "    \"max_tokens\": 1000,\n",
    "    \"temperature\": 0.1,\n",
    "    \"top_p\": 0.1, \n",
    "    \"repetition_penalty\": 1.15,\n",
    "    \"include_stop_str_in_output\": True\n",
    "}\n",
    "\n",
    "toolchain_id = \"test_chat_session_normal\"\n",
    "\n",
    "# Append, update, delete. In that order.\n",
    "WS_STATE_GLOBAL = {}\n",
    "\n",
    "with connect(\"ws://localhost:8000/toolchain\") as websocket:\n",
    "    \n",
    "    input = deepcopy(USER_ARGS_1)\n",
    "    input.update({\n",
    "        \"command\" : \"toolchain/create\",\n",
    "        \"arguments\": {\n",
    "            \"toolchain_id\": toolchain_id\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    websocket.send(json.dumps(input))\n",
    "    print(\"\\n\\n\")\n",
    "   \n",
    "    result_1, WS_STATE_GLOBAL = await wait_for_command_finish(websocket, WS_STATE_GLOBAL)\n",
    "    print(\"RESULT 1\")\n",
    "    print(json.dumps(result_1, indent=4))\n",
    "    \n",
    "    session_id = result_1[\"toolchain_session_id\"]\n",
    "    \n",
    "    input = deepcopy(USER_ARGS_1)\n",
    "    input.update({\n",
    "        \"command\" : \"toolchain/event\",\n",
    "        \"arguments\": {\n",
    "            \"session_id\": session_id,\n",
    "            \"event_node_id\": \"user_question_event\",\n",
    "            \"event_parameters\": {\n",
    "                \n",
    "                \"model_parameters\": model_params_static,\n",
    "                \"question\": \"What is the Riemann-Roch theorem?\"\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    websocket.send(json.dumps(input))\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    result_2, WS_STATE_GLOBAL = await wait_for_command_finish(websocket, WS_STATE_GLOBAL)\n",
    "    print(\"RESULT 2\")\n",
    "    print(json.dumps(result_2, indent=4))\n",
    "    \n",
    "    \n",
    "    input = deepcopy(USER_ARGS_1)\n",
    "    input.update({\n",
    "        \"command\" : \"toolchain/event\",\n",
    "        \"arguments\": {\n",
    "            \"session_id\": session_id,\n",
    "            \"event_node_id\": \"user_question_event\",\n",
    "            \"event_parameters\": {\n",
    "                \"model_parameters\": model_params_static,\n",
    "                \"question\": \"Who are the two people the Riemann-Roch Theorem is named after?\" \n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    websocket.send(json.dumps(input))\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    result_3, WS_STATE_GLOBAL = await wait_for_command_finish(websocket, WS_STATE_GLOBAL)\n",
    "    print(\"RESULT 3\")\n",
    "    print(json.dumps(result_3, indent=4))\n",
    "    \n",
    "    \n",
    "    input = deepcopy(USER_ARGS_1)\n",
    "    input.update({\n",
    "        \"command\" : \"toolchain/event\",\n",
    "        \"arguments\": {\n",
    "            \"session_id\": session_id,\n",
    "            \"event_node_id\": \"user_question_event\",\n",
    "            \"event_parameters\": {\n",
    "                \"model_parameters\": model_params_static,\n",
    "                \"question\": \"You're wrong. It was named after Gustav Roch.\"\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    websocket.send(json.dumps(input))\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    result_4, WS_STATE_GLOBAL = await wait_for_command_finish(websocket, WS_STATE_GLOBAL)\n",
    "    print(\"RESULT 4\")\n",
    "    print(json.dumps(result_4, indent=4))\n",
    "    \n",
    "    \n",
    "    print(\"\\n\\nFINAL TOOLCHAIN STATE\")\n",
    "    print(json.dumps(WS_STATE_GLOBAL, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ Toolchain Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from websockets.sync.client import connect, Connection\n",
    "from copy import deepcopy\n",
    "import time\n",
    "from typing import List, Union, Any\n",
    "from toolchain_efficient_receiver import wait_for_command_finish\n",
    "\n",
    "model_params_static = {\n",
    "    # \"model_choice\": \"mistral-7b-instruct-v0.1\",\n",
    "    # \"stream\": True, \n",
    "    # \"stream_response_normal\": True,\n",
    "    \"max_tokens\": 200, \n",
    "    \"temperature\": 0.1, \n",
    "    \"top_p\": 0.1, \n",
    "    \"repetition_penalty\": 1.15,\n",
    "    \"stop\": [\"<|im_end|>\"],\n",
    "    \"include_stop_str_in_output\": True\n",
    "}\n",
    "\n",
    "toolchain_id = \"test_chat_session_normal_streaming\"\n",
    "\n",
    "# Append, update, delete. In that order.\n",
    "WS_STATE_GLOBAL = {}\n",
    "\n",
    "with connect(\"ws://localhost:8000/toolchain\") as websocket:\n",
    "    \n",
    "    input = {\"auth\": {\"api_key\": API_KEY_1}}\n",
    "    input.update({\n",
    "        \"command\" : \"toolchain/create\",\n",
    "        \"arguments\": {\n",
    "            \"toolchain_id\": toolchain_id\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    websocket.send(json.dumps(input))\n",
    "    print(\"\\n\\n\")\n",
    "   \n",
    "    result_1, WS_STATE_GLOBAL = await wait_for_command_finish(websocket, WS_STATE_GLOBAL)\n",
    "    \n",
    "    session_id = result_1[\"toolchain_session_id\"]\n",
    "    \n",
    "    input = {\"auth\": {\"api_key\": API_KEY_1}}\n",
    "    input.update({\n",
    "        \"command\" : \"toolchain/event\",\n",
    "        \"arguments\": {\n",
    "            \"session_id\": session_id,\n",
    "            \"event_node_id\": \"user_question_event\",\n",
    "            \"event_parameters\": {\n",
    "                \n",
    "                \"model_parameters\": model_params_static,\n",
    "                \"question\": \"What is the Riemann-Roch theorem?\"\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    websocket.send(json.dumps(input))\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    result_2, WS_STATE_GLOBAL = await wait_for_command_finish(websocket, WS_STATE_GLOBAL)\n",
    "    \n",
    "    \n",
    "    input = {\"auth\": {\"api_key\": API_KEY_1}}\n",
    "    input.update({\n",
    "        \"command\" : \"toolchain/event\",\n",
    "        \"arguments\": {\n",
    "            \"session_id\": session_id,\n",
    "            \"event_node_id\": \"make_conversation_title\",\n",
    "            \"event_parameters\": {\n",
    "                \n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    websocket.send(json.dumps(input))\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    result_1_5, WS_STATE_GLOBAL = await wait_for_command_finish(websocket, WS_STATE_GLOBAL)\n",
    "    \n",
    "    \n",
    "    input = {\"auth\": {\"api_key\": API_KEY_1}}\n",
    "    input.update({\n",
    "        \"command\" : \"toolchain/event\",\n",
    "        \"arguments\": {\n",
    "            \"session_id\": session_id,\n",
    "            \"event_node_id\": \"user_question_event\",\n",
    "            \"event_parameters\": {\n",
    "                \"model_parameters\": model_params_static,\n",
    "                \"question\": \"Who are the two people the Riemann-Roch Theorem is named after?\" \n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    websocket.send(json.dumps(input))\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    result_3, WS_STATE_GLOBAL = await wait_for_command_finish(websocket, WS_STATE_GLOBAL)\n",
    "    \n",
    "    input = {\"auth\": {\"api_key\": API_KEY_1}}\n",
    "    input.update({\n",
    "        \"command\" : \"toolchain/event\",\n",
    "        \"arguments\": {\n",
    "            \"session_id\": session_id,\n",
    "            \"event_node_id\": \"user_question_event\",\n",
    "            \"event_parameters\": {\n",
    "                \"model_parameters\": model_params_static,\n",
    "                \"question\": \"You're wrong. It was named after Gustav Roch.\"\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    websocket.send(json.dumps(input))\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    result_4, WS_STATE_GLOBAL = await wait_for_command_finish(websocket, WS_STATE_GLOBAL)\n",
    "    \n",
    "    print(\"\\n\\nFINAL TOOLCHAIN STATE\")\n",
    "    print(json.dumps(WS_STATE_GLOBAL, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ Toolchain Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from websockets.sync.client import connect, Connection\n",
    "from copy import deepcopy\n",
    "import time\n",
    "from typing import List, Union, Any\n",
    "from toolchain_efficient_receiver import wait_for_command_finish\n",
    "\n",
    "model_params_static = {\n",
    "    # \"model_choice\": \"mistral-7b-instruct-v0.1\",\n",
    "    \"max_tokens\": 1000, \n",
    "    \"temperature\": 0.1, \n",
    "    \"top_p\": 0.1, \n",
    "    \"repetition_penalty\": 1.15,\n",
    "    # \"stop\": [\"<|im_end|>\"],\n",
    "    \"include_stop_str_in_output\": True\n",
    "}\n",
    "\n",
    "toolchain_id = \"iterable_test\"\n",
    "\n",
    "# Append, update, delete. In that order.\n",
    "WS_STATE_GLOBAL_2 = {}\n",
    "\n",
    "with connect(\"ws://localhost:8000/toolchain\") as websocket:\n",
    "    \n",
    "    input = {\"auth\": {\"api_key\": API_KEY_1}}\n",
    "    input.update({\n",
    "        \"command\" : \"toolchain/create\",\n",
    "        \"arguments\": {\n",
    "            \"toolchain_id\": toolchain_id\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    websocket.send(json.dumps(input))\n",
    "    print(\"\\n\\n\")\n",
    "   \n",
    "    result_1, WS_STATE_GLOBAL_2 = await wait_for_command_finish(websocket, WS_STATE_GLOBAL_2)\n",
    "    print(\"RESULT 1\")\n",
    "    print(json.dumps(result_1, indent=4))\n",
    "    \n",
    "    \n",
    "    session_id = result_1[\"toolchain_session_id\"]\n",
    "    \n",
    "    input = deepcopy(USER_ARGS_1)\n",
    "    input.update({\n",
    "        \"command\" : \"toolchain/event\",\n",
    "        \"arguments\": {\n",
    "            \"session_id\": session_id,\n",
    "            \"event_node_id\": \"user_question_event\",\n",
    "            \"event_parameters\": {\n",
    "                \"model_parameters\": model_params_static\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    websocket.send(json.dumps(input))\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    result_2, WS_STATE_GLOBAL_2 = await wait_for_command_finish(websocket, WS_STATE_GLOBAL_2)\n",
    "    print(\"RESULT 2\")\n",
    "    print(json.dumps(result_2, indent=4))\n",
    "    print(\"END RESULT 2\")\n",
    "    \n",
    "    print(\"\\n\\nFINAL TOOLCHAIN STATE\")\n",
    "    print(json.dumps(WS_STATE_GLOBAL_2, indent=4))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ Toolchain File Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from websockets.sync.client import connect, Connection\n",
    "from copy import deepcopy\n",
    "import time, json\n",
    "from typing import List, Union, Any\n",
    "from toolchain_efficient_receiver import wait_for_command_finish\n",
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "auth_args = {\"auth\": {\"api_key\": API_KEY_1}}\n",
    "\n",
    "if True: # File handling was changed recently.\n",
    "\ttoolchain_id = \"test_file_upload\"\n",
    "\n",
    "\t# Append, update, delete. In that order.\n",
    "\tWS_STATE_GLOBAL_2 = {}\n",
    "\n",
    "\twebsocket = connect(\"ws://localhost:8000/toolchain\")\n",
    "\t\t\n",
    "\tinput = deepcopy(auth_args)\n",
    "\tinput.update({\n",
    "\t\t\"command\" : \"toolchain/create\",\n",
    "\t\t\"arguments\": {\n",
    "\t\t\t\"toolchain_id\": toolchain_id\n",
    "\t\t}\n",
    "\t})\n",
    "\n",
    "\twebsocket.send(json.dumps(input))\n",
    "\tprint(\"\\n\\n\")\n",
    "\n",
    "\tresult_1, WS_STATE_GLOBAL_2 = await wait_for_command_finish(websocket, WS_STATE_GLOBAL_2)\n",
    "\tprint(\"RESULT 1\")\n",
    "\tprint(json.dumps(result_1, indent=4))\n",
    "\n",
    "\ttoolchain_session_id = result_1[\"toolchain_session_id\"]\n",
    "\n",
    "\t\n",
    "\n",
    "\tinput = deepcopy(auth_args)\n",
    "\tinput.update({\n",
    "\t\t\"collection_hash_id\": toolchain_session_id,\n",
    "\t\t\"collection_type\" : \"toolchain_session\"\n",
    "\t})\n",
    "\n",
    "\tencoded_params = urlencode({\"parameters\": json.dumps(input)})\n",
    "\n",
    "\tfor i, path in enumerate([PDF_TO_UPLOAD_PATH]):\n",
    "\t\twith open(path, 'rb') as f:\n",
    "\t\t\t# Define the files parameter for the POST request\n",
    "\t\t\tfiles = {'file': f}\n",
    "\t\t\tinput_json = json.dumps(input)\n",
    "\t\t\tresponse = requests.post(\"http://localhost:8000/upload_document?\"+encoded_params, files=files)\n",
    "\t\t\tresponse.raise_for_status()\n",
    "\n",
    "\t\t\tresult = response.json()\n",
    "\t\t\tf.close()\n",
    "\n",
    "\t\t\tprint(json.dumps(result, indent=4))\n",
    "\t\t\t\n",
    "\t\t\tdocument_hash_id = result[\"result\"][\"hash_id\"]\n",
    "\t\n",
    "\tinput = deepcopy(auth_args)\n",
    "\tinput.update({\n",
    "\t\t\"command\" : \"toolchain/event\",\n",
    "\t\t\"arguments\": {\n",
    "\t\t\t\"session_id\": toolchain_session_id,\n",
    "\t\t\t\"event_node_id\": \"user_file_upload_event\",\n",
    "\t\t\t\"event_parameters\": {\n",
    "\t\t\t\t\"file_upload\": {\n",
    "\t\t\t\t\t\"type\": \"<<||TOOLCHAIN_SESSION_FILE||>>\",\n",
    "\t\t\t\t\t\"document_hash_id\": document_hash_id\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t})\n",
    "\n",
    "\twebsocket.send(json.dumps(input))\n",
    "\tprint(\"\\n\\n\")\n",
    "\t\n",
    "\tresult_2, WS_STATE_GLOBAL_2 = await wait_for_command_finish(websocket, WS_STATE_GLOBAL_2)\n",
    "\tprint(\"RESULT 2\")\n",
    "\tprint(json.dumps(result_2, indent=4))\n",
    "\tprint(\"END RESULT 2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `get_usage_tally`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(f\"http://localhost:8000/api/get_usage_tally\", json={\n",
    "    \"auth\": {\"api_key\": API_KEY_1},\n",
    "    \"window\": \"day\",\n",
    "    \"start_timestamp\": 1722470400,\n",
    "    \"end_timestamp\": int(time.time())+1000\n",
    "}, stream=False)\n",
    "response.raise_for_status()\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "\n",
    "if \"error\" in result:\n",
    "    print(result[\"error\"])\n",
    "    print(result[\"trace\"])\n",
    "    \n",
    "ALL_RESPONSES[\"get_usage_tally\"] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open(\"responses.json\", \"w\") as f:\n",
    "# \tjson.dump(ALL_RESPONSES, f, indent=4)\n",
    "# \tf.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QL_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
