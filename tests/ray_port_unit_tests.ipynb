{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Functions to Test\n",
    "\n",
    "### User Auth\n",
    "* `add_user`\n",
    "* `login`\n",
    "* `get_available_models`\n",
    "* `set_user_openai_api_key`\n",
    "* `set_organization_openai_id`\n",
    "* `get_openai_api_key`\n",
    "\n",
    "### Collections\n",
    "* `fetch_document_collections_belonging_to`\n",
    "* `create_document_collection`\n",
    "* `fetch_all_collections`\n",
    "* `fetch_collection`\n",
    "* `modify_document_collection`\n",
    "\n",
    "### Documents\n",
    "* `upload_document`\n",
    "* `delete_document`\n",
    "* `get_document_secure`\n",
    "* `query_vector_db`\n",
    "* `craft_document_access_token`\n",
    "* `fetch_document`\n",
    "\n",
    "### Organizations\n",
    "* `create_organization`\n",
    "* `invite_user_to_organization`\n",
    "* `resolve_organization_invitation`\n",
    "* `fetch_memberships`\n",
    "* `fetch_memberships_of_organization`\n",
    "\n",
    "### Web Search\n",
    "* `set_user_serp_key`\n",
    "* `set_organization_serp_key`\n",
    "* `get_serp_key`\n",
    "* `search_google`\n",
    "* `perform_search_query`\n",
    "\n",
    "### Toolchains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USERNAME_1: cfe61aa6-c92f-4f6c-a17e-5bffe910\n",
      "USERNAME_2: 215a4c31-8b8d-471e-b187-fa3641c8\n",
      "PASSWORD_1: 67022e2a-623b-4afd-859f-7fcadb5f\n",
      "PASSWORD_2: f6e5d779-4a6c-4031-ad6b-534085a8\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "# Generate a random UUID\n",
    "\n",
    "\n",
    "USERNAME_1 = str(uuid.uuid4())[:32]\n",
    "USERNAME_2 = str(uuid.uuid4())[:32]\n",
    "\n",
    "PASSWORD_1 = str(uuid.uuid4())[:32]\n",
    "PASSWORD_2 = str(uuid.uuid4())[:32]\n",
    "\n",
    "PDF_TO_UPLOAD_PATH = '/home/kmccleary/projects/other/HNRS3035_08_22_2023_MLIntro.pdf'\n",
    "MD_FILE_TO_UPLOAD_PATH = '/home/kmccleary/projects/other/Primary_2.md'\n",
    "LARGE_PDF_TO_UPLOAD_PATH = '/home/kmccleary/projects/other/stats_book.pdf'\n",
    "\n",
    "print(f'USERNAME_1: {USERNAME_1}')\n",
    "print(f'USERNAME_2: {USERNAME_2}')\n",
    "print(f'PASSWORD_1: {PASSWORD_1}')\n",
    "print(f'PASSWORD_2: {PASSWORD_2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `add_user`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"username\": \"cfe61aa6-c92f-4f6c-a17e-5bffe910\",\n",
      "        \"auth\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VybmFtZSI6ImNmZTYxYWE2LWM5MmYtNGY2Yy1hMTdlLTViZmZlOTEwIiwicHdkX2hhc2giOiJiN2FiYzkzNDA1MWIwM2QyODY3NjQ4MjAwYjZmNTMxNjljNmNkYWI2YjExMzBhMTU0NmQxMTUxZWYyNjU4Yjg0IiwiZXhwIjoxNzIwODk1Njc2fQ.XXgeQosFdZNzL7h44-u6Gsv8sQ5aV8_hLB1ZwIp4qhk\",\n",
      "        \"memberships\": [],\n",
      "        \"admin\": false,\n",
      "        \"available_models\": {\n",
      "            \"default_model\": \"llama-3-8b-instruct\",\n",
      "            \"local_models\": [\n",
      "                {\n",
      "                    \"name\": \"Mistral 7B Instruct\",\n",
      "                    \"id\": \"mistral-7b-instruct-v0.1\",\n",
      "                    \"modelcard\": \"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1\"\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"LLaMA 3 8B Instruct\",\n",
      "                    \"id\": \"llama-3-8b-instruct\",\n",
      "                    \"modelcard\": \"https://ai.meta.com/blog/meta-llama-3/\"\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"Mistral 7B Instruct (v0.3)\",\n",
      "                    \"id\": \"mistral-7b-instruct-v0.3\",\n",
      "                    \"modelcard\": \"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3\"\n",
      "                }\n",
      "            ],\n",
      "            \"external_models\": {\n",
      "                \"openai\": [\n",
      "                    {\n",
      "                        \"name\": \"GPT-4 Turbo\",\n",
      "                        \"id\": \"gpt-4-1106-preview\",\n",
      "                        \"context\": 128000,\n",
      "                        \"modelcard\": \"https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"GPT-3.5 Turbo\",\n",
      "                        \"id\": \"gpt-3.5-turbo-1106\",\n",
      "                        \"context\": 16384,\n",
      "                        \"modelcard\": \"https://platform.openai.com/docs/models/gpt-3-5\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        },\n",
      "        \"available_toolchains\": [\n",
      "            {\n",
      "                \"category\": \"Test\",\n",
      "                \"entries\": [\n",
      "                    {\n",
      "                        \"title\": \"Static Chat Test And Really Long Name\",\n",
      "                        \"id\": \"test_chat_session_normal\",\n",
      "                        \"category\": \"Test\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"title\": \"File Upload Test\",\n",
      "                        \"id\": \"test_file_upload\",\n",
      "                        \"category\": \"Test\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"title\": \"Iteration Test\",\n",
      "                        \"id\": \"iterable_test\",\n",
      "                        \"category\": \"Test\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"title\": \"Streaming Chat Test\",\n",
      "                        \"id\": \"test_chat_session_normal_streaming\",\n",
      "                        \"category\": \"Test\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"category\": \"Summarization\",\n",
      "                \"entries\": [\n",
      "                    {\n",
      "                        \"title\": \"Article Assistant\",\n",
      "                        \"id\": \"article_curation_search_agent\",\n",
      "                        \"category\": \"Summarization\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"default_toolchain\": {\n",
      "            \"title\": \"Streaming Chat Test\",\n",
      "            \"id\": \"test_chat_session_normal_streaming\",\n",
      "            \"category\": \"Test\"\n",
      "        },\n",
      "        \"user_set_providers\": [],\n",
      "        \"providers\": [\n",
      "            \"OpenAI\",\n",
      "            \"Anthropic\",\n",
      "            \"Serper.dev\"\n",
      "        ],\n",
      "        \"pending_email\": false\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"username\": \"215a4c31-8b8d-471e-b187-fa3641c8\",\n",
      "        \"auth\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VybmFtZSI6IjIxNWE0YzMxLThiOGQtNDcxZS1iMTg3LWZhMzY0MWM4IiwicHdkX2hhc2giOiI1Y2FlZGU0Y2E0YTM5ZjAyNWE5NzBmNjE3OTFiODU2NTJiNTkzNzNmYmNlYzljN2ExOGVmNjRkYjFmN2ZiYzE5IiwiZXhwIjoxNzIwODk1Njc2fQ.urn5jlsi6_zAU0bePJswRFXeiJCMfYw8nm8pLQz0Sws\",\n",
      "        \"memberships\": [],\n",
      "        \"admin\": false,\n",
      "        \"available_models\": {\n",
      "            \"default_model\": \"llama-3-8b-instruct\",\n",
      "            \"local_models\": [\n",
      "                {\n",
      "                    \"name\": \"Mistral 7B Instruct\",\n",
      "                    \"id\": \"mistral-7b-instruct-v0.1\",\n",
      "                    \"modelcard\": \"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1\"\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"LLaMA 3 8B Instruct\",\n",
      "                    \"id\": \"llama-3-8b-instruct\",\n",
      "                    \"modelcard\": \"https://ai.meta.com/blog/meta-llama-3/\"\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"Mistral 7B Instruct (v0.3)\",\n",
      "                    \"id\": \"mistral-7b-instruct-v0.3\",\n",
      "                    \"modelcard\": \"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3\"\n",
      "                }\n",
      "            ],\n",
      "            \"external_models\": {\n",
      "                \"openai\": [\n",
      "                    {\n",
      "                        \"name\": \"GPT-4 Turbo\",\n",
      "                        \"id\": \"gpt-4-1106-preview\",\n",
      "                        \"context\": 128000,\n",
      "                        \"modelcard\": \"https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"GPT-3.5 Turbo\",\n",
      "                        \"id\": \"gpt-3.5-turbo-1106\",\n",
      "                        \"context\": 16384,\n",
      "                        \"modelcard\": \"https://platform.openai.com/docs/models/gpt-3-5\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        },\n",
      "        \"available_toolchains\": [\n",
      "            {\n",
      "                \"category\": \"Test\",\n",
      "                \"entries\": [\n",
      "                    {\n",
      "                        \"title\": \"Static Chat Test And Really Long Name\",\n",
      "                        \"id\": \"test_chat_session_normal\",\n",
      "                        \"category\": \"Test\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"title\": \"File Upload Test\",\n",
      "                        \"id\": \"test_file_upload\",\n",
      "                        \"category\": \"Test\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"title\": \"Iteration Test\",\n",
      "                        \"id\": \"iterable_test\",\n",
      "                        \"category\": \"Test\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"title\": \"Streaming Chat Test\",\n",
      "                        \"id\": \"test_chat_session_normal_streaming\",\n",
      "                        \"category\": \"Test\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"category\": \"Summarization\",\n",
      "                \"entries\": [\n",
      "                    {\n",
      "                        \"title\": \"Article Assistant\",\n",
      "                        \"id\": \"article_curation_search_agent\",\n",
      "                        \"category\": \"Summarization\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"default_toolchain\": {\n",
      "            \"title\": \"Streaming Chat Test\",\n",
      "            \"id\": \"test_chat_session_normal_streaming\",\n",
      "            \"category\": \"Test\"\n",
      "        },\n",
      "        \"user_set_providers\": [],\n",
      "        \"providers\": [\n",
      "            \"OpenAI\",\n",
      "            \"Anthropic\",\n",
      "            \"Serper.dev\"\n",
      "        ],\n",
      "        \"pending_email\": false\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "\n",
    "add_user_input = {\n",
    "    \"username\": USERNAME_1,\n",
    "    \"password\": PASSWORD_1,\n",
    "}\n",
    "\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/add_user\", json=add_user_input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "add_user_input = {\n",
    "    \"username\": USERNAME_2,\n",
    "    \"password\": PASSWORD_2,\n",
    "}\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/add_user\", json=add_user_input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `login`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auth': {'username': 'cfe61aa6-c92f-4f6c-a17e-5bffe910', 'password': '67022e2a-623b-4afd-859f-7fcadb5f'}}\n",
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"username\": \"cfe61aa6-c92f-4f6c-a17e-5bffe910\",\n",
      "        \"auth\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VybmFtZSI6ImNmZTYxYWE2LWM5MmYtNGY2Yy1hMTdlLTViZmZlOTEwIiwicHdkX2hhc2giOiJiN2FiYzkzNDA1MWIwM2QyODY3NjQ4MjAwYjZmNTMxNjljNmNkYWI2YjExMzBhMTU0NmQxMTUxZWYyNjU4Yjg0IiwiZXhwIjoxNzIwODk1Njc2fQ.XXgeQosFdZNzL7h44-u6Gsv8sQ5aV8_hLB1ZwIp4qhk\",\n",
      "        \"memberships\": [],\n",
      "        \"admin\": false,\n",
      "        \"available_models\": {\n",
      "            \"default_model\": \"llama-3-8b-instruct\",\n",
      "            \"local_models\": [\n",
      "                {\n",
      "                    \"name\": \"Mistral 7B Instruct\",\n",
      "                    \"id\": \"mistral-7b-instruct-v0.1\",\n",
      "                    \"modelcard\": \"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1\"\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"LLaMA 3 8B Instruct\",\n",
      "                    \"id\": \"llama-3-8b-instruct\",\n",
      "                    \"modelcard\": \"https://ai.meta.com/blog/meta-llama-3/\"\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"Mistral 7B Instruct (v0.3)\",\n",
      "                    \"id\": \"mistral-7b-instruct-v0.3\",\n",
      "                    \"modelcard\": \"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3\"\n",
      "                }\n",
      "            ],\n",
      "            \"external_models\": {\n",
      "                \"openai\": [\n",
      "                    {\n",
      "                        \"name\": \"GPT-4 Turbo\",\n",
      "                        \"id\": \"gpt-4-1106-preview\",\n",
      "                        \"context\": 128000,\n",
      "                        \"modelcard\": \"https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"GPT-3.5 Turbo\",\n",
      "                        \"id\": \"gpt-3.5-turbo-1106\",\n",
      "                        \"context\": 16384,\n",
      "                        \"modelcard\": \"https://platform.openai.com/docs/models/gpt-3-5\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        },\n",
      "        \"available_toolchains\": [\n",
      "            {\n",
      "                \"category\": \"Test\",\n",
      "                \"entries\": [\n",
      "                    {\n",
      "                        \"title\": \"Static Chat Test And Really Long Name\",\n",
      "                        \"id\": \"test_chat_session_normal\",\n",
      "                        \"category\": \"Test\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"title\": \"File Upload Test\",\n",
      "                        \"id\": \"test_file_upload\",\n",
      "                        \"category\": \"Test\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"title\": \"Iteration Test\",\n",
      "                        \"id\": \"iterable_test\",\n",
      "                        \"category\": \"Test\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"title\": \"Streaming Chat Test\",\n",
      "                        \"id\": \"test_chat_session_normal_streaming\",\n",
      "                        \"category\": \"Test\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"category\": \"Summarization\",\n",
      "                \"entries\": [\n",
      "                    {\n",
      "                        \"title\": \"Article Assistant\",\n",
      "                        \"id\": \"article_curation_search_agent\",\n",
      "                        \"category\": \"Summarization\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"default_toolchain\": {\n",
      "            \"title\": \"Streaming Chat Test\",\n",
      "            \"id\": \"test_chat_session_normal_streaming\",\n",
      "            \"category\": \"Test\"\n",
      "        },\n",
      "        \"user_set_providers\": [],\n",
      "        \"providers\": [\n",
      "            \"OpenAI\",\n",
      "            \"Anthropic\",\n",
      "            \"Serper.dev\"\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"username\": \"215a4c31-8b8d-471e-b187-fa3641c8\",\n",
      "        \"auth\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VybmFtZSI6IjIxNWE0YzMxLThiOGQtNDcxZS1iMTg3LWZhMzY0MWM4IiwicHdkX2hhc2giOiI1Y2FlZGU0Y2E0YTM5ZjAyNWE5NzBmNjE3OTFiODU2NTJiNTkzNzNmYmNlYzljN2ExOGVmNjRkYjFmN2ZiYzE5IiwiZXhwIjoxNzIwODk1Njc2fQ.urn5jlsi6_zAU0bePJswRFXeiJCMfYw8nm8pLQz0Sws\",\n",
      "        \"memberships\": [],\n",
      "        \"admin\": false,\n",
      "        \"available_models\": {\n",
      "            \"default_model\": \"llama-3-8b-instruct\",\n",
      "            \"local_models\": [\n",
      "                {\n",
      "                    \"name\": \"Mistral 7B Instruct\",\n",
      "                    \"id\": \"mistral-7b-instruct-v0.1\",\n",
      "                    \"modelcard\": \"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1\"\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"LLaMA 3 8B Instruct\",\n",
      "                    \"id\": \"llama-3-8b-instruct\",\n",
      "                    \"modelcard\": \"https://ai.meta.com/blog/meta-llama-3/\"\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"Mistral 7B Instruct (v0.3)\",\n",
      "                    \"id\": \"mistral-7b-instruct-v0.3\",\n",
      "                    \"modelcard\": \"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3\"\n",
      "                }\n",
      "            ],\n",
      "            \"external_models\": {\n",
      "                \"openai\": [\n",
      "                    {\n",
      "                        \"name\": \"GPT-4 Turbo\",\n",
      "                        \"id\": \"gpt-4-1106-preview\",\n",
      "                        \"context\": 128000,\n",
      "                        \"modelcard\": \"https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"GPT-3.5 Turbo\",\n",
      "                        \"id\": \"gpt-3.5-turbo-1106\",\n",
      "                        \"context\": 16384,\n",
      "                        \"modelcard\": \"https://platform.openai.com/docs/models/gpt-3-5\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        },\n",
      "        \"available_toolchains\": [\n",
      "            {\n",
      "                \"category\": \"Test\",\n",
      "                \"entries\": [\n",
      "                    {\n",
      "                        \"title\": \"Static Chat Test And Really Long Name\",\n",
      "                        \"id\": \"test_chat_session_normal\",\n",
      "                        \"category\": \"Test\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"title\": \"File Upload Test\",\n",
      "                        \"id\": \"test_file_upload\",\n",
      "                        \"category\": \"Test\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"title\": \"Iteration Test\",\n",
      "                        \"id\": \"iterable_test\",\n",
      "                        \"category\": \"Test\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"title\": \"Streaming Chat Test\",\n",
      "                        \"id\": \"test_chat_session_normal_streaming\",\n",
      "                        \"category\": \"Test\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"category\": \"Summarization\",\n",
      "                \"entries\": [\n",
      "                    {\n",
      "                        \"title\": \"Article Assistant\",\n",
      "                        \"id\": \"article_curation_search_agent\",\n",
      "                        \"category\": \"Summarization\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"default_toolchain\": {\n",
      "            \"title\": \"Streaming Chat Test\",\n",
      "            \"id\": \"test_chat_session_normal_streaming\",\n",
      "            \"category\": \"Test\"\n",
      "        },\n",
      "        \"user_set_providers\": [],\n",
      "        \"providers\": [\n",
      "            \"OpenAI\",\n",
      "            \"Anthropic\",\n",
      "            \"Serper.dev\"\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"auth\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VybmFtZSI6ImNmZTYxYWE2LWM5MmYtNGY2Yy1hMTdlLTViZmZlOTEwIiwicHdkX2hhc2giOiJiN2FiYzkzNDA1MWIwM2QyODY3NjQ4MjAwYjZmNTMxNjljNmNkYWI2YjExMzBhMTU0NmQxMTUxZWYyNjU4Yjg0IiwiZXhwIjoxNzIwODk1Njc2fQ.XXgeQosFdZNzL7h44-u6Gsv8sQ5aV8_hLB1ZwIp4qhk\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "\n",
    "add_user_input = {\"auth\":{\n",
    "    \"username\": USERNAME_1,\n",
    "    \"password\": PASSWORD_1,\n",
    "}}\n",
    "\n",
    "print(add_user_input)\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/login\", json=add_user_input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "# USER_ARGS_1 = {\"username\": USERNAME_1, \"password_prehash\": result[\"result\"][\"password_pre_hash\"]}\n",
    "# USER_ARGS_1 = {\"auth\": USER_ARGS_1}\n",
    "USER_ARGS_1 = {\"auth\":  result[\"result\"][\"auth\"]}\n",
    "\n",
    "\n",
    "add_user_input = {\"auth\":{\n",
    "    \"username\": USERNAME_2,\n",
    "    \"password\": PASSWORD_2,\n",
    "}}\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/login\", json=add_user_input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "USER_ARGS_2 = {\"auth\":  result[\"result\"][\"auth\"]}\n",
    "\n",
    "print(json.dumps(USER_ARGS_1, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `and_`\n",
    "this should fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": false,\n",
      "    \"error\": \"and_() missing 1 required positional argument: 'initial_clause'\",\n",
      "    \"trace\": \"Traceback (most recent call last):\\n  File \\\"/home/kmccleary/projects/QueryLakeDevelopment/QueryLakeBackend/./server.py\\\", line 444, in api_general_call\\n    args_get = function_actual(**true_args)\\nTypeError: and_() missing 1 required positional argument: 'initial_clause'\\n\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "\n",
    "input = {\n",
    "    \"username\": \"test\",\n",
    "    \"password\": \"test\",\n",
    "}\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/and_\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert (\"success\" in result and result[\"success\"] == False), \"Test succeeded when it should have failed\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `get_available_models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"available_models\": {\n",
      "            \"default_model\": \"llama-3-8b-instruct\",\n",
      "            \"local_models\": [\n",
      "                {\n",
      "                    \"name\": \"Mistral 7B Instruct\",\n",
      "                    \"id\": \"mistral-7b-instruct-v0.1\",\n",
      "                    \"modelcard\": \"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1\"\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"LLaMA 3 8B Instruct\",\n",
      "                    \"id\": \"llama-3-8b-instruct\",\n",
      "                    \"modelcard\": \"https://ai.meta.com/blog/meta-llama-3/\"\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"Mistral 7B Instruct (v0.3)\",\n",
      "                    \"id\": \"mistral-7b-instruct-v0.3\",\n",
      "                    \"modelcard\": \"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3\"\n",
      "                }\n",
      "            ],\n",
      "            \"external_models\": {\n",
      "                \"openai\": [\n",
      "                    {\n",
      "                        \"name\": \"GPT-4 Turbo\",\n",
      "                        \"id\": \"gpt-4-1106-preview\",\n",
      "                        \"context\": 128000,\n",
      "                        \"modelcard\": \"https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"GPT-3.5 Turbo\",\n",
      "                        \"id\": \"gpt-3.5-turbo-1106\",\n",
      "                        \"context\": 16384,\n",
      "                        \"modelcard\": \"https://platform.openai.com/docs/models/gpt-3-5\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/get_available_models\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `create_api_key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"api_key\": \"sk-PEO3cQQoW4jHQRzBMaJeIlGC6IcaJzDOfgUiGZ08j5VLWJjl\",\n",
      "        \"id\": \"e7bbf6445d9cc13a34d1dbb803a1910cfef78662b4b07f8d163afdbe26d70ccf\",\n",
      "        \"title\": \"API Key 1\",\n",
      "        \"created\": 1718303676.3470416,\n",
      "        \"last_used\": null,\n",
      "        \"key_preview\": \"sk-...WJjl\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"api_key\": \"sk-0nTeZrTPJ7WxB5ZRDExOq4VOcTYaDioBJffAAftrzxCLqgDP\",\n",
      "        \"id\": \"3337f1bf1c929896ea7a83fefee32cc9d73449e83a93d08aa8ca6d31f328d3db\",\n",
      "        \"title\": \"API Key 2\",\n",
      "        \"created\": 1718303676.3636513,\n",
      "        \"last_used\": null,\n",
      "        \"key_preview\": \"sk-...qgDP\"\n",
      "    }\n",
      "}\n",
      "API_KEY_1: ['sk-PEO3cQQoW4jHQRzBMaJeIlGC6IcaJzDOfgUiGZ08j5VLWJjl']\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "def create_api_key(title : str):\n",
    "    input = deepcopy({\"auth\": {\"username\": USERNAME_1, \"password\": PASSWORD_1}})\n",
    "    input.update({\"title\": title})\n",
    "\n",
    "    response = requests.get(\"http://localhost:8000/api/create_api_key\", json=input)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    result = response.json()\n",
    "\n",
    "    print(json.dumps(result, indent=4))\n",
    "    if \"trace\" in result:\n",
    "        print(result[\"trace\"])\n",
    "    assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "    \n",
    "    return result[\"result\"]\n",
    "\n",
    "API_KEY_1_INFO = create_api_key(\"API Key 1\")\n",
    "API_KEY_2_INFO = create_api_key(\"API Key 2\")\n",
    "\n",
    "API_KEY_1 = API_KEY_1_INFO[\"api_key\"]\n",
    "\n",
    "print(\"API_KEY_1:\", [API_KEY_1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `fetch_api_keys`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"api_keys\": [\n",
      "            {\n",
      "                \"id\": \"e7bbf6445d9cc13a34d1dbb803a1910cfef78662b4b07f8d163afdbe26d70ccf\",\n",
      "                \"title\": \"API Key 1\",\n",
      "                \"created\": 1718303676.3470416,\n",
      "                \"last_used\": null,\n",
      "                \"key_preview\": \"sk-...WJjl\"\n",
      "            },\n",
      "            {\n",
      "                \"id\": \"3337f1bf1c929896ea7a83fefee32cc9d73449e83a93d08aa8ca6d31f328d3db\",\n",
      "                \"title\": \"API Key 2\",\n",
      "                \"created\": 1718303676.3636513,\n",
      "                \"last_used\": null,\n",
      "                \"key_preview\": \"sk-...qgDP\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy({\"auth\": {\"username\": USERNAME_1, \"password\": PASSWORD_1}})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/fetch_api_keys\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `delete_api_key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy({\"auth\": {\"username\": USERNAME_1, \"password\": PASSWORD_1}})\n",
    "input.update({\"api_key_id\": API_KEY_2_INFO[\"id\"]})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/delete_api_key\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `create_oauth2_token`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VybmFtZSI6ImNmZTYxYWE2LWM5MmYtNGY2Yy1hMTdlLTViZmZlOTEwIiwicHdkX2hhc2giOiJiN2FiYzkzNDA1MWIwM2QyODY3NjQ4MjAwYjZmNTMxNjljNmNkYWI2YjExMzBhMTU0NmQxMTUxZWYyNjU4Yjg0IiwiZXhwIjoxNzIwODk1Njc2fQ.XXgeQosFdZNzL7h44-u6Gsv8sQ5aV8_hLB1ZwIp4qhk\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = {\"auth\": {\"username\": USERNAME_1, \"password\": PASSWORD_1}}\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/create_oauth2_token\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "OAUTH2_TOKEN = result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ Using OAuth2 Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"username\": \"cfe61aa6-c92f-4f6c-a17e-5bffe910\",\n",
      "        \"auth\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VybmFtZSI6ImNmZTYxYWE2LWM5MmYtNGY2Yy1hMTdlLTViZmZlOTEwIiwicHdkX2hhc2giOiJiN2FiYzkzNDA1MWIwM2QyODY3NjQ4MjAwYjZmNTMxNjljNmNkYWI2YjExMzBhMTU0NmQxMTUxZWYyNjU4Yjg0IiwiZXhwIjoxNzIwODk1Njc2fQ.XXgeQosFdZNzL7h44-u6Gsv8sQ5aV8_hLB1ZwIp4qhk\",\n",
      "        \"memberships\": [],\n",
      "        \"admin\": false,\n",
      "        \"available_models\": {\n",
      "            \"default_model\": \"llama-3-8b-instruct\",\n",
      "            \"local_models\": [\n",
      "                {\n",
      "                    \"name\": \"Mistral 7B Instruct\",\n",
      "                    \"id\": \"mistral-7b-instruct-v0.1\",\n",
      "                    \"modelcard\": \"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1\"\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"LLaMA 3 8B Instruct\",\n",
      "                    \"id\": \"llama-3-8b-instruct\",\n",
      "                    \"modelcard\": \"https://ai.meta.com/blog/meta-llama-3/\"\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"Mistral 7B Instruct (v0.3)\",\n",
      "                    \"id\": \"mistral-7b-instruct-v0.3\",\n",
      "                    \"modelcard\": \"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3\"\n",
      "                }\n",
      "            ],\n",
      "            \"external_models\": {\n",
      "                \"openai\": [\n",
      "                    {\n",
      "                        \"name\": \"GPT-4 Turbo\",\n",
      "                        \"id\": \"gpt-4-1106-preview\",\n",
      "                        \"context\": 128000,\n",
      "                        \"modelcard\": \"https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"GPT-3.5 Turbo\",\n",
      "                        \"id\": \"gpt-3.5-turbo-1106\",\n",
      "                        \"context\": 16384,\n",
      "                        \"modelcard\": \"https://platform.openai.com/docs/models/gpt-3-5\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        },\n",
      "        \"available_toolchains\": [\n",
      "            {\n",
      "                \"category\": \"Test\",\n",
      "                \"entries\": [\n",
      "                    {\n",
      "                        \"title\": \"Static Chat Test And Really Long Name\",\n",
      "                        \"id\": \"test_chat_session_normal\",\n",
      "                        \"category\": \"Test\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"title\": \"File Upload Test\",\n",
      "                        \"id\": \"test_file_upload\",\n",
      "                        \"category\": \"Test\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"title\": \"Iteration Test\",\n",
      "                        \"id\": \"iterable_test\",\n",
      "                        \"category\": \"Test\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"title\": \"Streaming Chat Test\",\n",
      "                        \"id\": \"test_chat_session_normal_streaming\",\n",
      "                        \"category\": \"Test\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"category\": \"Summarization\",\n",
      "                \"entries\": [\n",
      "                    {\n",
      "                        \"title\": \"Article Assistant\",\n",
      "                        \"id\": \"article_curation_search_agent\",\n",
      "                        \"category\": \"Summarization\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"default_toolchain\": {\n",
      "            \"title\": \"Streaming Chat Test\",\n",
      "            \"id\": \"test_chat_session_normal_streaming\",\n",
      "            \"category\": \"Test\"\n",
      "        },\n",
      "        \"user_set_providers\": [],\n",
      "        \"providers\": [\n",
      "            \"OpenAI\",\n",
      "            \"Anthropic\",\n",
      "            \"Serper.dev\"\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = {\"auth\": {\"username\": USERNAME_1, \"password\": PASSWORD_1}}\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/login\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `function_help`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": [\n",
      "        {\n",
      "            \"api_function_id\": \"add_user\",\n",
      "            \"function_name\": \"add_user\",\n",
      "            \"description\": \"Add user to the database.\\nDepending on your user configuration, you can send a confirmation email for signup,\\nand communicate this in the response via {\\\"pending_email\\\": True}.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"username\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"password\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"aes_decrypt_string\",\n",
      "            \"function_name\": \"aes_decrypt_string\",\n",
      "            \"description\": \"Decrypts ecnrypted hex string using any input key string.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"key\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"encrypted_hex_string\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"encoding\",\n",
      "                    \"type_hint\": \"str\",\n",
      "                    \"default\": \"'utf-8'\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"aes_encrypt_string\",\n",
      "            \"function_name\": \"aes_encrypt_string\",\n",
      "            \"description\": \"Encrypts input string using any input key string.\\nData is returned as a hex string.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"key\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"input_string\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"encoding\",\n",
      "                    \"type_hint\": \"str\",\n",
      "                    \"default\": \"'utf-8'\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"and_\",\n",
      "            \"function_name\": \"and_\",\n",
      "            \"description\": \"\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"initial_clause\",\n",
      "                    \"type_hint\": \"Union[Literal[True], ForwardRef('ColumnElement[_T]'), sqlalchemy.sql._typing._HasClauseElement[bool], ForwardRef('SQLCoreOperations[_T]'), sqlalchemy.sql.roles.ExpressionElementRole[bool], sqlalchemy.sql.roles.TypedColumnsClauseRole[bool], Callable[[], ForwardRef('ColumnElement[_T]')], ForwardRef('LambdaElement'), bool]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"clauses\",\n",
      "                    \"type_hint\": \"*clauses: Union[ForwardRef('ColumnElement[_T]'), sqlalchemy.sql._typing._HasClauseElement[bool], ForwardRef('SQLCoreOperations[_T]'), sqlalchemy.sql.roles.ExpressionElementRole[bool], sqlalchemy.sql.roles.TypedColumnsClauseRole[bool], Callable[[], ForwardRef('ColumnElement[_T]')], ForwardRef('LambdaElement'), bool]\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"copy\",\n",
      "            \"function_name\": \"copy\",\n",
      "            \"description\": \"Shallow copy operation on arbitrary Python objects.\\nSee the module's __doc__ string for more info.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"x\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"craft_document_access_token\",\n",
      "            \"function_name\": \"craft_document_access_token\",\n",
      "            \"description\": \"Craft a document access token using the global server public key.\\nDefault expiration is 60 seconds, but client can specify otherwise.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"hash_id\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"validity_window\",\n",
      "                    \"type_hint\": \"float\",\n",
      "                    \"default\": \"60\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"create_api_key\",\n",
      "            \"function_name\": \"create_api_key\",\n",
      "            \"description\": \"Create a new API key for the user.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str, dict]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"title\",\n",
      "                    \"type_hint\": \"str\",\n",
      "                    \"default\": \"None\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"create_chat_session\",\n",
      "            \"function_name\": \"create_chat_session\",\n",
      "            \"description\": \"Create a new chat session. Returns the hash_id of the created session.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"username\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"password_prehash\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"access_token_hash_id\",\n",
      "                    \"type_hint\": \"str\",\n",
      "                    \"default\": \"None\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"model_name\",\n",
      "                    \"type_hint\": \"str\",\n",
      "                    \"default\": \"'llama-3-8b-instruct'\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"create_document_collection\",\n",
      "            \"function_name\": \"create_document_collection\",\n",
      "            \"description\": \"Create a new document collection. \\nIf no hash_id is given, one is created, then returned.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"name\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"description\",\n",
      "                    \"type_hint\": \"str\",\n",
      "                    \"default\": \"None\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"public\",\n",
      "                    \"type_hint\": \"bool\",\n",
      "                    \"default\": \"False\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"organization_id\",\n",
      "                    \"type_hint\": \"int\",\n",
      "                    \"default\": \"None\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"create_oauth2_token\",\n",
      "            \"function_name\": \"create_oauth2_token\",\n",
      "            \"description\": \"Create an OAuth2 token for the user.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str, dict]\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"create_organization\",\n",
      "            \"function_name\": \"create_organization\",\n",
      "            \"description\": \"Add an organization to the db. Verify the user first.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"organization_name\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"organization_description\",\n",
      "                    \"type_hint\": \"str\",\n",
      "                    \"default\": \"None\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"create_text_embeddings\",\n",
      "            \"function_name\": \"create_text_embeddings\",\n",
      "            \"description\": \"Given a set of text chunks, possibly pairs with metadata, create embeddings for the\\nentries. Craft an entry in the vector db, using the collection relevant to the\\nmodel used. Each entry into the vector db will have the following metadata:\\ncollection_type - whether the parent collection is an org, user, or global collection.\\npublic - bool for if this is public or not.\\nparent_collection_id - sql db hash id for the parent collection\\ndocument_id - sql db hash id for the parent document.\\npage - what page of the original document the chunk is from.\\ndocument_name - name of the original document.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"text_segments\",\n",
      "                    \"type_hint\": \"List[Tuple[str, dict]]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"document_sql_entry\",\n",
      "                    \"type_hint\": \"QueryLake.database.sql_db_tables.document_raw\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"document_name\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"create_toolchain_session\",\n",
      "            \"function_name\": \"create_toolchain_session\",\n",
      "            \"description\": \"Initiate a toolchain session with a random access token.\\nThis token is the session ID, and the session will be stored in the\\ndatabase accordingly.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"toolchain_id\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"ws\",\n",
      "                    \"type_hint\": \"starlette.websockets.WebSocket\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"create_website_embeddings\",\n",
      "            \"function_name\": \"create_website_embeddings\",\n",
      "            \"description\": \"Given a set of text chunks, possibly pairs with metadata, create embeddings for the\\nentries. Craft an entry in the chroma db, using the collection relevant to the\\nmodel used. Each entry into the chroma db will have the following metadata:\\ncollection_type - whether the parent collection is an org, user, or global collection.\\npublic - bool for if this is public or not.\\nparent_collection_id - sql db hash id for the parent collection\\ndocument_id - sql db hash id for the parent document.\\npage - what page of the original document the chunk is from.\\ndocument_name - name of the original document.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"url_content_pairs\",\n",
      "                    \"type_hint\": \"list\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"deepcopy\",\n",
      "            \"function_name\": \"deepcopy\",\n",
      "            \"description\": \"Deep copy operation on arbitrary Python objects.\\nSee the module's __doc__ string for more info.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"x\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"memo\",\n",
      "                    \"type_hint\": \"\",\n",
      "                    \"default\": \"None\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"_nil\",\n",
      "                    \"type_hint\": \"\",\n",
      "                    \"default\": \"[]\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"delete_api_key\",\n",
      "            \"function_name\": \"delete_api_key\",\n",
      "            \"description\": \"Delete an API key by its id.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str, dict]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"api_key_id\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"delete_document\",\n",
      "            \"function_name\": \"delete_document\",\n",
      "            \"description\": \"Authorizes that user has permission to delete document, then does so.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"hash_id\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"embed_urls\",\n",
      "            \"function_name\": \"embed_urls\",\n",
      "            \"description\": \"Download Urls, convert them to markdown, and\\nchunk them into the database.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"urls\",\n",
      "                    \"type_hint\": \"List[str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"titles\",\n",
      "                    \"type_hint\": \"List[str]\",\n",
      "                    \"default\": \"None\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"web_timeout\",\n",
      "                    \"type_hint\": \"float\",\n",
      "                    \"default\": \"10\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"fetch_all_collections\",\n",
      "            \"function_name\": \"fetch_all_collections\",\n",
      "            \"description\": \"Fetches all collections that a user has priviledge to read.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"fetch_api_keys\",\n",
      "            \"function_name\": \"fetch_api_keys\",\n",
      "            \"description\": \"Fetch all API keys belonging to the user.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str, dict]\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"fetch_chat_sessions\",\n",
      "            \"function_name\": \"fetch_chat_sessions\",\n",
      "            \"description\": \"Get previous chat sessions of user. Returned as a list of objects sorted by timestamp.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"username\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"password_prehash\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"cutoff_date\",\n",
      "                    \"type_hint\": \"str\",\n",
      "                    \"default\": \"None\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"fetch_collection\",\n",
      "            \"function_name\": \"fetch_collection\",\n",
      "            \"description\": \"Retrieves details of a collection for user, \\nincluding all documents in the collection.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"collection_hash_id\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"collection_type\",\n",
      "                    \"type_hint\": \"str\",\n",
      "                    \"default\": \"'user'\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"fetch_document\",\n",
      "            \"function_name\": \"fetch_document\",\n",
      "            \"description\": \"Decrypt document in memory for the user's viewing.\\nReturn as a streaming response of bytes.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"document_auth_access\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"fetch_document_collections_belonging_to\",\n",
      "            \"function_name\": \"fetch_document_collections_belonging_to\",\n",
      "            \"description\": \"Gets a list of dicts for document collections. \\nIf organization_id is none, return the user's personal collections. \\nIf it is provided, check the user is an accepted member of the org, then retrieve the collections.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"organization_id\",\n",
      "                    \"type_hint\": \"int\",\n",
      "                    \"default\": \"None\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"global_collections\",\n",
      "                    \"type_hint\": \"bool\",\n",
      "                    \"default\": \"False\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"fetch_memberships\",\n",
      "            \"function_name\": \"fetch_memberships\",\n",
      "            \"description\": \"Returns a list of dicts for organizations for which the user has a membership table connecting the two.\\nreturn_subset is \\\"accepted\\\" | \\\"open_invitations\\\" | \\\"all\\\".\\ndicts contain: org_name, org_id, role, accepted\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"return_subset\",\n",
      "                    \"type_hint\": \"str\",\n",
      "                    \"default\": \"'accepted'\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"fetch_memberships_of_organization\",\n",
      "            \"function_name\": \"fetch_memberships_of_organization\",\n",
      "            \"description\": \"Fetches all active memberships of an organization, first verifying that the user is in the given organization.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"organization_id\",\n",
      "                    \"type_hint\": \"int\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"fetch_session\",\n",
      "            \"function_name\": \"fetch_session\",\n",
      "            \"description\": \"Get all interactions from chat session by id.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"username\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"password_prehash\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"hash_id\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"fetch_toolchain_config\",\n",
      "            \"function_name\": \"fetch_toolchain_config\",\n",
      "            \"description\": \"TODO: Revisit this for permission locks.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"toolchain_id\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"fetch_toolchain_session\",\n",
      "            \"function_name\": \"fetch_toolchain_session\",\n",
      "            \"description\": \"Retrieve toolchain session from session id.\\nIf not in memory, it is loaded from the database.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"session_id\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"ws\",\n",
      "                    \"type_hint\": \"starlette.websockets.WebSocket\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"fetch_toolchain_sessions\",\n",
      "            \"function_name\": \"fetch_toolchain_sessions\",\n",
      "            \"description\": \"Get previous toolchain sessions of user. \\nReturned as a list of objects sorted by timestamp.\\nOptional cutoff date provided in unix time.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"cutoff_date\",\n",
      "                    \"type_hint\": \"float\",\n",
      "                    \"default\": \"None\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"file_size_as_string\",\n",
      "            \"function_name\": \"file_size_as_string\",\n",
      "            \"description\": \"Convert a file size in bytes to a human readable string.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"byte_count\",\n",
      "                    \"type_hint\": \"int\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"gather\",\n",
      "            \"function_name\": \"gather\",\n",
      "            \"description\": \"Return a future aggregating results from the given coroutines/futures.\\nCoroutines will be wrapped in a future and scheduled in the event\\nloop. They will not necessarily be scheduled in the same order as\\npassed in.\\nAll futures must share the same event loop.  If all the tasks are\\ndone successfully, the returned future's result is the list of\\nresults (in the order of the original sequence, not necessarily\\nthe order of results arrival).  If *return_exceptions* is True,\\nexceptions in the tasks are treated the same as successful\\nresults, and gathered in the result list; otherwise, the first\\nraised exception will be immediately propagated to the returned\\nfuture.\\nCancellation: if the outer Future is cancelled, all children (that\\nhave not completed yet) are also cancelled.  If any child is\\ncancelled, this is treated as if it raised CancelledError --\\nthe outer Future is *not* cancelled in this case.  (This is to\\nprevent the cancellation of one child to cause other children to\\nbe cancelled.)\\nIf *return_exceptions* is False, cancelling gather() after it\\nhas been marked done won't cancel any submitted awaitables.\\nFor instance, gather can be marked done after propagating an\\nexception to the caller, therefore, calling ``gather.cancel()``\\nafter catching an exception (raised by one of the awaitables) from\\ngather won't cancel any other awaitables.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"coros_or_futures\",\n",
      "                    \"type_hint\": \"*coros_or_futures\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"return_exceptions\",\n",
      "                    \"type_hint\": \"\",\n",
      "                    \"default\": \"False\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"get\",\n",
      "            \"function_name\": \"get\",\n",
      "            \"description\": \"Get a remote object or a list of remote objects from the object store.\\nThis method blocks until the object corresponding to the object ref is\\navailable in the local object store. If this object is not in the local\\nobject store, it will be shipped from an object store that has it (once the\\nobject has been created). If object_refs is a list, then the objects\\ncorresponding to each object in the list will be returned.\\nOrdering for an input list of object refs is preserved for each object\\nreturned. That is, if an object ref to A precedes an object ref to B in the\\ninput list, then A will precede B in the returned list.\\nThis method will issue a warning if it's running inside async context,\\nyou can use ``await object_ref`` instead of ``ray.get(object_ref)``. For\\na list of object refs, you can use ``await asyncio.gather(*object_refs)``.\\nPassing :class:`~ObjectRefGenerator` is not allowed.\\nRelated patterns and anti-patterns:\\n- :doc:`/ray-core/patterns/ray-get-loop`\\n- :doc:`/ray-core/patterns/unnecessary-ray-get`\\n- :doc:`/ray-core/patterns/ray-get-submission-order`\\n- :doc:`/ray-core/patterns/ray-get-too-many-objects`\\nArgs:\\nobject_refs: Object ref of the object to get or a list of object refs\\nto get.\\ntimeout (Optional[float]): The maximum amount of time in seconds to\\nwait before returning. Set this to None will block until the\\ncorresponding object becomes available. Setting ``timeout=0`` will\\nreturn the object immediately if it's available, else raise\\nGetTimeoutError in accordance with the above docstring.\\nReturns:\\nA Python object or a list of Python objects.\\nRaises:\\nGetTimeoutError: A GetTimeoutError is raised if a timeout is set and\\nthe get takes longer than timeout to return.\\nException: An exception is raised if the task that created the object\\nor that created one of the objects raised an exception.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"object_refs\",\n",
      "                    \"type_hint\": \"Union[ForwardRef('ObjectRef[Any]'), Sequence[ForwardRef('ObjectRef[Any]')]]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"timeout\",\n",
      "                    \"type_hint\": \"Optional[float]\",\n",
      "                    \"default\": \"None\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"get_available_models\",\n",
      "            \"function_name\": \"get_available_models\",\n",
      "            \"description\": \"Gets a list of all models on the server available to the given user.\\nPlan on making changes so that organizations can have private models.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"get_available_toolchains\",\n",
      "            \"function_name\": \"get_available_toolchains\",\n",
      "            \"description\": \"Returns available toolchains with chat window settings and all.\\nWill find organization locked\\nIf there are organization locked toolchains, they will be added to the database.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"get_document_secure\",\n",
      "            \"function_name\": \"get_document_secure\",\n",
      "            \"description\": \"Returns the document entry withing the system database.\\nPrimarily used for internal calls.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"hash_id\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"return_document\",\n",
      "                    \"type_hint\": \"bool\",\n",
      "                    \"default\": \"False\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"get_file_bytes\",\n",
      "            \"function_name\": \"get_file_bytes\",\n",
      "            \"description\": \"\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"hash_id\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"encryption_key\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"get_openai_api_key\",\n",
      "            \"function_name\": \"get_openai_api_key\",\n",
      "            \"description\": \"Retrieve user OpenAI API key.\\nIf organization is specified, return an array with the former plus\\nthe organization OpenAI ID.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"organization_hash_id\",\n",
      "                    \"type_hint\": \"str\",\n",
      "                    \"default\": \"None\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"get_session_state\",\n",
      "            \"function_name\": \"get_session_state\",\n",
      "            \"description\": \"Get the session state of a given toolchain.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"dict\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"session_id\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"session\",\n",
      "                    \"type_hint\": \"QueryLake.operation_classes.toolchain_session.ToolchainSession\",\n",
      "                    \"default\": \"None\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"get_toolchain_from_db\",\n",
      "            \"function_name\": \"get_toolchain_from_db\",\n",
      "            \"description\": \"TODO: Revisit this for permission locks.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"toolchain_id\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"get_toolchain_output_file_response\",\n",
      "            \"function_name\": \"get_toolchain_output_file_response\",\n",
      "            \"description\": \"Retrieve file response from a toolchain result.\\nThis is basically a middleman function to actually get the file response.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"document_id\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"document_password\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"get_user_external_providers_dict\",\n",
      "            \"function_name\": \"get_user_external_providers_dict\",\n",
      "            \"description\": \"Get user external providers dictionary.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str, dict]\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"hash_function\",\n",
      "            \"function_name\": \"hash_function\",\n",
      "            \"description\": \"SHA256 hashing function.\\nOptional salting. The process is hash(hash(input)+hash(salt)).\\nIf only_salt is enabled, process is hash(input+hash(salt))\\nIf no salt is given, process is hash(input)\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"input\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"salt\",\n",
      "                    \"type_hint\": \"str\",\n",
      "                    \"default\": \"None\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"only_salt\",\n",
      "                    \"type_hint\": \"bool\",\n",
      "                    \"default\": \"False\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"hide_chat_session\",\n",
      "            \"function_name\": \"hide_chat_session\",\n",
      "            \"description\": \"Permanently hide chat session so it does not show up in history.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"username\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"password_prehash\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"hash_id\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"invite_user_to_organization\",\n",
      "            \"function_name\": \"invite_user_to_organization\",\n",
      "            \"description\": \"Invite a user to organization. \\nRaise an error if they are already in the organization.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"username_to_invite\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"organization_id\",\n",
      "                    \"type_hint\": \"int\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"member_class\",\n",
      "                    \"type_hint\": \"str\",\n",
      "                    \"default\": \"'member'\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"llm_isolate_question\",\n",
      "            \"function_name\": \"llm_isolate_question\",\n",
      "            \"description\": \"Given a chat history with a most recent question, rephrase the question so\\nthat it is completely clear without context.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"chat_history\",\n",
      "                    \"type_hint\": \"List[dict]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"model_choice\",\n",
      "                    \"type_hint\": \"str\",\n",
      "                    \"default\": \"None\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"llm_make_conversation_title\",\n",
      "            \"function_name\": \"llm_make_conversation_title\",\n",
      "            \"description\": \"Given a chat history with a most recent question, rephrase the question so\\nthat it is completely clear without context.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"chat_history\",\n",
      "                    \"type_hint\": \"List[dict]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"stream_callables\",\n",
      "                    \"type_hint\": \"Dict[str, Awaitable[Callable[[str], NoneType]]]\",\n",
      "                    \"default\": \"None\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"model_choice\",\n",
      "                    \"type_hint\": \"str\",\n",
      "                    \"default\": \"None\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"llm_multistep_search\",\n",
      "            \"function_name\": \"llm_multistep_search\",\n",
      "            \"description\": \"Given a chat history with a most recent question, \\nperform iterative search using the LLM as an agent.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"chat_history\",\n",
      "                    \"type_hint\": \"List[dict]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"collection_ids\",\n",
      "                    \"type_hint\": \"List[str]\",\n",
      "                    \"default\": \"[]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"model_choice\",\n",
      "                    \"type_hint\": \"str\",\n",
      "                    \"default\": \"None\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"max_searches\",\n",
      "                    \"type_hint\": \"int\",\n",
      "                    \"default\": \"5\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"search_web\",\n",
      "                    \"type_hint\": \"bool\",\n",
      "                    \"default\": \"False\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"web_timeout\",\n",
      "                    \"type_hint\": \"float\",\n",
      "                    \"default\": \"10\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"login\",\n",
      "            \"function_name\": \"login\",\n",
      "            \"description\": \"This is for verifying a user login, and providing them their password prehash.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str, dict]\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"modify_document_collection\",\n",
      "            \"function_name\": \"modify_document_collection\",\n",
      "            \"description\": \"Changes document collection properties for a user.\\nTODO: Implement public/private switch.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"collection_hash_id\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"title\",\n",
      "                    \"type_hint\": \"str\",\n",
      "                    \"default\": \"None\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"description\",\n",
      "                    \"type_hint\": \"str\",\n",
      "                    \"default\": \"None\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"collection_type\",\n",
      "                    \"type_hint\": \"str\",\n",
      "                    \"default\": \"'user'\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"modify_user_external_providers\",\n",
      "            \"function_name\": \"modify_user_external_providers\",\n",
      "            \"description\": \"Modify user external providers.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str, dict]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"update\",\n",
      "                    \"type_hint\": \"dict\",\n",
      "                    \"default\": \"None\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"delete\",\n",
      "                    \"type_hint\": \"List[Union[int, str]]\",\n",
      "                    \"default\": \"None\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"ocr_pdf_file\",\n",
      "            \"function_name\": \"ocr_pdf_file\",\n",
      "            \"description\": \"OCR a pdf file and return the raw text.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"file\",\n",
      "                    \"type_hint\": \"bytes\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"parse_PDFs\",\n",
      "            \"function_name\": \"parse_PDFs\",\n",
      "            \"description\": \"\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"bytes_in\",\n",
      "                    \"type_hint\": \"Union[bytes, _io.BytesIO]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"return_all_text_as_string\",\n",
      "                    \"type_hint\": \"bool\",\n",
      "                    \"default\": \"False\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"parse_url\",\n",
      "            \"function_name\": \"parse_url\",\n",
      "            \"description\": \"\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"url_in\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"parse_urls\",\n",
      "            \"function_name\": \"parse_urls\",\n",
      "            \"description\": \"Embed URLs into the database.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"urls\",\n",
      "                    \"type_hint\": \"List[str]\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"process_input_as_auth_type\",\n",
      "            \"function_name\": \"process_input_as_auth_type\",\n",
      "            \"description\": \"\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str, dict]\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"query_database\",\n",
      "            \"function_name\": \"query_database\",\n",
      "            \"description\": \"Create an embedding for a query and lookup a certain amount of relevant chunks.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"query\",\n",
      "                    \"type_hint\": \"Union[str, List[str]]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"collection_ids\",\n",
      "                    \"type_hint\": \"List[str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"k\",\n",
      "                    \"type_hint\": \"int\",\n",
      "                    \"default\": \"10\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"use_lexical\",\n",
      "                    \"type_hint\": \"bool\",\n",
      "                    \"default\": \"False\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"use_embeddings\",\n",
      "                    \"type_hint\": \"bool\",\n",
      "                    \"default\": \"True\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"use_rerank\",\n",
      "                    \"type_hint\": \"bool\",\n",
      "                    \"default\": \"False\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"use_web\",\n",
      "                    \"type_hint\": \"bool\",\n",
      "                    \"default\": \"False\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"rerank_question\",\n",
      "                    \"type_hint\": \"str\",\n",
      "                    \"default\": \"''\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"ratio\",\n",
      "                    \"type_hint\": \"float\",\n",
      "                    \"default\": \"0.5\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"minimum_relevance\",\n",
      "                    \"type_hint\": \"float\",\n",
      "                    \"default\": \"0.05\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"random_hash\",\n",
      "            \"function_name\": \"random_hash\",\n",
      "            \"description\": \"Returns a random SHA256 hash.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"length\",\n",
      "                    \"type_hint\": \"int\",\n",
      "                    \"default\": \"64\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"base\",\n",
      "                    \"type_hint\": \"int\",\n",
      "                    \"default\": \"16\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"resolve_organization_invitation\",\n",
      "            \"function_name\": \"resolve_organization_invitation\",\n",
      "            \"description\": \"Given the index of an organization, find the membership between user and org and accept or decline the invite.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"organization_id\",\n",
      "                    \"type_hint\": \"int\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"accept\",\n",
      "                    \"type_hint\": \"bool\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"retrieve_toolchain_session_from_db\",\n",
      "            \"function_name\": \"retrieve_toolchain_session_from_db\",\n",
      "            \"description\": \"\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"session_id\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"ws\",\n",
      "                    \"type_hint\": \"starlette.websockets.WebSocket\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"run_function_safe\",\n",
      "            \"function_name\": \"run_function_safe\",\n",
      "            \"description\": \"Run function without the danger of unknown kwargs.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"function_actual\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"kwargs\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"run_sequence_action_on_object\",\n",
      "            \"function_name\": \"run_sequence_action_on_object\",\n",
      "            \"description\": \"TODO: Think about how we want to efficiently communicate changes here to\\nthe client. Maybe the client needs to have a copy of it's own state and\\nrun the sequence actions themselves. This would save data,\\nbut client performance would be worse.\\nRun a set of sequence actions on an object.\\nKeeping the local functions here, as the states are already kept in scope.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"subject_state\",\n",
      "                    \"type_hint\": \"Union[list, dict]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"toolchain_state\",\n",
      "                    \"type_hint\": \"Union[list, dict]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"node_inputs_state\",\n",
      "                    \"type_hint\": \"Union[list, dict]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"node_outputs_state\",\n",
      "                    \"type_hint\": \"Union[list, dict]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"toolchain_files\",\n",
      "                    \"type_hint\": \"Union[list, dict]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"sequence\",\n",
      "                    \"type_hint\": \"List[Union[int, str, QueryLake.typing.toolchains.indexRouteRetrieved, QueryLake.typing.toolchains.staticValue, QueryLake.typing.toolchains.indexRouteRetrievedStateValue, QueryLake.typing.toolchains.indexRouteRetrievedInputArgValue, QueryLake.typing.toolchains.indexRouteRetrievedOutputArgValue, QueryLake.typing.toolchains.indexRouteRetrievedFile, QueryLake.typing.toolchains.getLengthValue, QueryLake.typing.toolchains.createAction, QueryLake.typing.toolchains.updateAction, QueryLake.typing.toolchains.appendAction, QueryLake.typing.toolchains.deleteAction, QueryLake.typing.toolchains.operatorAction, QueryLake.typing.toolchains.backOut]]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"provided_object\",\n",
      "                    \"type_hint\": \"Any\",\n",
      "                    \"default\": \"None\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"get_files_callable\",\n",
      "                    \"type_hint\": \"Callable[[QueryLake.typing.toolchains.ToolChainSessionFile], Union[bytes, _io.BytesIO, str]]\",\n",
      "                    \"default\": \"None\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"deepcopy_object\",\n",
      "                    \"type_hint\": \"bool\",\n",
      "                    \"default\": \"False\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"return_provided_object_routes\",\n",
      "                    \"type_hint\": \"bool\",\n",
      "                    \"default\": \"False\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"safe_serialize\",\n",
      "            \"function_name\": \"safe_serialize\",\n",
      "            \"description\": \"Serialize an object, but if an element is not serializable, return a string representation of said element.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"obj\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"**kwargs\",\n",
      "                    \"type_hint\": \"OPEN_KWARGS\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"set_organization_openai_id\",\n",
      "            \"function_name\": \"set_organization_openai_id\",\n",
      "            \"description\": \"Sets organization OpenAI ID Key.\\nUsing this allows users to use OpenAI models with charges made\\nto the OpenAI organization instead.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"openai_organization_id\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"organization_hash_id\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"set_user_openai_api_key\",\n",
      "            \"function_name\": \"set_user_openai_api_key\",\n",
      "            \"description\": \"Sets user OpenAI API key in SQL db.\\nNecessary to use OpenAI models for chat outputs.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"openai_api_key\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"toolchain_event_call\",\n",
      "            \"function_name\": \"toolchain_event_call\",\n",
      "            \"description\": \"Call an event node in provided toolchain session and propagate forward.\\nEntry parameters can be provided, however there must be special cases for\\nthings like files.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"session\",\n",
      "                    \"type_hint\": \"QueryLake.operation_classes.toolchain_session.ToolchainSession\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"session_id\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"event_node_id\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"event_parameters\",\n",
      "                    \"type_hint\": \"dict\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"system_args\",\n",
      "                    \"type_hint\": \"dict\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"ws\",\n",
      "                    \"type_hint\": \"starlette.websockets.WebSocket\",\n",
      "                    \"default\": \"None\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"return_file_response\",\n",
      "                    \"type_hint\": \"bool\",\n",
      "                    \"default\": \"False\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"toolchain_file_upload_event_call\",\n",
      "            \"function_name\": \"toolchain_file_upload_event_call\",\n",
      "            \"description\": \"Trigger file upload event call in toolchain.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"session\",\n",
      "                    \"type_hint\": \"QueryLake.operation_classes.toolchain_session.ToolchainSession\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"session_id\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"event_parameters\",\n",
      "                    \"type_hint\": \"dict\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"document_hash_id\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"file_name\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"upload_document\",\n",
      "            \"function_name\": \"upload_document\",\n",
      "            \"description\": \"Upload file to server. Possibly with encryption.\\nCan be a user document, organization document, or global document, or a toolchain_session document.\\nIn the very last case, provide the toolchain session hash id as the collection hash id.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"file\",\n",
      "                    \"type_hint\": \"fastapi.datastructures.UploadFile\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"collection_hash_id\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"collection_type\",\n",
      "                    \"type_hint\": \"str\",\n",
      "                    \"default\": \"'user'\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"public\",\n",
      "                    \"type_hint\": \"bool\",\n",
      "                    \"default\": \"False\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"return_file_hash\",\n",
      "                    \"type_hint\": \"bool\",\n",
      "                    \"default\": \"False\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"add_to_vector_db\",\n",
      "                    \"type_hint\": \"bool\",\n",
      "                    \"default\": \"True\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"await_embedding\",\n",
      "                    \"type_hint\": \"bool\",\n",
      "                    \"default\": \"False\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"web_search\",\n",
      "            \"function_name\": \"web_search\",\n",
      "            \"description\": \"Perform a search query and embed URLs into database.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"query\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"results\",\n",
      "                    \"type_hint\": \"int\",\n",
      "                    \"default\": \"10\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"web_timeout\",\n",
      "                    \"type_hint\": \"float\",\n",
      "                    \"default\": \"10\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"llm\",\n",
      "            \"function_name\": \"llm_call\",\n",
      "            \"description\": \"Call an LLM model, possibly with parameters.\\nTODO: Move OpenAI calls here for integration.\\nTODO: Add optionality via default values to the model parameters.\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"question\",\n",
      "                    \"type_hint\": \"str\",\n",
      "                    \"default\": \"None\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"model_parameters\",\n",
      "                    \"type_hint\": \"dict\",\n",
      "                    \"default\": \"{}\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"sources\",\n",
      "                    \"type_hint\": \"List[dict]\",\n",
      "                    \"default\": \"[]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"chat_history\",\n",
      "                    \"type_hint\": \"List[dict]\",\n",
      "                    \"default\": \"None\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"stream_callables\",\n",
      "                    \"type_hint\": \"Dict[str, Awaitable[Callable[[str], NoneType]]]\",\n",
      "                    \"default\": \"None\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"llm_count_tokens\",\n",
      "            \"function_name\": \"llm_count_tokens\",\n",
      "            \"description\": \"\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"model_id\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"input_string\",\n",
      "                    \"type_hint\": \"str\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"text_models_callback\",\n",
      "            \"function_name\": \"text_models_callback\",\n",
      "            \"description\": \"\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"request_dict\",\n",
      "                    \"type_hint\": \"dict\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"model_choice\",\n",
      "                    \"type_hint\": \"Literal['embedding', 'rerank']\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"embedding\",\n",
      "            \"function_name\": \"embedding_call\",\n",
      "            \"description\": \"\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"inputs\",\n",
      "                    \"type_hint\": \"List[str]\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"rerank\",\n",
      "            \"function_name\": \"rerank_call\",\n",
      "            \"description\": \"\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"inputs\",\n",
      "                    \"type_hint\": \"List[Tuple[str, str]]\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"web_scrape\",\n",
      "            \"function_name\": \"web_scrape_call\",\n",
      "            \"description\": \"\",\n",
      "            \"function_args\": [\n",
      "                {\n",
      "                    \"keyword\": \"auth\",\n",
      "                    \"type_hint\": \"Union[QueryLake.typing.config.AuthType1, QueryLake.typing.config.AuthType2, QueryLake.typing.config.AuthType3, QueryLake.typing.config.AuthType4, str]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"inputs\",\n",
      "                    \"type_hint\": \"Union[str, List[str]]\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"timeout\",\n",
      "                    \"type_hint\": \"Union[float, List[float]]\",\n",
      "                    \"default\": \"10\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"markdown\",\n",
      "                    \"type_hint\": \"Union[bool, List[bool]]\",\n",
      "                    \"default\": \"True\"\n",
      "                },\n",
      "                {\n",
      "                    \"keyword\": \"summary\",\n",
      "                    \"type_hint\": \"Union[bool, List[bool]]\",\n",
      "                    \"default\": \"False\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"api_function_id\": \"function_help\",\n",
      "            \"function_name\": \"get_all_function_descriptions\",\n",
      "            \"description\": \"Return a list of all available API functions with their specifications.\",\n",
      "            \"function_args\": []\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "['add_user', 'aes_decrypt_string', 'aes_encrypt_string', 'and_', 'copy', 'craft_document_access_token', 'create_api_key', 'create_chat_session', 'create_document_collection', 'create_oauth2_token', 'create_organization', 'create_text_embeddings', 'create_toolchain_session', 'create_website_embeddings', 'deepcopy', 'delete_api_key', 'delete_document', 'embed_urls', 'fetch_all_collections', 'fetch_api_keys', 'fetch_chat_sessions', 'fetch_collection', 'fetch_document', 'fetch_document_collections_belonging_to', 'fetch_memberships', 'fetch_memberships_of_organization', 'fetch_session', 'fetch_toolchain_config', 'fetch_toolchain_session', 'fetch_toolchain_sessions', 'file_size_as_string', 'gather', 'get', 'get_available_models', 'get_available_toolchains', 'get_document_secure', 'get_file_bytes', 'get_openai_api_key', 'get_session_state', 'get_toolchain_from_db', 'get_toolchain_output_file_response', 'get_user_external_providers_dict', 'hash_function', 'hide_chat_session', 'invite_user_to_organization', 'llm_isolate_question', 'llm_make_conversation_title', 'llm_multistep_search', 'login', 'modify_document_collection', 'modify_user_external_providers', 'ocr_pdf_file', 'parse_PDFs', 'parse_url', 'parse_urls', 'process_input_as_auth_type', 'query_database', 'random_hash', 'resolve_organization_invitation', 'retrieve_toolchain_session_from_db', 'run_function_safe', 'run_sequence_action_on_object', 'safe_serialize', 'set_organization_openai_id', 'set_user_openai_api_key', 'toolchain_event_call', 'toolchain_file_upload_event_call', 'upload_document', 'web_search', 'llm_call', 'llm_count_tokens', 'text_models_callback', 'embedding_call', 'rerank_call', 'web_scrape_call', 'get_all_function_descriptions']\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = {\"auth\": {\"username\": USERNAME_1, \"password\": PASSWORD_1}}\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/function_help\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "if \"result\" in result:\n",
    "\tprint(json.dumps([r[\"function_name\"] for r in result[\"result\"]], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `fetch_document_collections_belonging_to`\n",
    "* ✅ `user`\n",
    "* `organization`\n",
    "* `global`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"collections\": []\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/fetch_document_collections_belonging_to\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `create_document_collection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"hash_id\": \"537e0f99e58f9829b405e1202c421d35eae040a724b026bd3398f21a13b88246\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update({\n",
    "    \"name\": \"test_collection_1\"\n",
    "})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/create_document_collection\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"trace\"]\n",
    "\n",
    "COLLECTION_ARGS = {\"hash_id\": result[\"result\"][\"hash_id\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `fetch_all_collections`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"collections\": {\n",
      "            \"global_collections\": [],\n",
      "            \"user_collections\": [\n",
      "                {\n",
      "                    \"name\": \"test_collection_1\",\n",
      "                    \"hash_id\": \"537e0f99e58f9829b405e1202c421d35eae040a724b026bd3398f21a13b88246\",\n",
      "                    \"document_count\": 0,\n",
      "                    \"type\": \"user\"\n",
      "                }\n",
      "            ],\n",
      "            \"organization_collections\": {}\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "response = requests.get(\"http://localhost:8000/api/fetch_all_collections\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `fetch_collection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"title\": \"test_collection_1\",\n",
      "        \"description\": \"\",\n",
      "        \"type\": \"user\",\n",
      "        \"owner\": \"personal\",\n",
      "        \"public\": false,\n",
      "        \"document_list\": []\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update({\n",
    "    \"collection_hash_id\": COLLECTION_ARGS[\"hash_id\"],\n",
    "})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/fetch_collection\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `modify_document_collection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update({\n",
    "    \"collection_hash_id\": COLLECTION_ARGS[\"hash_id\"],\n",
    "    \"title\": \"test_collection_1_modified\",\n",
    "    \"description\": \"test description please ignore\"\n",
    "})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/modify_document_collection\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `upload_document`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m files \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m'\u001b[39m: f}\n\u001b[1;32m     17\u001b[0m input_json \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttp://localhost:8000/upload_document?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mencoded_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m     21\u001b[0m result \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/requests/sessions.py:725\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_redirects:\n\u001b[1;32m    723\u001b[0m     \u001b[38;5;66;03m# Redirect resolving generator.\u001b[39;00m\n\u001b[1;32m    724\u001b[0m     gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_redirects(r, request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 725\u001b[0m     history \u001b[38;5;241m=\u001b[39m [resp \u001b[38;5;28;01mfor\u001b[39;00m resp \u001b[38;5;129;01min\u001b[39;00m gen]\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    727\u001b[0m     history \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/requests/sessions.py:725\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_redirects:\n\u001b[1;32m    723\u001b[0m     \u001b[38;5;66;03m# Redirect resolving generator.\u001b[39;00m\n\u001b[1;32m    724\u001b[0m     gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_redirects(r, request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 725\u001b[0m     history \u001b[38;5;241m=\u001b[39m [resp \u001b[38;5;28;01mfor\u001b[39;00m resp \u001b[38;5;129;01min\u001b[39;00m gen]\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    727\u001b[0m     history \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/requests/sessions.py:266\u001b[0m, in \u001b[0;36mSessionRedirectMixin.resolve_redirects\u001b[0;34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m req\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 266\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madapter_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m     extract_cookies_to_jar(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcookies, prepared_request, resp\u001b[38;5;241m.\u001b[39mraw)\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;66;03m# extract redirect url, if any, for the next loop\u001b[39;00m\n",
      "File \u001b[0;32m/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/urllib3/connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    809\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/urllib3/connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/urllib3/connection.py:466\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    465\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/bin/miniconda3/envs/QL_1/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/bin/miniconda3/envs/QL_1/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/bin/miniconda3/envs/QL_1/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/bin/miniconda3/envs/QL_1/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from urllib.parse import urlencode\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update({\n",
    "    \"collection_hash_id\": COLLECTION_ARGS[\"hash_id\"],\n",
    "    \"await_embedding\": True\n",
    "})\n",
    "\n",
    "encoded_params = urlencode({\"parameters\": json.dumps(input)})\n",
    "\n",
    "for i, path in enumerate([PDF_TO_UPLOAD_PATH, PDF_TO_UPLOAD_PATH, LARGE_PDF_TO_UPLOAD_PATH]):\n",
    "    with open(path, 'rb') as f:\n",
    "        # Define the files parameter for the POST request\n",
    "        files = {'file': f}\n",
    "        input_json = json.dumps(input)\n",
    "        response = requests.post(\"http://localhost:8000/upload_document?\"+encoded_params, files=files)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        result = response.json()\n",
    "        f.close()\n",
    "\n",
    "        print(json.dumps(result, indent=4))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"title\": \"test_collection_1_modified\",\n",
      "        \"description\": \"test description please ignore\",\n",
      "        \"type\": \"user\",\n",
      "        \"owner\": \"personal\",\n",
      "        \"public\": false,\n",
      "        \"document_list\": [\n",
      "            {\n",
      "                \"title\": \"HNRS3035_08_22_2023_MLIntro.pdf\",\n",
      "                \"hash_id\": \"f74235c39d351e078c64f0df733adfc413b062a7f866dde3ad92d892f3ca9fe2\",\n",
      "                \"size\": \"481.7 KB\"\n",
      "            },\n",
      "            {\n",
      "                \"title\": \"HNRS3035_08_22_2023_MLIntro.pdf\",\n",
      "                \"hash_id\": \"08bd0cad1e9ccd763a3029819ac2b2e9d821ecf9cb48e0728589ac7030a75de6\",\n",
      "                \"size\": \"481.7 KB\"\n",
      "            },\n",
      "            {\n",
      "                \"title\": \"stats_book.pdf\",\n",
      "                \"hash_id\": \"f8546d1cf9c3d4526192f66a08e5639b729db2aadc20ab033a60791d1cb907dc\",\n",
      "                \"size\": \"7.1 MB\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Get new doc ids\n",
    "\n",
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "add_user_input = deepcopy(USER_ARGS_1)\n",
    "add_user_input.update({\n",
    "    \"collection_hash_id\": COLLECTION_ARGS[\"hash_id\"],\n",
    "})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/fetch_collection\", json=add_user_input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "DOC_ARGS_1 = {\"hash_id\": result[\"result\"][\"document_list\"][0][\"hash_id\"]}\n",
    "DOC_ARGS_2 = {\"hash_id\": result[\"result\"][\"document_list\"][1][\"hash_id\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `delete_document`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update(DOC_ARGS_1)\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/delete_document\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `get_document_secure`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"auth\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VybmFtZSI6ImYzNjQ4NjI1LTFjZGUtNDE4Ny1iYjNkLTA0MzUyNjhhIiwicHdkX2hhc2giOiIyYjYxOGU1MDVlNWJjZDEyMjI1ZWRiODg2YjM3OTI4MzIwZmNhODE3NmU3Yzc4N2I5YmRlM2QyMzNiNzYzMjhkIiwiZXhwIjoxNzE5NzAzNzI2fQ.4m-WhwQKHuU7y0CplUdiKsyNwvskyjMLTZoNzbbD8qo\",\n",
      "    \"hash_id\": \"08bd0cad1e9ccd763a3029819ac2b2e9d821ecf9cb48e0728589ac7030a75de6\"\n",
      "}\n",
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"password\": \"15f1dc25dde41f386d07156dd40b6a3f40e5717ee9d820a59097590b85ad252c\",\n",
      "        \"hash_id\": \"08bd0cad1e9ccd763a3029819ac2b2e9d821ecf9cb48e0728589ac7030a75de6\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update(DOC_ARGS_2)\n",
    "\n",
    "print(json.dumps(input, indent=4))\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/get_document_secure\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `query_database`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection Hash: 960b6cd17b707103a29598c1dad153f7bc045c4dbd4226e1dfe2b467b3d18402\n",
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "# input = deepcopy(USER_ARGS_1)\n",
    "\n",
    "input = {\n",
    "    \"auth\": {\"api_key\": API_KEY_1}\n",
    "}\n",
    "\n",
    "# input.update({\n",
    "#     # \"query\": [\"Riemann Roch Theorem\"],\n",
    "#     \"query\": [\"Huey Newton\", \"What is representation learning?\", \"What is an artificial neural network?\"],\n",
    "#     # \"query\": \"Who is Catherine?\",\n",
    "#     \"collection_ids\": [COLLECTION_ARGS[\"hash_id\"]],\n",
    "#     \"use_lexical\": True,\n",
    "#     \"use_embeddings\": True,\n",
    "#     # \"rerank_question\": \"What is the purpose of the Riemann Roch Theorem?\",\n",
    "#     # \"rerank_question\": \"What is Representation Learning?\",\n",
    "#     \"rerank_question\": \"Who is Huey Newton?\",\n",
    "#     \"use_rerank\": True,\n",
    "#     \"use_web\": True,\n",
    "#     \"k\": 20,\n",
    "#     \"minimum_relevance\": 0,\n",
    "# })\n",
    "\n",
    "input.update({\n",
    "    \"query\": \"Who is Huey Newton?\",\n",
    "    \"collection_ids\": [],\n",
    "    \"k\": 5,\n",
    "    \"use_lexical\": True,\n",
    "    \"use_embeddings\": True,\n",
    "    \"use_rerank\": True,\n",
    "    \"use_web\": True,\n",
    "    \"rerank_question\": \"Who is Huey Newton?\",\n",
    "    \"ratio\": 0.5,\n",
    "    \"minimum_relevance\": 0\n",
    "})\n",
    "\n",
    "print(\"Collection Hash:\", COLLECTION_ARGS[\"hash_id\"])\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/query_database\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "if \"trace\" in result:\n",
    "    print(result[\"trace\"])\n",
    "    \n",
    "assert not (\"success\" in result and result[\"success\"] == False), json.dumps(result[\"trace\"], indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `craft_document_access_token`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"file_name\": \"HNRS3035_08_22_2023_MLIntro.pdf\",\n",
      "        \"access_encrypted\": \"0401a6d5d22e3acff1584f690c9392398abb835f6c3a9b6529bc9c69592ae90ffcf5f28cbb76fb8683f34c40f309460469cfed08112504fc598e77f72b52e9b6a3743741b6f8b0eb371aa1c0cca3d5e34161609a42d56c9d504d4c443ae8cc263d2638c2d861550f359bba62ff726e34b11ea8c67ea43d612595d02a39a15d7ab941dcd4191e33029401861a2993d85f935380cec92a0cf366a9694f3dd986da5d1df4a32507b80236343e1b1594561234292b217936650fde4b61a07e5cea1c68f747a3eeda099ddd686a780162a32018c0d2587b7f53c1dd3dc2abe2ff69742d98b823965caba8b9557d01e2dba0ef2b08f735c157bbb274e03951c29f23ffc9dbea5a8d31ca4f2bdd5bbe9f099ad651703da3168764e9b97f4589862657066d7065531ade8b4cb052d062faeede47afd08dda08432c00b6f44c0a8f7e83312f846cb7065c6dd1243f385fc902f4bac341d2c7e7e026c450840d78a36ac1c3a0683d7df3f68541731f750bd4704187f7f02065e99980baba628381b18faa208222ba3c637bc8a92aca4b28b638230ef959898958a998c61a7117a4a43b0c799f38f973035d34b5ee893f060a3a3c8a6e6d1b28a2b0cda9e24e36e9de93fe69ee65f5a2d14f6a67f17f428f8e78a8d71883a78773adc03a91b827b6352289d0af50dbfde80770e80fa3322dd58b73805860c6dc9b53691371caf5eacab5915d159024718826ba920b2a04b9ea5e1b92151fdd230c0e177bd68b59195bd1bb6386028bf9cbdad4897005f4ca078402a3f5a8dc70c867eb9e8df0f2f2ea7853520fc82045d9eb45d39091830ede2f5afdcddbe5897970e198b942d9a31e97465eca2caf34219037b3cfd2402b12abc23011beea2d33742ee087bedf7f4a485113e0ce2dc936bfdd1d76ee7c154b10b1d664ffc70889a2ec4254b4cf425e2e545c1fe90e98bcc6bdaa02e5c658c089\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update(DOC_ARGS_2)\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/craft_document_access_token\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "DOCUMENT_AUTH_ACCESS = {\"document_auth_access\": result[\"result\"][\"access_encrypted\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `fetch_document`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8000/fetch_document?parameters=%7B%22document_auth_access%22%3A+%220401a6d5d22e3acff1584f690c9392398abb835f6c3a9b6529bc9c69592ae90ffcf5f28cbb76fb8683f34c40f309460469cfed08112504fc598e77f72b52e9b6a3743741b6f8b0eb371aa1c0cca3d5e34161609a42d56c9d504d4c443ae8cc263d2638c2d861550f359bba62ff726e34b11ea8c67ea43d612595d02a39a15d7ab941dcd4191e33029401861a2993d85f935380cec92a0cf366a9694f3dd986da5d1df4a32507b80236343e1b1594561234292b217936650fde4b61a07e5cea1c68f747a3eeda099ddd686a780162a32018c0d2587b7f53c1dd3dc2abe2ff69742d98b823965caba8b9557d01e2dba0ef2b08f735c157bbb274e03951c29f23ffc9dbea5a8d31ca4f2bdd5bbe9f099ad651703da3168764e9b97f4589862657066d7065531ade8b4cb052d062faeede47afd08dda08432c00b6f44c0a8f7e83312f846cb7065c6dd1243f385fc902f4bac341d2c7e7e026c450840d78a36ac1c3a0683d7df3f68541731f750bd4704187f7f02065e99980baba628381b18faa208222ba3c637bc8a92aca4b28b638230ef959898958a998c61a7117a4a43b0c799f38f973035d34b5ee893f060a3a3c8a6e6d1b28a2b0cda9e24e36e9de93fe69ee65f5a2d14f6a67f17f428f8e78a8d71883a78773adc03a91b827b6352289d0af50dbfde80770e80fa3322dd58b73805860c6dc9b53691371caf5eacab5915d159024718826ba920b2a04b9ea5e1b92151fdd230c0e177bd68b59195bd1bb6386028bf9cbdad4897005f4ca078402a3f5a8dc70c867eb9e8df0f2f2ea7853520fc82045d9eb45d39091830ede2f5afdcddbe5897970e198b942d9a31e97465eca2caf34219037b3cfd2402b12abc23011beea2d33742ee087bedf7f4a485113e0ce2dc936bfdd1d76ee7c154b10b1d664ffc70889a2ec4254b4cf425e2e545c1fe90e98bcc6bdaa02e5c658c089%22%7D\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from urllib.parse import urlencode\n",
    "from copy import deepcopy\n",
    "\n",
    "# input = deepcopy(USER_ARGS_1)\n",
    "input = deepcopy(DOCUMENT_AUTH_ACCESS)\n",
    "\n",
    "encoded_params = urlencode({\"parameters\": json.dumps(input)})\n",
    "\n",
    "print(\"http://localhost:8000/fetch_document?\"+encoded_params)\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/fetch_document?\"+encoded_params)\n",
    "response.raise_for_status()\n",
    "\n",
    "# result = response.json()\n",
    "\n",
    "# print(json.dumps(result, indent=4))\n",
    "# assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `create_organization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"organization_id\": \"0d582f04ff7edfd42ca86b868604bb95c1f1af314731e78c8cf1e28f91b7288b\",\n",
      "        \"organization_dict\": {\n",
      "            \"name\": \"test_org\",\n",
      "            \"hash_id\": \"f8f61ab1b3fca2f6fd6b43a10b6fd9d49d1ef9e1660e4df115b0724f5febb372\",\n",
      "            \"public_key\": \"7ec7bd8105d007d9452ca149f37b346c72ce7aabeef30e1026a1972bcd206c7c409b31cddc4e80143249264e7233f2b3239fbbdb8e1304e955a931b6cbeb5465\",\n",
      "            \"openai_organization_id_encrypted\": null,\n",
      "            \"id\": \"0d582f04ff7edfd42ca86b868604bb95c1f1af314731e78c8cf1e28f91b7288b\",\n",
      "            \"creation_timestamp\": 1717111837.8064487,\n",
      "            \"serp_api_key_encrypted\": null\n",
      "        },\n",
      "        \"membership_dict\": {}\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update({\n",
    "    \"organization_name\": \"test_org\",\n",
    "})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/create_organization\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "\n",
    "ORG_ARGS = result[\"result\"][\"organization_dict\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `set_organization_openai_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update({\n",
    "    \"openai_organization_id\": \"org-1111111111111111111111111\"\n",
    "})\n",
    "input.update({\n",
    "    \"organization_hash_id\": ORG_ARGS[\"hash_id\"]\n",
    "})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/set_organization_openai_id\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `invite_user_to_organization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update({\n",
    "    \"username_to_invite\": USERNAME_2,\n",
    "    \"organization_id\": ORG_ARGS[\"id\"],\n",
    "    \"member_class\": \"member\"\n",
    "})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/invite_user_to_organization\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `fetch_memberships`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"memberships\": [\n",
      "            {\n",
      "                \"organization_id\": \"0d582f04ff7edfd42ca86b868604bb95c1f1af314731e78c8cf1e28f91b7288b\",\n",
      "                \"organization_name\": \"test_org\",\n",
      "                \"role\": \"member\",\n",
      "                \"invite_still_open\": true,\n",
      "                \"sender\": \"f3648625-1cde-4187-bb3d-0435268a\"\n",
      "            }\n",
      "        ],\n",
      "        \"admin\": false\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_2)\n",
    "input.update({\n",
    "    \"return_subset\" : \"all\"\n",
    "})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/fetch_memberships\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]\n",
    "INVITATION = result[\"result\"][\"memberships\"][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `resolve_organization_invitation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_2)\n",
    "input.update({\n",
    "    \"organization_id\": INVITATION[\"organization_id\"],\n",
    "    \"accept\": True\n",
    "})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/resolve_organization_invitation\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `fetch_memberships_of_organization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"memberships\": [\n",
      "            {\n",
      "                \"organization_id\": \"0d582f04ff7edfd42ca86b868604bb95c1f1af314731e78c8cf1e28f91b7288b\",\n",
      "                \"organization_name\": \"test_org\",\n",
      "                \"role\": \"owner\",\n",
      "                \"username\": \"f3648625-1cde-4187-bb3d-0435268a\",\n",
      "                \"invite_still_open\": false\n",
      "            },\n",
      "            {\n",
      "                \"organization_id\": \"0d582f04ff7edfd42ca86b868604bb95c1f1af314731e78c8cf1e28f91b7288b\",\n",
      "                \"organization_name\": \"test_org\",\n",
      "                \"role\": \"member\",\n",
      "                \"username\": \"7c3b439b-5472-4c2b-8aab-54c5cfb6\",\n",
      "                \"invite_still_open\": false\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update({\n",
    "    \"organization_id\": INVITATION[\"organization_id\"],\n",
    "})\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/fetch_memberships_of_organization\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `set_user_serp_key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User external provider data has been changed. This functionality is deprecated.\n",
    "if False:\n",
    "    import requests, json\n",
    "    from copy import deepcopy\n",
    "\n",
    "    input = deepcopy(USER_ARGS_1)\n",
    "    input.update({\n",
    "        \"serp_key\" : \"test_serp_key\"\n",
    "    })\n",
    "\n",
    "    response = requests.get(\"http://localhost:8000/api/set_user_serp_key\", json=input)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    result = response.json()\n",
    "\n",
    "    print(json.dumps(result, indent=4))\n",
    "    assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `set_organization_serp_key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User external provider data has been changed. This functionality is deprecated.\n",
    "if False:\n",
    "    import requests, json\n",
    "    from copy import deepcopy\n",
    "\n",
    "    input = deepcopy(USER_ARGS_1)\n",
    "    input.update({\n",
    "        \"serp_key\" : \"test_serp_key\",\n",
    "        \"organization_hash_id\": ORG_ARGS[\"hash_id\"]\n",
    "    })\n",
    "\n",
    "    response = requests.get(\"http://localhost:8000/api/set_organization_serp_key\", json=input)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    result = response.json()\n",
    "\n",
    "    print(json.dumps(result, indent=4))\n",
    "    assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `get_serp_key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User external provider data has been changed. This functionality is deprecated.\n",
    "if False:\n",
    "    import requests, json\n",
    "    from copy import deepcopy\n",
    "\n",
    "    input = deepcopy(USER_ARGS_1)\n",
    "\n",
    "    response = requests.get(\"http://localhost:8000/api/get_serp_key\", json=input)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    result = response.json()\n",
    "\n",
    "    print(json.dumps(result, indent=4))\n",
    "    assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ❌ `search_google`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # Not implemented yet\n",
    "    import requests, json\n",
    "    from copy import deepcopy\n",
    "\n",
    "    input = deepcopy(USER_ARGS_1)\n",
    "\n",
    "    response = requests.get(\"http://localhost:8000/api/search_google\", json=input)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    result = response.json()\n",
    "\n",
    "    print(json.dumps(result, indent=4))\n",
    "    assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ❌ `perform_search_query`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # Not implemented yet.\n",
    "    import requests, json\n",
    "    from copy import deepcopy\n",
    "\n",
    "    input = deepcopy(USER_ARGS_1)\n",
    "\n",
    "    response = requests.get(\"http://localhost:8000/api/perform_search_query\", json=input)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    result = response.json()\n",
    "\n",
    "    print(json.dumps(result, indent=4))\n",
    "    assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `embed_urls`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Riemann–Roch theorem - Wikipedia\n",
      "\n",
      "[Jump to content](#bodyContent)\n",
      "\n",
      "Main menu\n",
      "\n",
      "Main menu\n",
      "move to sidebar\n",
      "hide\n",
      "\n",
      " Navigation\n",
      " \n",
      "\n",
      "* [Main page](/wiki/Main_Page \"Visit the main page [alt-shift-z]\")\n",
      "* [Contents](/wiki/Wikipedia:Contents \"Guides to browsing Wikipedia\")\n",
      "* [Current events](/wiki/Portal:Current_events \"Articles related to current events\")\n",
      "* [Random article](/wiki/Special:Random \"Visit a randomly selected article [alt-shift-x]\")\n",
      "* [About Wikipedia](/wiki/Wikipedia:About \"Learn about Wikipedia and how it works\")\n",
      "* [Contact us](//en.wikipedia.org/wiki/Wikipedia:Contact_us \"How to contact Wikipedia\")\n",
      "* [Donate](https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en \"Support us by donating to the Wikimedia Foundation\")\n",
      "\n",
      " Contribute\n",
      " \n",
      "\n",
      "* [Help](/wiki/Help:Contents \"Guidance on how to use and edit Wikipedia\")\n",
      "* [Learn to edit](/wiki/Help:Introduction \"Learn how to edit Wikipedia\")\n",
      "* [Community portal](/wiki/Wikipedia:Community_portal \"The hub for editors\")\n",
      "* [Recent changes](/wiki/Special:RecentChanges \"A list of recent changes to Wikipedia [alt-shift-r]\")\n",
      "* [Upload file](/wiki/Wikipedia:File_upload_wizard \"Add images or other media for use on Wikipedia\")\n",
      "\n",
      "[![](/static/images/icons/wikipedia.png)\n",
      "\n",
      "![Wikipedia](/static/images/mobile/copyright/wikipedia-wordmark-en.svg)\n",
      "![The Free Encyclopedia](/static/images/mobile/copyright/wikipedia-tagline-en.svg)](/wiki/Main_Page)\n",
      "\n",
      "[Search](/wiki/Special:Search \"Search Wikipedia [alt-shift-f]\")\n",
      "\n",
      "Search\n",
      "\n",
      "* [Create account](/w/index.php?title=Special:CreateAccount&returnto=Riemann%E2%80%93Roch+theorem \"You are encouraged to create an account and log in; however, it is not mandatory\")\n",
      "* [Log in](/w/index.php?title=Special:UserLogin&returnto=Riemann%E2%80%93Roch+theorem \"You're encouraged to log in; however, it's not mandatory. [alt-shift-o]\")\n",
      "\n",
      "Personal tools\n",
      "\n",
      "* [Create account](/w/index.php?title=Special:CreateAccount&returnto=Riemann%E2%80%93\n",
      "{'title': 'Riemann–Roch theorem - Wikipedia', 'url': 'https://en.wikipedia.org/wiki/Riemann%E2%80%93Roch_theorem', 'type': 'website'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Huey P. Newton - Wikipedia\n",
      "\n",
      "[Jump to content](#bodyContent)\n",
      "\n",
      "Main menu\n",
      "\n",
      "Main menu\n",
      "move to sidebar\n",
      "hide\n",
      "\n",
      " Navigation\n",
      " \n",
      "\n",
      "* [Main page](/wiki/Main_Page \"Visit the main page [alt-shift-z]\")\n",
      "* [Contents](/wiki/Wikipedia:Contents \"Guides to browsing Wikipedia\")\n",
      "* [Current events](/wiki/Portal:Current_events \"Articles related to current events\")\n",
      "* [Random article](/wiki/Special:Random \"Visit a randomly selected article [alt-shift-x]\")\n",
      "* [About Wikipedia](/wiki/Wikipedia:About \"Learn about Wikipedia and how it works\")\n",
      "* [Contact us](//en.wikipedia.org/wiki/Wikipedia:Contact_us \"How to contact Wikipedia\")\n",
      "* [Donate](https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en \"Support us by donating to the Wikimedia Foundation\")\n",
      "\n",
      " Contribute\n",
      " \n",
      "\n",
      "* [Help](/wiki/Help:Contents \"Guidance on how to use and edit Wikipedia\")\n",
      "* [Learn to edit](/wiki/Help:Introduction \"Learn how to edit Wikipedia\")\n",
      "* [Community portal](/wiki/Wikipedia:Community_portal \"The hub for editors\")\n",
      "* [Recent changes](/wiki/Special:RecentChanges \"A list of recent changes to Wikipedia [alt-shift-r]\")\n",
      "* [Upload file](/wiki/Wikipedia:File_upload_wizard \"Add images or other media for use on Wikipedia\")\n",
      "\n",
      "[![](/static/images/icons/wikipedia.png)\n",
      "\n",
      "![Wikipedia](/static/images/mobile/copyright/wikipedia-wordmark-en.svg)\n",
      "![The Free Encyclopedia](/static/images/mobile/copyright/wikipedia-tagline-en.svg)](/wiki/Main_Page)\n",
      "\n",
      "[Search](/wiki/Special:Search \"Search Wikipedia [alt-shift-f]\")\n",
      "\n",
      "Search\n",
      "\n",
      "* [Create account](/w/index.php?title=Special:CreateAccount&returnto=Huey+P.+Newton \"You are encouraged to create an account and log in; however, it is not mandatory\")\n",
      "* [Log in](/w/index.php?title=Special:UserLogin&returnto=Huey+P.+Newton \"You're encouraged to log in; however, it's not mandatory. [alt-shift-o]\")\n",
      "\n",
      "Personal tools\n",
      "\n",
      "* [Create account](/w/index.php?title=Special:CreateAccount&returnto=Huey+P.+Newton \"You are encouraged to create an ac\n",
      "{'title': 'Huey P. Newton - Wikipedia', 'url': 'https://en.wikipedia.org/wiki/Huey_P._Newton', 'type': 'website'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(f\"http://localhost:8000/api/embed_urls\", json={\n",
    "    \"auth\": {\"api_key\": API_KEY_1},\n",
    "    \"urls\": [\n",
    "        \"https://en.wikipedia.org/wiki/Riemann%E2%80%93Roch_theorem\",\n",
    "        \"https://en.wikipedia.org/wiki/Huey_P._Newton\"\n",
    "    ]\n",
    "}, stream=False)\n",
    "response.raise_for_status()\n",
    "result = response.json()\n",
    "\n",
    "# print(result)\n",
    "\n",
    "if \"error\" in result:\n",
    "    print(result[\"error\"])\n",
    "    print(result[\"trace\"])\n",
    "else:\n",
    "    for c in result[\"result\"][\"content\"]:\n",
    "        print(c[\"text\"][:min(2000, len(c[\"text\"]))])\n",
    "        print(c[\"metadata\"], end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `api/llm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Riemann-Roch theorem is a fundamental result in algebraic geometry that relates the dimension of the space of sections of a line bundle on a curve to its degree.\n",
      "\n",
      "Let $(X,L)$ be a compact connected complex curve (or Riemann surface) with genus $g$, and let $\\ell\\in \\mathbb{N}$ be an integer. The theorem states that if we consider the vector spaces:\n",
      "\n",
      "* $H^0(X,\\mathcal{O}_X(\\ell))$: the global sections of the trivial line bundle $\\mathcal{O}_X(\\ell)=L^\\otimes\\ell$\n",
      "* $H^1(X,\\mathcal{O}_X(\\ell-1))$: the first cohomology group of the line bundle $\\mathcal{O}_X(\\ell-1)$\n",
      "\n",
      "then their dimensions satisfy the following inequality:\n",
      "\n",
      "$$\\dim H^0(X,\\mathcal{O}_X(\\ell))-\\deg L+\\dim H^1(X,\\mathcal{O}_X(\\ell-1))\\geq 1-g$$\n",
      "\n",
      "where $\\deg L$ denotes the degree of the line bundle $L$. This inequality provides a lower bound for the dimension of the space of sections of the line bundle $\\mathcal{O}_X(\\ell)$.\n",
      "\n",
      "The Riemann-Roch theorem has far-reaching implications in many areas of mathematics, including algebraic geometry, number theory, and topology. It plays a crucial role in understanding the properties of curves and surfaces, and it has numerous applications in computer science, physics, and engineering.\n",
      "\n",
      "Here's a more detailed version of the theorem, using the language of sheaf cohomology:\n",
      "\n",
      "**Riemann-Roch Theorem**\n",
      "\n",
      "Let $(X,\\mathscr{O}_X)$ be a compact connected complex curve with genus $g$, and let $\\ell\\in \\mathbb{N}$. Then for any invertible sheaf $L$ on $X$, we have:\n",
      "\n",
      "$$\\chi(L):=\\sum_{i=0}^{2}\\left(-1\\right)^{i}\\cdot\\dim H^{i}(X,L)\\geq\\deg L+1-g$$\n",
      "\n",
      "where $\\chi(L)$ is called the Euler characteristic of $L$.\n",
      "\n",
      "This theorem can be used to study various geometric objects, such as divisors, line bundles, and curves, by analyzing their cohomological invariants like the Euler characteristic.\n",
      "\n",
      "\n",
      "FINISHED RESPONSE WITH   496 tokens,  100.04 t/s, ( 0.1393 -  5.0871): ['What is the Riemann-Roch theorem?', \"The Riemann-Roch theorem is a fundamental result in algebraic geometry that relates the dimension of the space of sections of a line bundle on a curve to its degree.\\n\\nLet $(X,L)$ be a compact connected complex curve (or Riemann surface) with genus $g$, and let $\\\\ell\\\\in \\\\mathbb{N}$ be an integer. The theorem states that if we consider the vector spaces:\\n\\n* $H^0(X,\\\\mathcal{O}_X(\\\\ell))$: the global sections of the trivial line bundle $\\\\mathcal{O}_X(\\\\ell)=L^\\\\otimes\\\\ell$\\n* $H^1(X,\\\\mathcal{O}_X(\\\\ell-1))$: the first cohomology group of the line bundle $\\\\mathcal{O}_X(\\\\ell-1)$\\n\\nthen their dimensions satisfy the following inequality:\\n\\n$$\\\\dim H^0(X,\\\\mathcal{O}_X(\\\\ell))-\\\\deg L+\\\\dim H^1(X,\\\\mathcal{O}_X(\\\\ell-1))\\\\geq 1-g$$\\n\\nwhere $\\\\deg L$ denotes the degree of the line bundle $L$. This inequality provides a lower bound for the dimension of the space of sections of the line bundle $\\\\mathcal{O}_X(\\\\ell)$.\\n\\nThe Riemann-Roch theorem has far-reaching implications in many areas of mathematics, including algebraic geometry, number theory, and topology. It plays a crucial role in understanding the properties of curves and surfaces, and it has numerous applications in computer science, physics, and engineering.\\n\\nHere's a more detailed version of the theorem, using the language of sheaf cohomology:\\n\\n**Riemann-Roch Theorem**\\n\\nLet $(X,\\\\mathscr{O}_X)$ be a compact connected complex curve with genus $g$, and let $\\\\ell\\\\in \\\\mathbb{N}$. Then for any invertible sheaf $L$ on $X$, we have:\\n\\n$$\\\\chi(L):=\\\\sum_{i=0}^{2}\\\\left(-1\\\\right)^{i}\\\\cdot\\\\dim H^{i}(X,L)\\\\geq\\\\deg L+1-g$$\\n\\nwhere $\\\\chi(L)$ is called the Euler characteristic of $L$.\\n\\nThis theorem can be used to study various geometric objects, such as divisors, line bundles, and curves, by analyzing their cohomological invariants like the Euler characteristic.\"]\n"
     ]
    }
   ],
   "source": [
    "import requests, json, time\n",
    "from copy import deepcopy\n",
    "\n",
    "prompt = \"What is the Riemann-Roch theorem?\"\n",
    "\n",
    "def run_llm_test(prompt_input, parameters={}):\n",
    "\tsystem_instruction = \"You are a general answering assistant that can comply with any request.\\n\\nYou always answer with markdown formatting. You will be penalized if you do not answer with markdown when it would be possible.\\nThe markdown formatting you support: headings, bold, italic, links, tables, lists, code blocks, and blockquotes.\\nYou do not support images and never include images. You will be penalized if you render images.\\n\\nAlways use markdown code blocks for code, and always use MathJax with LaTeX formatting for pure math expressions.\\nFor example code would look like:\\n```python\\n*Python code here\\n```\\nAnd math expressions would look like:\\n$$P(y|x) = \\\\frac{{P(x|y) \\\\cdot P(y)}}{{P(x)}}$$\"\n",
    "\tprompt_formatted = f\"<s>[INST] <<SYS>>\\n{system_instruction}\\n<</SYS>>\\n{prompt_input} [/INST] \"\n",
    "\tsample_input = {\n",
    "\t\t# \"model_choice\": \"mistral-7b-instruct-v0.1\",\n",
    "\t\t\"stream\": True, \n",
    "\t\t\"max_tokens\": 1000, \n",
    "\t\t\"temperature\": 0.5, \n",
    "\t\t\"top_p\": 0.9, \n",
    "\t\t\"repetition_penalty\": 1.15\n",
    "\t}\n",
    "\tsample_input.update(parameters)\n",
    " \n",
    "\t# input = deepcopy(USER_ARGS_1)\n",
    "\tinput = {\n",
    "\t\t\"auth\": {\n",
    "\t\t\t\"username\": USERNAME_1,\n",
    "\t\t\t\"password\": PASSWORD_1\n",
    "\t\t}\n",
    "\t}\n",
    "\tinput.update({\n",
    "\t\t\"model_parameters\": sample_input,\n",
    "\t\t\"question\": prompt_input, \n",
    "\t})\n",
    "\n",
    "\n",
    "\tglobal_start_time = time.time()\n",
    "\n",
    "\tresponse = requests.get(f\"http://localhost:8000/api/llm\", json=input, stream=True)\n",
    "\tresponse.raise_for_status()\n",
    "\tresponse_completed = \"\"\n",
    "\tstart_time, token_count = time.time(), 0\n",
    "\tfor chunk_raw in response.iter_content(chunk_size=None, decode_unicode=False):\n",
    "\t\t# print(chunk_raw)\n",
    "\t\tif token_count == 0:\n",
    "\t\t\tstart_time = time.time()\n",
    "\t\tchunk_decoded = chunk_raw.decode(\"utf-8\")\n",
    "\t\t# print(chunk_decoded)\n",
    "\t\t# chunk = json.loads(chunk_decoded)[\"text\"]\n",
    "\t\tchunk = chunk_decoded\n",
    "\t\tresponse_completed += chunk\n",
    "\t\tprint(chunk, end=\"\")\n",
    "\t\t\n",
    "\t\ttoken_count += 1\n",
    "\tend_time = time.time()\n",
    "\ttime_taken = end_time - start_time\n",
    "\tprint(\"\\n\\n\\nFINISHED RESPONSE WITH %5d tokens, %7.2f t/s, (%7.4f - %7.4f):\" % (token_count, (token_count-1) / time_taken, start_time - global_start_time, end_time - global_start_time), [prompt, response_completed])\n",
    " \n",
    "run_llm_test(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"output\": \"**The Riemann-Roch Theorem**\\n\\nThe Riemann-Roch theorem is a fundamental result in algebraic geometry that relates the dimension of the space of sections of a line bundle on an algebraic curve to the degree of the divisor representing the line bundle.\\n\\nLet's break it down:\\n\\n* **Line Bundle**: A line bundle on an algebraic curve C is a holomorphic vector bundle over C whose fibers are one-dimensional vector spaces (i.e., lines).\\n* **Divisor**: A divisor D on C is a formal linear combination of points on C, where each point has a non-negative integer coefficient.\\n* **Section**: A section s of a line bundle L on C is a global function f: C \\u2192 \\u2102 such that f(x) \\u2208 L_x for all x \\u2208 C.\\n\\nThe Riemann-Roch theorem states that if L is a line bundle on C and D is a divisor on C, then there exists a linear map from the space of sections of L\\u2297\\u2112(D) to H^1(C, L), where \\u2112(D) denotes the line bundle associated to the divisor D, which induces an isomorphism between these two spaces when restricted to the subspace of sections vanishing at infinity.\\n\\nMathematically, this can be expressed as:\\n\\n$$\\\\dim \\\\Gamma(L \\u2297 \\u2112(D)) - \\\\deg(D) + g = \\\\deg(\\\\omega_C \\u2297 L)$$\\n\\nwhere g is the genus of the curve C, \\u03c9_C is the canonical bundle of C, and \\u0393 denotes the space of sections.\\n\\nIn essence, the Riemann-Roch theorem provides a way to compute the dimension of the space of sections of a line bundle on an algebraic curve by relating it to the degree of the divisor representing the line bundle.\\n\\nThis theorem has far-reaching implications in many areas of mathematics, including algebraic geometry, complex analysis, and number theory. It plays a crucial role in understanding various properties of algebraic curves, such as their genera, moduli spaces, and geometric invariants.\\n\\nWould you like me to elaborate further or explore related topics?\",\n",
      "        \"token_count\": 431\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(f\"http://localhost:8000/api/llm\", json={\n",
    "    **USER_ARGS_1, \n",
    "    \"question\": \"What is the Riemann-Roch theorem?\",\n",
    "    \n",
    "})\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With grammar sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"output\": \" \\r \\r\\r\\n\\r\\n\\r \\r {\\r\\n\\r\\n  } \\r\\r\\r\\n\\r\\n  \\r\\n\\n\",\n",
      "        \"token_count\": 18\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "ts_scheme = \"\"\"\n",
    "type User = {\n",
    "    name: string;\n",
    "    age: number;\n",
    "    isActive: boolean;\n",
    "};\n",
    "\"\"\"\n",
    "\n",
    "response = requests.get(f\"http://localhost:8000/api/llm\", json={\n",
    "    \"auth\": {\"api_key\": API_KEY_1},\n",
    "    \"model_parameters\": {\n",
    "        \"grammar\": [\"typescript\", ts_scheme]\n",
    "    },\n",
    "    \"question\": \"What is the Riemann-Roch theorem?\",\n",
    "})\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "if \"trace\" in result:\n",
    "\tprint(result[\"trace\"])\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regex Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"output\": \"1/2/2023\",\n",
      "        \"token_count\": 7\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "regex_scheme = r'(0?[1-9]|1[0-2])\\/(0?[1-9]|1\\d|2\\d|3[01])\\/(19|20)\\d{2}'\n",
    "# regex_scheme = r'(.*?)'\n",
    "\n",
    "response = requests.get(f\"http://localhost:8000/api/llm\", json={\n",
    "    \"auth\": {\"api_key\": API_KEY_1},\n",
    "    \"model_parameters\": {\n",
    "        \"grammar\": [\"regex\", regex_scheme],\n",
    "        # \"max_tokens\": 100\n",
    "    },\n",
    "    \"question\": \"Who is Oda? Write it as a JSON.\",\n",
    "})\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "if \"trace\" in result:\n",
    "\tprint(result[\"trace\"])\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"success\":true,\"result\":{\"output\":\"The Riemann-Roch theorem is a fundamental result in algebraic geometry that relates the dimension of the space of sections of a line bundle on an algebraic curve to its degree.\\n\\nLet's break it down:\\n\\n**Riemann-Hurwitz Formula**: The Riemann-Hurwitz formula gives us a way to compute the genus (a measure of curvature) of a branched cover of curves. It states that if we have a finite morphism π: C → D between two smooth projective curves, then the genus of C is given by:\\n\\ng(C) = g(D) + 1 - n + Σ(ρ_i - 1)\\n\\nwhere n is the number of points where π is not injective, ρi is the ramification index at each such point, and Σ denotes summation over all these points.\\n\\n**Riemann-Roch Theorem**: Now, let L be a line bundle on a smooth projective curve C. We can define the **Chern character** of L as:\\n\\nch(L) = deg(L) + χ(O_C ⊗ L)\\n\\nHere, χ(O_C ⊗ L) is the Euler characteristic of O_C ⊗ L, which is defined using the cohomology groups H^k(C, O_C ⊗ L).\\n\\nThe Riemann-Roch theorem states that:\\n\\nch(L) = deg(L) + χ(O_C ⊗ L) ≥ dim(H^0(C, L)) - dim(H^1(C, L))\\n\\nThis inequality provides a lower bound for the dimension of the space of global sections of L, in terms of its degree and the cohomology of O_C ⊗ L.\\n\\n**Interpretations**: There are several ways to interpret this theorem. One common approach is to use it to study the behavior of line bundles under various operations like tensor product, pullback, or restriction. Another perspective is to view the Riemann-Roch theorem as a tool for computing the Chern characters of line bundles, which are essential in many areas of mathematics and physics.\\n\\nI hope this helps! Do you have any specific questions about the Riemann-Roch theorem or would you like me to elaborate on certain aspects?\",\"token_count\":451}}\n",
      "The Riemann-Roch theorem is a fundamental result in algebraic geometry that relates the dimension of the space of sections of a line bundle on an algebraic curve to its degree.\n",
      "\n",
      "Let's break it down:\n",
      "\n",
      "**Riemann-Hurwitz Formula**: The Riemann-Hurwitz formula gives us a way to compute the genus (a measure of curvature) of a branched cover of curves. It states that if we have a finite morphism π: C → D between two smooth projective curves, then the genus of C is given by:\n",
      "\n",
      "g(C) = g(D) + 1 - n + Σ(ρ_i - 1)\n",
      "\n",
      "where n is the number of points where π is not injective, ρi is the ramification index at each such point, and Σ denotes summation over all these points.\n",
      "\n",
      "**Riemann-Roch Theorem**: Now, let L be a line bundle on a smooth projective curve C. We can define the **Chern character** of L as:\n",
      "\n",
      "ch(L) = deg(L) + χ(O_C ⊗ L)\n",
      "\n",
      "Here, χ(O_C ⊗ L) is the Euler characteristic of O_C ⊗ L, which is defined using the cohomology groups H^k(C, O_C ⊗ L).\n",
      "\n",
      "The Riemann-Roch theorem states that:\n",
      "\n",
      "ch(L) = deg(L) + χ(O_C ⊗ L) ≥ dim(H^0(C, L)) - dim(H^1(C, L))\n",
      "\n",
      "This inequality provides a lower bound for the dimension of the space of global sections of L, in terms of its degree and the cohomology of O_C ⊗ L.\n",
      "\n",
      "**Interpretations**: There are several ways to interpret this theorem. One common approach is to use it to study the behavior of line bundles under various operations like tensor product, pullback, or restriction. Another perspective is to view the Riemann-Roch theorem as a tool for computing the Chern characters of line bundles, which are essential in many areas of mathematics and physics.\n",
      "\n",
      "I hope this helps! Do you have any specific questions about the Riemann-Roch theorem or would you like me to elaborate on certain aspects?"
     ]
    }
   ],
   "source": [
    "import requests, json, time\n",
    "\n",
    "\n",
    "response = requests.get(f\"http://localhost:8000/api/llm\", json={\n",
    "    \"auth\": {\"api_key\": API_KEY_1},\n",
    "    \"question\": \"What is the Riemann-Roch theorem?\"\n",
    "})\n",
    "response.raise_for_status()\n",
    "response_completed = \"\"\n",
    "start_time, token_count = time.time(), 0\n",
    "for chunk_raw in response.iter_content(chunk_size=None, decode_unicode=True):\n",
    "    chunk_decoded = chunk_raw\n",
    "    print(chunk_decoded)\n",
    "    chunk : dict = json.loads(chunk_decoded)\n",
    "    # print(chunk[\"result\"].keys())\n",
    "    \n",
    "    response_completed += chunk[\"result\"][\"output\"]\n",
    "    print(chunk[\"result\"][\"output\"], end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State Question Standalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': 'What is a recursive neural network? How does it compare to LSTMs?'}\n",
      "{'success': True, 'result': {'output': 'Can you explain what a recursive neural network is and how it compares to Long Short-Term Memory (LSTM) networks in terms of their ability to process sequential data and handle long-term dependencies?', 'token_count': 40}}\n"
     ]
    }
   ],
   "source": [
    "import requests, json, time\n",
    "\n",
    "\n",
    "e_1 = \"\"\"\n",
    "Which theorem allows us to measure the extent to which the fundamental theorem of calculus fails at high dimensional manifolds?\n",
    "\"\"\".strip()\n",
    "\n",
    "e_2 = \"\"\"\n",
    "The theorem you're referring to is likely the **Asymptotic Formula** or **Logarithmic Correction**, also known as the **Gaussian Integral Asymptotics**.\n",
    "\n",
    "This result provides an estimate on how well the Fundamental Theorem of Calculus (FTC) approximates the integral of a function over a high-dimensional manifold. Specifically, it shows that the FTC's error grows logarithmically with the dimensionality of the manifold.\n",
    "\n",
    "In more detail, let's consider a compact Riemannian manifold M of dimension n. Suppose we have a smooth function f on M. Then, the asymptotic formula states that:\n",
    "\n",
    "$$\\int_M f(x) dx = \\frac{1}{(2\\pi)^{\\frac{n}{2}}} \\int_{\\mathbb{R}^n} f(\\exp_x(y)) J_y dy + O(n^{-1})$$\n",
    "\n",
    "Here, exp_x is the exponential map from the tangent space TxM to M, J_y denotes the Jacobian determinant of this map evaluated at y, and O(n^-1) represents the leading-order term in the large-n expansion.\n",
    "\n",
    "This result shows that the FTC approximation becomes increasingly inaccurate as the dimension n increases. The logarithmic correction term captures this failure of the FTC at high dimensions.\n",
    "\n",
    "Keep in mind that this result has important implications in various areas, such as differential geometry, geometric analysis, and machine learning, where high-dimensional data often arises naturally.\n",
    "\n",
    "Would you like me to elaborate on this topic further or provide references for those interested in exploring the subject in greater depth?\n",
    "\"\"\".strip()\n",
    "\n",
    "e_3 = \"\"\"\n",
    "Tell me more about FTC.\n",
    "\"\"\".strip()\n",
    "\n",
    "e_4 = \"\"\"\n",
    "**The Fundamental Theorem of Calculus (FTC)** is one of the most important and influential results in mathematical history. It establishes a deep connection between two branches of calculus: **differential calculus**, which deals with rates of change and slopes of curves, and **integral calculus**, which studies accumulation of quantities.\n",
    "\n",
    "### Statement of the FTC\n",
    "\n",
    "Let f(x) be a continuous function on [a,b] and let F(x) be the antiderivative of f(x). Then:\n",
    "\n",
    "$$\\int_{a}^{b}f(x)dx=F(b)-F(a)$$\n",
    "\n",
    "In other words, the definite integral of a function can be evaluated by computing the difference between its antiderivative at the upper limit and lower limit.\n",
    "\n",
    "### Underlying Principles\n",
    "\n",
    "1. **Antiderivatives**: The FTC relies heavily on the concept of an antiderivative, which is a function that, when differentiated, returns the original function. Antiderivatives play a crucial role in evaluating definite integrals.\n",
    "2. **Chain Rule**: The chain rule from differential calculus allows us to differentiate composite functions. This is essential in relating derivatives to indefinite integrals.\n",
    "3. **Fundamental Principle of Integration**: This principle states that if F(x) is an antiderivative of f(x), then $\\frac{d}{dx}(c+F(x))=c+f(x)$ for any constant c. This helps connect indefinite integration with definite integration.\n",
    "\n",
    "### Applications of the FTC\n",
    "\n",
    "1. **Area under Curves**: The FTC enables us to calculate the area under curves using definite integrals, making it a powerful tool in physics, engineering, economics, and many other fields.\n",
    "2. **Volume of Solids**: By integrating volumes of solids bounded by surfaces described by functions, we can compute their total volume or surface area.\n",
    "3. **Work and Energy**: In mechanics, the FTC helps determine work done by forces acting along a path, leading to insights into energy transfer and conservation.\n",
    "4. **Optimization Problems**: The FTC is used to solve optimization problems involving maximums or minimums of functions, such as finding the shortest distance or the maximum value of a function.\n",
    "5. **Physics and Engineering**: The FTC has numerous applications in these fields, including modeling population growth, electrical circuits, and fluid dynamics.\n",
    "\n",
    "### Historical Significance\n",
    "\n",
    "The FTC was first formulated by Sir Isaac Newton and German mathematician Gottfried Wilhelm Leibniz independently in the late 17th century. Their work laid the foundation for calculus as we know it today, revolutionizing mathematics, science, and engineering.\n",
    "\n",
    "I hope this introduction to the Fundamental Theorem of Calculus has sparked your interest! Do you have any specific questions or topics related to the FTC you'd like me to elaborate on?\n",
    "\"\"\".strip()\n",
    "\n",
    "e_5 = \"\"\"\n",
    "Who discovered it?\n",
    "\"\"\".strip()\n",
    "\n",
    "e_6 = \"\"\"\n",
    "The discovery of the Fundamental Theorem of Calculus (FTC) is attributed to both Sir Isaac Newton and German mathematician Gottfried Wilhelm Leibniz, who developed calculus independently of each other in the late 17th century.\n",
    "\n",
    "**Isaac Newton's Contribution**\n",
    "\n",
    "Newton developed his method of fluxions, which is equivalent to modern-day differentiation. He recognized that the derivative of a position function represents velocity and the second derivative represents acceleration. His work on calculus appeared in his book \"Method of Fluxions\" in 1671.\n",
    "\n",
    "However, Newton did not publish his findings until much later, in 1736, when they were included in his famous book \"Philosophiæ Naturalis Principia Mathematica\". Even then, his work remained largely unknown outside England.\n",
    "\n",
    "**Gottfried Wilhelm Leibniz' Contribution**\n",
    "\n",
    "Leibniz, on the other hand, published his work on calculus in 1684, introducing the notation of dx and dy for infinitesimal changes in x and y, respectively. He also introduced the notation of the integral sign ∫, which is still widely used today.\n",
    "\n",
    "Leibniz communicated his discoveries to the Royal Academy of Sciences in Paris, where they gained popularity among European mathematicians. As a result, he is often credited with being the first to publish the fundamental theorem of calculus.\n",
    "\n",
    "**Collaboration and Controversy**\n",
    "\n",
    "Although both Newton and Leibniz worked independently, there is evidence suggesting that they may have influenced each other's work indirectly through correspondence with common acquaintances. However, the exact nature of their collaboration remains unclear due to limited documentation.\n",
    "\n",
    "A bitter dispute over priority and credit for the invention of calculus ensued between Newton and Leibniz, with some mathematicians siding with Newton and others with Leibniz. Today, both men are acknowledged as co-developers of calculus, and their contributions continue to shape our understanding of the world around us.\n",
    "\n",
    "Would you like to explore more about the development of calculus or its applications?\n",
    "\"\"\"\n",
    "\n",
    "e_7 = \"\"\"\n",
    "What is a recursive neural network? How does it compare to LSTMs?\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "TEST_CHAT_HISTORY = [\n",
    "    # {\"role\": \"user\", \"content\": \"Where is Afghanistan?\"},\n",
    "    # {\"role\": \"assistant\", \"content\": \"Afghanistan is located in south-central Asia\"},\n",
    "    # {\"role\": \"user\", \"content\": \"What is the capital?\"},\n",
    "    {\"role\": \"user\", \"content\": e_1},\n",
    "    {\"role\": \"assistant\", \"content\": e_2},\n",
    "    {\"role\": \"user\", \"content\": e_3},\n",
    "    {\"role\": \"assistant\", \"content\": e_4},\n",
    "    {\"role\": \"user\", \"content\": e_5},\n",
    "    {\"role\": \"assistant\", \"content\": e_6},\n",
    "    {\"role\": \"user\", \"content\": e_7},\n",
    "]\n",
    "print(TEST_CHAT_HISTORY[-1])\n",
    "\n",
    "response = requests.get(f\"http://localhost:8000/api/llm_isolate_question\", json={\n",
    "    \"auth\": {\"api_key\": API_KEY_1},\n",
    "    \"chat_history\": TEST_CHAT_HISTORY\n",
    "}, stream=False)\n",
    "response.raise_for_status()\n",
    "result = response.json()\n",
    "\n",
    "print(result)\n",
    "\n",
    "if \"error\" in result:\n",
    "    print(result[\"error\"])\n",
    "    print(result[\"trace\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Step Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': False, 'error': '\\x1b[36mray::ServeReplica:default:VLLMDeploymentClass.handle_request_with_rejection()\\x1b[39m (pid=1729613, ip=167.96.96.59, actor_id=300e834785294afb218a0bb701000000, repr=<ray.serve._private.replica.ServeReplica:default:VLLMDeploymentClass object at 0x77868b300880>)\\n    async for result in self._call_user_generator(\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 460, in _call_user_generator\\n    raise e from None\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1150, in call_user_method\\n    raise e from None\\nray.exceptions.RayTaskError: \\x1b[36mray::ServeReplica:default:VLLMDeploymentClass.handle_request_with_rejection()\\x1b[39m (pid=1729613, ip=167.96.96.59)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/utils.py\", line 168, in wrap_to_ray_error\\n    raise exception\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1131, in call_user_method\\n    result = await self._handle_user_method_result(\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1038, in _handle_user_method_result\\n    async for r in result:\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 666, in generate\\n    raise e\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 660, in generate\\n    async for request_output in stream:\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 77, in __anext__\\n    raise result\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 38, in _raise_exception_on_finish\\n    task.result()\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 501, in run_engine_loop\\n    has_requests_in_progress = await asyncio.wait_for(\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/asyncio/tasks.py\", line 445, in wait_for\\n    return fut.result()\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 475, in engine_step\\n    request_outputs = await self.engine.step_async()\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 221, in step_async\\n    output = await self.model_executor.execute_model_async(\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/executor/gpu_executor.py\", line 148, in execute_model_async\\n    output = await make_async(self.driver_worker.execute_model\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\\n    result = self.fn(*self.args, **self.kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\\n    return func(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/worker/worker.py\", line 249, in execute_model\\n    output = self.model_runner.execute_model(seq_group_metadata_list,\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\\n    return func(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/worker/model_runner.py\", line 808, in execute_model\\n    hidden_states = model_executable(**execute_model_kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 364, in forward\\n    hidden_states = self.model(input_ids, positions, kv_caches,\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 291, in forward\\n    hidden_states, residual = layer(\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 243, in forward\\n    hidden_states = self.mlp(hidden_states)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 77, in forward\\n    gate_up, _ = self.gate_up_proj(x)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py\", line 281, in forward\\n    output_parallel = self.quant_method.apply(self, input_, bias)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/awq.py\", line 169, in apply\\n    out = torch.matmul(reshaped_x, out)\\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 114.00 MiB. GPU', 'trace': 'Traceback (most recent call last):\\n  File \"/home/kmccleary/projects/QueryLakeDevelopment/QueryLakeBackend/./server.py\", line 432, in api_general_call\\n    args_get = await function_actual(**true_args)\\n  File \"/home/kmccleary/projects/QueryLakeDevelopment/QueryLakeBackend/QueryLake/api/custom_model_functions/multi_search.py\", line 143, in llm_multistep_search\\n    current_response = await llm_call(\\n  File \"/home/kmccleary/projects/QueryLakeDevelopment/QueryLakeBackend/./server.py\", line 288, in llm_call\\n    async for result in stream_results_tokens(gen, on_new_token=on_new_token, stop_sequences=stop_sequences):\\n  File \"/home/kmccleary/projects/QueryLakeDevelopment/QueryLakeBackend/QueryLake/misc_functions/server_class_functions.py\", line 34, in stream_results_tokens\\n    async for request_output in results_generator:\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/handle.py\", line 663, in __anext__\\n    return await next_obj_ref\\nray.exceptions.RayTaskError(OutOfMemoryError): \\x1b[36mray::ServeReplica:default:VLLMDeploymentClass.handle_request_with_rejection()\\x1b[39m (pid=1729613, ip=167.96.96.59, actor_id=300e834785294afb218a0bb701000000, repr=<ray.serve._private.replica.ServeReplica:default:VLLMDeploymentClass object at 0x77868b300880>)\\n    async for result in self._call_user_generator(\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 460, in _call_user_generator\\n    raise e from None\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1150, in call_user_method\\n    raise e from None\\nray.exceptions.RayTaskError: \\x1b[36mray::ServeReplica:default:VLLMDeploymentClass.handle_request_with_rejection()\\x1b[39m (pid=1729613, ip=167.96.96.59)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/utils.py\", line 168, in wrap_to_ray_error\\n    raise exception\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1131, in call_user_method\\n    result = await self._handle_user_method_result(\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1038, in _handle_user_method_result\\n    async for r in result:\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 666, in generate\\n    raise e\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 660, in generate\\n    async for request_output in stream:\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 77, in __anext__\\n    raise result\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 38, in _raise_exception_on_finish\\n    task.result()\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 501, in run_engine_loop\\n    has_requests_in_progress = await asyncio.wait_for(\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/asyncio/tasks.py\", line 445, in wait_for\\n    return fut.result()\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 475, in engine_step\\n    request_outputs = await self.engine.step_async()\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 221, in step_async\\n    output = await self.model_executor.execute_model_async(\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/executor/gpu_executor.py\", line 148, in execute_model_async\\n    output = await make_async(self.driver_worker.execute_model\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\\n    result = self.fn(*self.args, **self.kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\\n    return func(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/worker/worker.py\", line 249, in execute_model\\n    output = self.model_runner.execute_model(seq_group_metadata_list,\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\\n    return func(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/worker/model_runner.py\", line 808, in execute_model\\n    hidden_states = model_executable(**execute_model_kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 364, in forward\\n    hidden_states = self.model(input_ids, positions, kv_caches,\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 291, in forward\\n    hidden_states, residual = layer(\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 243, in forward\\n    hidden_states = self.mlp(hidden_states)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 77, in forward\\n    gate_up, _ = self.gate_up_proj(x)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py\", line 281, in forward\\n    output_parallel = self.quant_method.apply(self, input_, bias)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/awq.py\", line 169, in apply\\n    out = torch.matmul(reshaped_x, out)\\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 114.00 MiB. GPU\\n'}\n",
      "\u001b[36mray::ServeReplica:default:VLLMDeploymentClass.handle_request_with_rejection()\u001b[39m (pid=1729613, ip=167.96.96.59, actor_id=300e834785294afb218a0bb701000000, repr=<ray.serve._private.replica.ServeReplica:default:VLLMDeploymentClass object at 0x77868b300880>)\n",
      "    async for result in self._call_user_generator(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 460, in _call_user_generator\n",
      "    raise e from None\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1150, in call_user_method\n",
      "    raise e from None\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::ServeReplica:default:VLLMDeploymentClass.handle_request_with_rejection()\u001b[39m (pid=1729613, ip=167.96.96.59)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/utils.py\", line 168, in wrap_to_ray_error\n",
      "    raise exception\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1131, in call_user_method\n",
      "    result = await self._handle_user_method_result(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1038, in _handle_user_method_result\n",
      "    async for r in result:\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 666, in generate\n",
      "    raise e\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 660, in generate\n",
      "    async for request_output in stream:\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 77, in __anext__\n",
      "    raise result\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 38, in _raise_exception_on_finish\n",
      "    task.result()\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 501, in run_engine_loop\n",
      "    has_requests_in_progress = await asyncio.wait_for(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/asyncio/tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 475, in engine_step\n",
      "    request_outputs = await self.engine.step_async()\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 221, in step_async\n",
      "    output = await self.model_executor.execute_model_async(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/executor/gpu_executor.py\", line 148, in execute_model_async\n",
      "    output = await make_async(self.driver_worker.execute_model\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/worker/worker.py\", line 249, in execute_model\n",
      "    output = self.model_runner.execute_model(seq_group_metadata_list,\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/worker/model_runner.py\", line 808, in execute_model\n",
      "    hidden_states = model_executable(**execute_model_kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 364, in forward\n",
      "    hidden_states = self.model(input_ids, positions, kv_caches,\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 291, in forward\n",
      "    hidden_states, residual = layer(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 243, in forward\n",
      "    hidden_states = self.mlp(hidden_states)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 77, in forward\n",
      "    gate_up, _ = self.gate_up_proj(x)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py\", line 281, in forward\n",
      "    output_parallel = self.quant_method.apply(self, input_, bias)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/awq.py\", line 169, in apply\n",
      "    out = torch.matmul(reshaped_x, out)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 114.00 MiB. GPU\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kmccleary/projects/QueryLakeDevelopment/QueryLakeBackend/./server.py\", line 432, in api_general_call\n",
      "    args_get = await function_actual(**true_args)\n",
      "  File \"/home/kmccleary/projects/QueryLakeDevelopment/QueryLakeBackend/QueryLake/api/custom_model_functions/multi_search.py\", line 143, in llm_multistep_search\n",
      "    current_response = await llm_call(\n",
      "  File \"/home/kmccleary/projects/QueryLakeDevelopment/QueryLakeBackend/./server.py\", line 288, in llm_call\n",
      "    async for result in stream_results_tokens(gen, on_new_token=on_new_token, stop_sequences=stop_sequences):\n",
      "  File \"/home/kmccleary/projects/QueryLakeDevelopment/QueryLakeBackend/QueryLake/misc_functions/server_class_functions.py\", line 34, in stream_results_tokens\n",
      "    async for request_output in results_generator:\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/handle.py\", line 663, in __anext__\n",
      "    return await next_obj_ref\n",
      "ray.exceptions.RayTaskError(OutOfMemoryError): \u001b[36mray::ServeReplica:default:VLLMDeploymentClass.handle_request_with_rejection()\u001b[39m (pid=1729613, ip=167.96.96.59, actor_id=300e834785294afb218a0bb701000000, repr=<ray.serve._private.replica.ServeReplica:default:VLLMDeploymentClass object at 0x77868b300880>)\n",
      "    async for result in self._call_user_generator(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 460, in _call_user_generator\n",
      "    raise e from None\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1150, in call_user_method\n",
      "    raise e from None\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::ServeReplica:default:VLLMDeploymentClass.handle_request_with_rejection()\u001b[39m (pid=1729613, ip=167.96.96.59)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/utils.py\", line 168, in wrap_to_ray_error\n",
      "    raise exception\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1131, in call_user_method\n",
      "    result = await self._handle_user_method_result(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1038, in _handle_user_method_result\n",
      "    async for r in result:\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 666, in generate\n",
      "    raise e\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 660, in generate\n",
      "    async for request_output in stream:\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 77, in __anext__\n",
      "    raise result\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 38, in _raise_exception_on_finish\n",
      "    task.result()\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 501, in run_engine_loop\n",
      "    has_requests_in_progress = await asyncio.wait_for(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/asyncio/tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 475, in engine_step\n",
      "    request_outputs = await self.engine.step_async()\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 221, in step_async\n",
      "    output = await self.model_executor.execute_model_async(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/executor/gpu_executor.py\", line 148, in execute_model_async\n",
      "    output = await make_async(self.driver_worker.execute_model\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/worker/worker.py\", line 249, in execute_model\n",
      "    output = self.model_runner.execute_model(seq_group_metadata_list,\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/worker/model_runner.py\", line 808, in execute_model\n",
      "    hidden_states = model_executable(**execute_model_kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 364, in forward\n",
      "    hidden_states = self.model(input_ids, positions, kv_caches,\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 291, in forward\n",
      "    hidden_states, residual = layer(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 243, in forward\n",
      "    hidden_states = self.mlp(hidden_states)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 77, in forward\n",
      "    gate_up, _ = self.gate_up_proj(x)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py\", line 281, in forward\n",
      "    output_parallel = self.quant_method.apply(self, input_, bias)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/awq.py\", line 169, in apply\n",
      "    out = torch.matmul(reshaped_x, out)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 114.00 MiB. GPU\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json, textwrap\n",
    "\n",
    "response = requests.get(f\"http://localhost:8000/api/llm_multistep_search\", json={\n",
    "    \"auth\": {\"api_key\": API_KEY_1},\n",
    "    \"chat_history\": TEST_CHAT_HISTORY,\n",
    "    \"collection_ids\": [COLLECTION_ARGS[\"hash_id\"]],\n",
    "    \"max_searches\": 2,\n",
    "    # \"search_web\": True\n",
    "}, stream=False)\n",
    "response.raise_for_status()\n",
    "result = response.json()\n",
    "\n",
    "print(result)\n",
    "\n",
    "if \"error\" in result:\n",
    "    print(result[\"error\"])\n",
    "    print(result[\"trace\"])\n",
    "else:\n",
    "    result = result[\"result\"]\n",
    "    for r in result[\"sources\"]:\n",
    "        # print(json.dumps(r, indent=4))\n",
    "        if \"text\" in r:\n",
    "            print(textwrap.fill(r[\"text\"].replace(\"\\n\", \"\"), width=100), end=\"\\n\\n\")\n",
    "    for command in result[\"commands\"]:\n",
    "        print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Conversation Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': False, 'error': '\\x1b[36mray::ServeReplica:default:VLLMDeploymentClass.handle_request_with_rejection()\\x1b[39m (pid=1729613, ip=167.96.96.59, actor_id=300e834785294afb218a0bb701000000, repr=<ray.serve._private.replica.ServeReplica:default:VLLMDeploymentClass object at 0x77868b300880>)\\n    async for result in self._call_user_generator(\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 460, in _call_user_generator\\n    raise e from None\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1150, in call_user_method\\n    raise e from None\\nray.exceptions.RayTaskError: \\x1b[36mray::ServeReplica:default:VLLMDeploymentClass.handle_request_with_rejection()\\x1b[39m (pid=1729613, ip=167.96.96.59)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/utils.py\", line 168, in wrap_to_ray_error\\n    raise exception\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1131, in call_user_method\\n    result = await self._handle_user_method_result(\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1038, in _handle_user_method_result\\n    async for r in result:\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 666, in generate\\n    raise e\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 660, in generate\\n    async for request_output in stream:\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 77, in __anext__\\n    raise result\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 38, in _raise_exception_on_finish\\n    task.result()\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 501, in run_engine_loop\\n    has_requests_in_progress = await asyncio.wait_for(\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/asyncio/tasks.py\", line 445, in wait_for\\n    return fut.result()\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 475, in engine_step\\n    request_outputs = await self.engine.step_async()\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 221, in step_async\\n    output = await self.model_executor.execute_model_async(\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/executor/gpu_executor.py\", line 148, in execute_model_async\\n    output = await make_async(self.driver_worker.execute_model\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\\n    result = self.fn(*self.args, **self.kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\\n    return func(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/worker/worker.py\", line 249, in execute_model\\n    output = self.model_runner.execute_model(seq_group_metadata_list,\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\\n    return func(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/worker/model_runner.py\", line 808, in execute_model\\n    hidden_states = model_executable(**execute_model_kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 364, in forward\\n    hidden_states = self.model(input_ids, positions, kv_caches,\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 291, in forward\\n    hidden_states, residual = layer(\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 243, in forward\\n    hidden_states = self.mlp(hidden_states)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 77, in forward\\n    gate_up, _ = self.gate_up_proj(x)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py\", line 281, in forward\\n    output_parallel = self.quant_method.apply(self, input_, bias)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/awq.py\", line 169, in apply\\n    out = torch.matmul(reshaped_x, out)\\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 114.00 MiB. GPU \\n\\nThe above exception was the direct cause of the following exception:\\n\\n\\x1b[36mray::ServeReplica:default:VLLMDeploymentClass.handle_request_with_rejection()\\x1b[39m (pid=1729613, ip=167.96.96.59)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/utils.py\", line 168, in wrap_to_ray_error\\n    raise exception\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1131, in call_user_method\\n    result = await self._handle_user_method_result(\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1038, in _handle_user_method_result\\n    async for r in result:\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 666, in generate\\n    raise e\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 650, in generate\\n    stream = await self.add_request(\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 537, in add_request\\n    self.start_background_loop()\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 411, in start_background_loop\\n    raise AsyncEngineDeadError(\\nvllm.engine.async_llm_engine.AsyncEngineDeadError: Background loop has errored already.', 'trace': 'Traceback (most recent call last):\\n  File \"/home/kmccleary/projects/QueryLakeDevelopment/QueryLakeBackend/./server.py\", line 432, in api_general_call\\n    args_get = await function_actual(**true_args)\\n  File \"/home/kmccleary/projects/QueryLakeDevelopment/QueryLakeBackend/QueryLake/api/custom_model_functions/create_conversation_title.py\", line 66, in llm_make_conversation_title\\n    result = await llm_call(\\n  File \"/home/kmccleary/projects/QueryLakeDevelopment/QueryLakeBackend/./server.py\", line 288, in llm_call\\n    async for result in stream_results_tokens(gen, on_new_token=on_new_token, stop_sequences=stop_sequences):\\n  File \"/home/kmccleary/projects/QueryLakeDevelopment/QueryLakeBackend/QueryLake/misc_functions/server_class_functions.py\", line 34, in stream_results_tokens\\n    async for request_output in results_generator:\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/handle.py\", line 663, in __anext__\\n    return await next_obj_ref\\nray.exceptions.RayTaskError(AsyncEngineDeadError): \\x1b[36mray::ServeReplica:default:VLLMDeploymentClass.handle_request_with_rejection()\\x1b[39m (pid=1729613, ip=167.96.96.59, actor_id=300e834785294afb218a0bb701000000, repr=<ray.serve._private.replica.ServeReplica:default:VLLMDeploymentClass object at 0x77868b300880>)\\n    async for result in self._call_user_generator(\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 460, in _call_user_generator\\n    raise e from None\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1150, in call_user_method\\n    raise e from None\\nray.exceptions.RayTaskError: \\x1b[36mray::ServeReplica:default:VLLMDeploymentClass.handle_request_with_rejection()\\x1b[39m (pid=1729613, ip=167.96.96.59)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/utils.py\", line 168, in wrap_to_ray_error\\n    raise exception\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1131, in call_user_method\\n    result = await self._handle_user_method_result(\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1038, in _handle_user_method_result\\n    async for r in result:\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 666, in generate\\n    raise e\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 660, in generate\\n    async for request_output in stream:\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 77, in __anext__\\n    raise result\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 38, in _raise_exception_on_finish\\n    task.result()\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 501, in run_engine_loop\\n    has_requests_in_progress = await asyncio.wait_for(\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/asyncio/tasks.py\", line 445, in wait_for\\n    return fut.result()\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 475, in engine_step\\n    request_outputs = await self.engine.step_async()\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 221, in step_async\\n    output = await self.model_executor.execute_model_async(\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/executor/gpu_executor.py\", line 148, in execute_model_async\\n    output = await make_async(self.driver_worker.execute_model\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\\n    result = self.fn(*self.args, **self.kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\\n    return func(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/worker/worker.py\", line 249, in execute_model\\n    output = self.model_runner.execute_model(seq_group_metadata_list,\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\\n    return func(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/worker/model_runner.py\", line 808, in execute_model\\n    hidden_states = model_executable(**execute_model_kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 364, in forward\\n    hidden_states = self.model(input_ids, positions, kv_caches,\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 291, in forward\\n    hidden_states, residual = layer(\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 243, in forward\\n    hidden_states = self.mlp(hidden_states)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 77, in forward\\n    gate_up, _ = self.gate_up_proj(x)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py\", line 281, in forward\\n    output_parallel = self.quant_method.apply(self, input_, bias)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/awq.py\", line 169, in apply\\n    out = torch.matmul(reshaped_x, out)\\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 114.00 MiB. GPU \\n\\nThe above exception was the direct cause of the following exception:\\n\\n\\x1b[36mray::ServeReplica:default:VLLMDeploymentClass.handle_request_with_rejection()\\x1b[39m (pid=1729613, ip=167.96.96.59)\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/utils.py\", line 168, in wrap_to_ray_error\\n    raise exception\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1131, in call_user_method\\n    result = await self._handle_user_method_result(\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1038, in _handle_user_method_result\\n    async for r in result:\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 666, in generate\\n    raise e\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 650, in generate\\n    stream = await self.add_request(\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 537, in add_request\\n    self.start_background_loop()\\n  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 411, in start_background_loop\\n    raise AsyncEngineDeadError(\\nvllm.engine.async_llm_engine.AsyncEngineDeadError: Background loop has errored already.\\n'}\n",
      "\u001b[36mray::ServeReplica:default:VLLMDeploymentClass.handle_request_with_rejection()\u001b[39m (pid=1729613, ip=167.96.96.59, actor_id=300e834785294afb218a0bb701000000, repr=<ray.serve._private.replica.ServeReplica:default:VLLMDeploymentClass object at 0x77868b300880>)\n",
      "    async for result in self._call_user_generator(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 460, in _call_user_generator\n",
      "    raise e from None\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1150, in call_user_method\n",
      "    raise e from None\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::ServeReplica:default:VLLMDeploymentClass.handle_request_with_rejection()\u001b[39m (pid=1729613, ip=167.96.96.59)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/utils.py\", line 168, in wrap_to_ray_error\n",
      "    raise exception\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1131, in call_user_method\n",
      "    result = await self._handle_user_method_result(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1038, in _handle_user_method_result\n",
      "    async for r in result:\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 666, in generate\n",
      "    raise e\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 660, in generate\n",
      "    async for request_output in stream:\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 77, in __anext__\n",
      "    raise result\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 38, in _raise_exception_on_finish\n",
      "    task.result()\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 501, in run_engine_loop\n",
      "    has_requests_in_progress = await asyncio.wait_for(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/asyncio/tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 475, in engine_step\n",
      "    request_outputs = await self.engine.step_async()\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 221, in step_async\n",
      "    output = await self.model_executor.execute_model_async(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/executor/gpu_executor.py\", line 148, in execute_model_async\n",
      "    output = await make_async(self.driver_worker.execute_model\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/worker/worker.py\", line 249, in execute_model\n",
      "    output = self.model_runner.execute_model(seq_group_metadata_list,\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/worker/model_runner.py\", line 808, in execute_model\n",
      "    hidden_states = model_executable(**execute_model_kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 364, in forward\n",
      "    hidden_states = self.model(input_ids, positions, kv_caches,\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 291, in forward\n",
      "    hidden_states, residual = layer(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 243, in forward\n",
      "    hidden_states = self.mlp(hidden_states)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 77, in forward\n",
      "    gate_up, _ = self.gate_up_proj(x)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py\", line 281, in forward\n",
      "    output_parallel = self.quant_method.apply(self, input_, bias)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/awq.py\", line 169, in apply\n",
      "    out = torch.matmul(reshaped_x, out)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 114.00 MiB. GPU \n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ServeReplica:default:VLLMDeploymentClass.handle_request_with_rejection()\u001b[39m (pid=1729613, ip=167.96.96.59)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/utils.py\", line 168, in wrap_to_ray_error\n",
      "    raise exception\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1131, in call_user_method\n",
      "    result = await self._handle_user_method_result(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1038, in _handle_user_method_result\n",
      "    async for r in result:\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 666, in generate\n",
      "    raise e\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 650, in generate\n",
      "    stream = await self.add_request(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 537, in add_request\n",
      "    self.start_background_loop()\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 411, in start_background_loop\n",
      "    raise AsyncEngineDeadError(\n",
      "vllm.engine.async_llm_engine.AsyncEngineDeadError: Background loop has errored already.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kmccleary/projects/QueryLakeDevelopment/QueryLakeBackend/./server.py\", line 432, in api_general_call\n",
      "    args_get = await function_actual(**true_args)\n",
      "  File \"/home/kmccleary/projects/QueryLakeDevelopment/QueryLakeBackend/QueryLake/api/custom_model_functions/create_conversation_title.py\", line 66, in llm_make_conversation_title\n",
      "    result = await llm_call(\n",
      "  File \"/home/kmccleary/projects/QueryLakeDevelopment/QueryLakeBackend/./server.py\", line 288, in llm_call\n",
      "    async for result in stream_results_tokens(gen, on_new_token=on_new_token, stop_sequences=stop_sequences):\n",
      "  File \"/home/kmccleary/projects/QueryLakeDevelopment/QueryLakeBackend/QueryLake/misc_functions/server_class_functions.py\", line 34, in stream_results_tokens\n",
      "    async for request_output in results_generator:\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/handle.py\", line 663, in __anext__\n",
      "    return await next_obj_ref\n",
      "ray.exceptions.RayTaskError(AsyncEngineDeadError): \u001b[36mray::ServeReplica:default:VLLMDeploymentClass.handle_request_with_rejection()\u001b[39m (pid=1729613, ip=167.96.96.59, actor_id=300e834785294afb218a0bb701000000, repr=<ray.serve._private.replica.ServeReplica:default:VLLMDeploymentClass object at 0x77868b300880>)\n",
      "    async for result in self._call_user_generator(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 460, in _call_user_generator\n",
      "    raise e from None\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1150, in call_user_method\n",
      "    raise e from None\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::ServeReplica:default:VLLMDeploymentClass.handle_request_with_rejection()\u001b[39m (pid=1729613, ip=167.96.96.59)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/utils.py\", line 168, in wrap_to_ray_error\n",
      "    raise exception\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1131, in call_user_method\n",
      "    result = await self._handle_user_method_result(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1038, in _handle_user_method_result\n",
      "    async for r in result:\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 666, in generate\n",
      "    raise e\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 660, in generate\n",
      "    async for request_output in stream:\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 77, in __anext__\n",
      "    raise result\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 38, in _raise_exception_on_finish\n",
      "    task.result()\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 501, in run_engine_loop\n",
      "    has_requests_in_progress = await asyncio.wait_for(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/asyncio/tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 475, in engine_step\n",
      "    request_outputs = await self.engine.step_async()\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 221, in step_async\n",
      "    output = await self.model_executor.execute_model_async(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/executor/gpu_executor.py\", line 148, in execute_model_async\n",
      "    output = await make_async(self.driver_worker.execute_model\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/worker/worker.py\", line 249, in execute_model\n",
      "    output = self.model_runner.execute_model(seq_group_metadata_list,\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/worker/model_runner.py\", line 808, in execute_model\n",
      "    hidden_states = model_executable(**execute_model_kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 364, in forward\n",
      "    hidden_states = self.model(input_ids, positions, kv_caches,\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 291, in forward\n",
      "    hidden_states, residual = layer(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 243, in forward\n",
      "    hidden_states = self.mlp(hidden_states)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 77, in forward\n",
      "    gate_up, _ = self.gate_up_proj(x)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py\", line 281, in forward\n",
      "    output_parallel = self.quant_method.apply(self, input_, bias)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/awq.py\", line 169, in apply\n",
      "    out = torch.matmul(reshaped_x, out)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 114.00 MiB. GPU \n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ServeReplica:default:VLLMDeploymentClass.handle_request_with_rejection()\u001b[39m (pid=1729613, ip=167.96.96.59)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/utils.py\", line 168, in wrap_to_ray_error\n",
      "    raise exception\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1131, in call_user_method\n",
      "    result = await self._handle_user_method_result(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1038, in _handle_user_method_result\n",
      "    async for r in result:\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 666, in generate\n",
      "    raise e\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 650, in generate\n",
      "    stream = await self.add_request(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 537, in add_request\n",
      "    self.start_background_loop()\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 411, in start_background_loop\n",
      "    raise AsyncEngineDeadError(\n",
      "vllm.engine.async_llm_engine.AsyncEngineDeadError: Background loop has errored already.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(f\"http://localhost:8000/api/llm_make_conversation_title\", json={\n",
    "    \"auth\": {\"api_key\": API_KEY_1},\n",
    "    \"chat_history\": TEST_CHAT_HISTORY\n",
    "}, stream=False)\n",
    "response.raise_for_status()\n",
    "result = response.json()\n",
    "\n",
    "print(result)\n",
    "\n",
    "if \"error\" in result:\n",
    "    print(result[\"error\"])\n",
    "    print(result[\"trace\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': True, 'result': 4}\n"
     ]
    }
   ],
   "source": [
    "import requests, json, time\n",
    "\n",
    "\n",
    "response = requests.get(f\"http://localhost:8000/api/llm_count_tokens\", json={\n",
    "    \"auth\": {\"api_key\": API_KEY_1},\n",
    "    \"model_id\": \"llama-3-8b-instruct\",\n",
    "    \"input_string\": \"Where is Afghanistan?\"\n",
    "}, stream=False)\n",
    "response.raise_for_status()\n",
    "result = response.json()\n",
    "\n",
    "print(result)\n",
    "\n",
    "if \"error\" in result:\n",
    "    print(result[\"error\"])\n",
    "    print(result[\"trace\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `api/rerank`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING RERANK\n",
      "Get response with: [['What is the square root of 169?', 'The square root of 169 is 13.'], ['What is the derivative of sin(cos(x))?', \"What is the derivative of sin(cos(x))? Well, it's a bit complicated. The derivative of sin(cos(x)) is cos(cos(x)) * -sin(x).\"]]\n",
      "Get response with: [['What is the square root of 169?', 'cupcake'], ['What is the derivative of sin(cos(x))?', 'math'], ['What is the square root of 169?', 'math'], ['What is the derivative of sin(cos(x))?', 'math']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': True, 'result': [100.0, 100.0]}\n",
      "FINISHED RESPONSE in  1.29s: [[['What is the square root of 169?', 'The square root of 169 is 13.'], ['What is the derivative of sin(cos(x))?', \"What is the derivative of sin(cos(x))? Well, it's a bit complicated. The derivative of sin(cos(x)) is cos(cos(x)) * -sin(x).\"]], [100.0, 100.0]]\n",
      "{'success': True, 'result': [1.0827401638380252e-05, 0.0024664821103215218, 0.0028941642958670855, 0.0024664821103215218]}\n",
      "FINISHED RESPONSE in  1.29s: [[['What is the square root of 169?', 'cupcake'], ['What is the derivative of sin(cos(x))?', 'math'], ['What is the square root of 169?', 'math'], ['What is the derivative of sin(cos(x))?', 'math']], [1.0827401638380252e-05, 0.0024664821103215218, 0.0028941642958670855, 0.0024664821103215218]]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from threading import Thread\n",
    "import time, json\n",
    "from copy import deepcopy\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "prompts_rerank = [\n",
    "    [\n",
    "        [\"What is the square root of 169?\", \"The square root of 169 is 13.\"],\n",
    "        [\"What is the derivative of sin(cos(x))?\", \"What is the derivative of sin(cos(x))? Well, it's a bit complicated. The derivative of sin(cos(x)) is cos(cos(x)) * -sin(x).\"],\n",
    "    ], [\n",
    "        [\"What is the square root of 169?\", \"cupcake\"],\n",
    "        [\"What is the derivative of sin(cos(x))?\", \"math\"],\n",
    "        [\"What is the square root of 169?\", \"math\"],\n",
    "        [\"What is the derivative of sin(cos(x))?\", \"math\"],\n",
    "    ]\n",
    "]\n",
    "\n",
    "def get_response(prompt_input):\n",
    "    print(\"Get response with:\", prompt_input)\n",
    "    input = {\"auth\": {\"api_key\": API_KEY_1}}\n",
    "    input.update({\n",
    "        \"inputs\": prompt_input\n",
    "    })\n",
    "    \n",
    "    time_start = time.time()\n",
    "    response = requests.get(f\"http://localhost:8000/api/rerank\", json=input)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    response_value = response.json()\n",
    "    print(response_value)\n",
    "    response_value = response_value[\"result\"]\n",
    "    time_end = time.time()\n",
    "    time_taken = time_end - time_start\n",
    "    \n",
    "    assert not (\"success\" in response_value and response_value[\"success\"] == False), response_value[\"error\"]\n",
    "    print(\"FINISHED RESPONSE in %5.2fs:\" % (time_taken), [prompt_input, response_value])\n",
    "\n",
    "print(\"RUNNING RERANK\")\n",
    "# for p in prompts_rerank:\n",
    "#     # time.sleep(0.5)\n",
    "#     Thread(target=get_response, args=(p,)).start()\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    executor.map(get_response, prompts_rerank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `api/embedding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00771331787109375, 0.01000213623046875, -0.04278564453125, -0.050262451171875, 0.00998687744140625, 0.0013494491577148438, 0.01245880126953125, -0.0185394287109375, 0.01195526123046875, -0.0302886962890625, -0.01511383056640625, 0.06768798828125, -0.0260009765625, 0.0086517333984375, 0.027313232421875, -0.01329803466796875, -0.00011336803436279297, 0.0050811767578125, 0.028656005859375, -0.0037746429443359375, 0.0027904510498046875, -0.0347900390625, -0.03448486328125, 0.024505615234375, 0.00124359130859375, -0.01197052001953125, 0.015594482421875, 0.0015659332275390625, -0.031158447265625, -0.0635986328125, 0.021697998046875, -0.0283050537109375, 0.0166015625, -0.020751953125, -0.006946563720703125, -0.01806640625, 0.0223541259765625, -0.02386474609375, -0.052825927734375, -0.00640106201171875, -0.00830841064453125, 0.0150299072265625, 0.006641387939453125, -0.042999267578125, -0.0016164779663085938, -0.082275390625, -0.02728271484375, -0.058380126953125, -0.0016679763793945312, 0.0256195068359375, 0.031829833984375, 0.0101165771484375, 0.041229248046875, -0.0194091796875, 0.03619384765625, -0.0095977783203125, 0.0141143798828125, 0.06011962890625, -0.059814453125, 0.006267547607421875, -0.044464111328125, -0.005771636962890625, -0.0161895751953125, -0.02264404296875, 0.0472412109375, 0.028228759765625, -0.0209808349609375, 0.0114898681640625, -0.00047588348388671875, -0.00928497314453125, -0.04083251953125, 7.11679458618164e-05, -0.053497314453125, 0.01558685302734375, -0.0467529296875, 0.01131439208984375, -0.009368896484375, -4.100799560546875e-05, -0.0236663818359375, -0.01416778564453125, 0.09259033203125, 0.043060302734375, 0.005756378173828125, -0.01812744140625, -0.0014142990112304688, 0.04510498046875, -0.00246429443359375, -0.005443572998046875, 0.01177215576171875, -0.07586669921875, -0.0232086181640625, 0.01430511474609375, -0.01248931884765625, -0.03497314453125, -0.018707275390625, 0.01180267333984375, -0.08746337890625, 0.0675048828125, -0.0117645263671875, -0.0274200439453125, -0.047210693359375, 0.040313720703125, -0.0183868408203125, -0.0128936767578125, 0.0312347412109375, 0.0306854248046875, 0.06304931640625, -0.01352691650390625, 0.018096923828125, 0.0084228515625, 0.0041046142578125, 0.0273284912109375, 0.0167999267578125, -0.05474853515625, -0.03875732421875, -0.041259765625, -0.035888671875, -0.055755615234375, 0.009185791015625, -0.01224517822265625, 0.020751953125, 0.00586700439453125, 0.03936767578125, -0.042724609375, -0.0478515625, 0.039947509765625, 0.019500732421875, 0.038818359375, -0.04754638671875, 0.0184326171875, -0.0238800048828125, -0.01324462890625, -0.0258636474609375, 0.0113677978515625, -0.0189666748046875, -0.01454925537109375, 0.03057861328125, 0.0151519775390625, -0.0195770263671875, -0.024078369140625, 0.012115478515625, 0.024658203125, 0.002124786376953125, -0.02691650390625, -0.004245758056640625, -0.0181427001953125, 0.0028324127197265625, -0.07391357421875, -0.01406097412109375, 0.004024505615234375, 0.0307464599609375, -0.0134429931640625, 0.049530029296875, -0.01453399658203125, -0.0278167724609375, -0.0173187255859375, -0.01410675048828125, 0.029815673828125, 0.035247802734375, 0.0140533447265625, 0.08160400390625, 0.030120849609375, -0.020477294921875, -0.07635498046875, 0.01422882080078125, 0.035308837890625, -0.040771484375, 0.0455322265625, 0.0011281967163085938, 0.00604248046875, 0.0279388427734375, -0.0394287109375, -0.0019178390502929688, -0.0168609619140625, -0.001873016357421875, -0.0032863616943359375, 0.050933837890625, 0.0042572021484375, -0.01023101806640625, -0.0041046142578125, 0.006137847900390625, 0.039093017578125, -0.01448822021484375, -0.051239013671875, -0.027099609375, -0.02716064453125, 0.010009765625, 0.0281982421875, 0.022430419921875, 0.0174560546875, -0.015594482421875, 0.01021575927734375, 0.02899169921875, 0.01092529296875, -0.005489349365234375, 0.0338134765625, -0.005710601806640625, -0.0911865234375, -0.0140533447265625, 0.007476806640625, 0.0008106231689453125, 0.0022373199462890625, 0.007709503173828125, 0.0180511474609375, -0.0435791015625, -0.0158538818359375, -0.10662841796875, -0.03192138671875, 0.0151519775390625, -0.015716552734375, -0.061187744140625, 0.01776123046875, 0.05029296875, 0.07958984375, -0.00403594970703125, -0.0286712646484375, 0.015350341796875, -0.0020599365234375, 0.0158233642578125, 0.00399017333984375, 0.003627777099609375, -0.014373779296875, -0.0036563873291015625, -0.00319671630859375, -0.007648468017578125, 0.0223236083984375, -0.0057830810546875, -0.041900634765625, -0.02752685546875, -0.026092529296875, -0.01325225830078125, -0.010467529296875, 0.003665924072265625, 0.0165252685546875, 0.032867431640625, -0.02435302734375, -0.006927490234375, 0.030303955078125, 0.01385498046875, -0.02313232421875, -0.04193115234375, 0.0377197265625, -0.0438232421875, -0.057891845703125, -0.016021728515625, -0.0159149169921875, 0.033782958984375, -0.05450439453125, -0.0027523040771484375, -0.0015506744384765625, 0.0304718017578125, -0.02447509765625, 0.0211181640625, 0.02081298828125, 0.034912109375, 0.02801513671875, 0.0142059326171875, -0.0171356201171875, 0.035003662109375, 0.0030841827392578125, -0.0035953521728515625, -0.005039215087890625, -0.00353240966796875, 0.04949951171875, 0.00618743896484375, -0.00870513916015625, -0.002960205078125, 0.046905517578125, 0.01202392578125, -0.006412506103515625, -0.05029296875, -0.0081024169921875, -0.028594970703125, 0.015655517578125, -0.0228271484375, 0.0121307373046875, -0.023468017578125, -0.0079193115234375, 0.0263671875, -0.014190673828125, 0.0167999267578125, -0.0016412734985351562, -0.0004382133483886719, -0.02691650390625, 0.023681640625, -0.0250701904296875, -0.0303955078125, -0.054840087890625, -0.0016727447509765625, -0.0274658203125, -0.0184478759765625, -0.0104522705078125, 0.04248046875, 0.024749755859375, -0.03533935546875, -0.04681396484375, -0.05596923828125, -0.157470703125, -0.0276641845703125, 0.003192901611328125, 0.04840087890625, 0.0203399658203125, -0.0149078369140625, 0.0266876220703125, -0.0177764892578125, -0.01371002197265625, -0.00868988037109375, -0.054412841796875, -0.038482666015625, 0.0155487060546875, 0.004375457763671875, -0.007793426513671875, -0.00435638427734375, 0.01525115966796875, 0.01227569580078125, 0.0296478271484375, -0.00011074542999267578, 0.049530029296875, -0.029541015625, 0.03607177734375, -0.035003662109375, 0.02056884765625, -0.04327392578125, 0.02947998046875, 0.029876708984375, -0.0232696533203125, -0.0511474609375, 0.012451171875, -0.011932373046875, -0.01084136962890625, 0.0321044921875, 0.0215911865234375, 0.0012712478637695312, -0.0302734375, -0.01971435546875, 0.0213470458984375, 0.0103302001953125, 0.0033054351806640625, 0.0176544189453125, -0.01024627685546875, 0.007015228271484375, -0.0193328857421875, -0.050323486328125, -0.00948333740234375, -0.01788330078125, 0.00394439697265625, 0.0096282958984375, -0.07135009765625, 0.0054168701171875, -0.025787353515625, -0.01971435546875, -0.0152587890625, 0.0263214111328125, -0.00574493408203125, 0.032470703125, -0.005115509033203125, 0.00977325439453125, -0.021148681640625, 0.0014219284057617188, 0.01096343994140625, 0.0306243896484375, 0.0025577545166015625, -0.0300445556640625, -0.00799560546875, -0.0079803466796875, 0.01132965087890625, -0.0036773681640625, 0.002010345458984375, 0.0171356201171875, -0.01080322265625, -0.019744873046875, 0.01036834716796875, 0.007045745849609375, 0.028289794921875, 0.001064300537109375, 0.0386962890625, -0.12017822265625, -0.0005102157592773438, 0.035888671875, -0.021942138671875, 0.03582763671875, -0.028900146484375, 0.01467132568359375, -0.021453857421875, 0.0011014938354492188, -0.02435302734375, 0.2071533203125, 0.01568603515625, 0.036895751953125, -0.005054473876953125, 0.01531219482421875, -0.0033111572265625, -0.0041046142578125, -0.038055419921875, 0.004215240478515625, -0.00018155574798583984, -0.06982421875, -0.0158538818359375, 0.0146331787109375, -0.0158843994140625, 0.0291900634765625, 0.008087158203125, -0.013946533203125, 0.00875091552734375, -0.0073089599609375, 0.00812530517578125, -0.01140594482421875, 0.028045654296875, 0.022308349609375, 0.01125335693359375, -0.01812744140625, -0.037933349609375, 0.0177764892578125, 0.063232421875, -0.036346435546875, 0.00814056396484375, -0.00936126708984375, -0.01093292236328125, 0.0012903213500976562, -0.032257080078125, 0.036407470703125, -0.03289794921875, 0.005786895751953125, -0.0217132568359375, -0.03057861328125, 0.0028285980224609375, 0.0207977294921875, -0.0401611328125, -0.00759124755859375, 0.0279541015625, 0.03936767578125, -0.00542449951171875, 0.038482666015625, -0.029754638671875, -0.02215576171875, -0.046600341796875, 0.07623291015625, 0.006763458251953125, -0.0231475830078125, 0.0110931396484375, -0.0173187255859375, 0.0277099609375, -0.0167236328125, -0.019744873046875, 0.0003802776336669922, -0.01456451416015625, -0.0007686614990234375, 0.01190185546875, -0.00713348388671875, -0.0316162109375, 0.0269012451171875, -0.046783447265625, 0.0032444000244140625, -0.01306915283203125, -0.027618408203125, -0.02886962890625, 0.035064697265625, -0.03143310546875, -0.0249176025390625, -0.0552978515625, 0.037628173828125, -0.01123809814453125, -0.04486083984375, 0.02105712890625, 0.0088043212890625, -0.026123046875, 0.0240478515625, -0.0093231201171875, -0.04888916015625, -0.06207275390625, -0.0003979206085205078, 0.0391845703125, -0.006549835205078125, 0.008148193359375, -0.01551055908203125, -0.03741455078125, 0.033538818359375, 0.029327392578125, -0.0267486572265625, -0.01080322265625, 0.04034423828125, 0.00746917724609375, 0.00945281982421875, 0.047698974609375, -0.0157470703125, 0.006504058837890625, 0.0255279541015625, -0.01080322265625, 0.007537841796875, 0.01294708251953125, -0.0179901123046875, -0.0633544921875, 0.02203369140625, 0.046905517578125, 0.000728607177734375, -0.05419921875, -0.032501220703125, 0.00849151611328125, 0.022979736328125, 0.0017709732055664062, -0.01248931884765625, 0.025360107421875, 0.0196990966796875, -0.01268768310546875, -0.017486572265625, 0.0357666015625, -0.042572021484375, -0.0322265625, 0.0110931396484375, 0.0027904510498046875, -0.006683349609375, 0.001857757568359375, -0.0102386474609375, 0.04388427734375, -0.03338623046875, -0.0021533966064453125, -0.00339508056640625, 0.01425933837890625, 0.05157470703125, 0.04241943359375, 0.0155792236328125, -0.003940582275390625, 0.01043701171875, -0.0073699951171875, -0.0277862548828125, 0.033447265625, 0.014190673828125, -0.046295166015625, 0.01216888427734375, 0.00786590576171875, 0.0185699462890625, 0.083251953125, 0.04864501953125, -0.01953125, -0.0087127685546875, 0.0294189453125, -0.0222625732421875, -0.01088714599609375, 0.01361083984375, -0.069091796875, -0.019134521484375, 0.00484466552734375, -0.0222625732421875, -0.05950927734375, 0.060455322265625, -0.026763916015625, 0.017242431640625, 0.0168914794921875, -0.000568389892578125, 0.05670166015625, 0.006038665771484375, 0.06231689453125, -0.05633544921875, -0.0222625732421875, 0.024993896484375, -0.01152801513671875, 0.061676025390625, -0.047393798828125, -0.0033359527587890625, 0.0101165771484375, 0.037689208984375, 0.04071044921875, -0.01149749755859375, -0.01352691650390625, 0.0177459716796875, -0.00745391845703125, -0.002544403076171875, 0.025177001953125, 0.05340576171875, 0.03778076171875, -0.0265045166015625, 0.042236328125, -0.05096435546875, -0.007343292236328125, -0.0222625732421875, -0.01177978515625, -0.0200653076171875, 0.031829833984375, -0.0208587646484375, 0.01934814453125, 0.05010986328125, -0.02587890625, -0.046173095703125, 0.0165557861328125, 0.0198211669921875, -0.016204833984375, -0.01256561279296875, -0.0107269287109375, -0.01212310791015625, 0.007251739501953125, 0.007297515869140625, 0.004241943359375, -0.0099639892578125, 0.0036468505859375, -0.020111083984375, 0.00024819374084472656, 0.00852203369140625, 0.0024890899658203125, 0.047332763671875, -0.0216064453125, 0.0438232421875, -0.0057373046875, -0.0616455078125, 0.0191802978515625, -0.00545501708984375, -0.033172607421875, 0.0002777576446533203, 0.054656982421875, 0.01934814453125, -0.01361846923828125, 0.017608642578125, -0.003032684326171875, 0.00672149658203125, -0.0164642333984375, 0.00978851318359375, -0.0260772705078125, 0.006771087646484375, 0.046234130859375, 0.004673004150390625, -0.023284912109375, 0.017242431640625, -0.0017919540405273438, 0.034637451171875, -0.00690460205078125, 0.07769775390625, -0.03936767578125, -0.00616455078125, 0.022979736328125, 0.00228118896484375, 0.037811279296875, -0.0237884521484375, 0.050018310546875, -0.00417327880859375, 0.01512908935546875, -0.023162841796875, 0.07403564453125, 0.0271759033203125, 0.014404296875, 0.0199737548828125, 0.02105712890625, -0.066162109375, 0.053192138671875, -0.001476287841796875, 0.0223846435546875, 0.01056671142578125, 0.059478759765625, 0.00229644775390625, 0.027862548828125, -0.0377197265625, 0.0130157470703125, -0.0286865234375, -0.01468658447265625, 0.0281982421875, -0.038421630859375, -0.037384033203125, 0.0015954971313476562, 0.01107025146484375, -0.009063720703125, -0.08074951171875, -0.0037364959716796875, -0.007244110107421875, 0.01462554931640625, 0.0225677490234375, -0.007175445556640625, -0.00858306884765625, 0.01293182373046875, -0.0081634521484375, 0.0498046875, -0.0007128715515136719, 0.0709228515625, -0.0296630859375, 0.035797119140625, -0.0142669677734375, 0.0087432861328125, 0.046295166015625, -0.0156097412109375, 0.006450653076171875, -0.024017333984375, -0.030609130859375, 0.06646728515625, 0.037811279296875, 0.0140533447265625, -0.035888671875, 0.086181640625, -0.024505615234375, -0.0174560546875, -0.018829345703125, -0.006313323974609375, -0.035888671875, 0.00980377197265625, -0.0271453857421875, -0.01021575927734375, 0.01454925537109375, 0.02099609375, -0.0215606689453125, -0.038604736328125, 0.005340576171875, -0.00595855712890625, 0.02484130859375, -0.036712646484375, -0.00502777099609375, -0.012603759765625, -0.03369140625, 0.014373779296875, 0.007793426513671875, 0.08685302734375, 0.0377197265625, -0.011199951171875, 0.0330810546875, -0.0265960693359375, 0.031341552734375, -0.012176513671875, -0.00035858154296875, -0.004093170166015625, -0.023834228515625, -0.0266876220703125, -0.039825439453125, 0.023834228515625, -0.0177459716796875, -0.041900634765625, -0.018707275390625, -0.00470733642578125, -0.0166015625, -0.0072021484375, 0.038543701171875, -0.0241851806640625, -0.0182952880859375, -0.044403076171875, 0.0250396728515625, -0.0013952255249023438, 0.00150299072265625, -0.01393890380859375, 0.01342010498046875, -0.0015926361083984375, -0.0347900390625, -0.01175689697265625, 0.010955810546875, 0.0233001708984375, 0.00992584228515625, -0.0684814453125, -0.0004000663757324219, 0.0219573974609375, -0.12030029296875, -0.051239013671875, 0.0050048828125, 0.01141357421875, -0.0055694580078125, -0.01256561279296875, 0.0247344970703125, 0.045318603515625, -0.0287322998046875, 0.061981201171875, 0.0352783203125, 0.0296173095703125, -0.07476806640625, -0.00646209716796875, 0.014312744140625, 0.0039825439453125, 0.0018930435180664062, 0.01194000244140625, 0.014862060546875, 0.046722412109375, 0.004405975341796875, -0.026123046875, 0.020660400390625, -0.0188751220703125, -0.032501220703125, -0.054901123046875, -0.02313232421875, -0.02215576171875, 3.510713577270508e-05, -0.0030040740966796875, -0.030181884765625, -0.01221466064453125, 0.059173583984375, 0.0013456344604492188, -0.0069732666015625, -0.004764556884765625, -0.0213775634765625, -0.0147552490234375, -0.0966796875, -0.0007205009460449219, 0.037628173828125, -0.050079345703125, -0.0227203369140625, -0.0164031982421875, 0.0005640983581542969, -0.0287322998046875, 0.011383056640625, -0.0218505859375, -0.0006556510925292969, 0.021209716796875, -0.01377105712890625, -0.0022029876708984375, -0.044677734375, 0.0303955078125, 0.009033203125, -0.00415802001953125, -0.0223388671875, 0.051544189453125, -0.0261383056640625, 0.0122222900390625, 0.039154052734375, 0.01873779296875, 0.072265625, -0.048980712890625, 0.030426025390625, -0.00548553466796875, -0.0294036865234375, -0.06170654296875, 0.0200042724609375, 0.0426025390625, 0.032440185546875, 0.02056884765625, -0.0027484893798828125, -0.0223388671875, 0.00391387939453125, 0.0044708251953125, 0.0086517333984375, -0.01174163818359375, 0.06549072265625, 0.03692626953125, -0.01922607421875, -0.049285888671875, 0.031494140625, -0.047088623046875, 0.0275726318359375, 0.0057220458984375, -0.0215301513671875, 0.0216217041015625, 0.0318603515625, -0.03533935546875, 0.041290283203125, 0.0168914794921875, -0.020172119140625, 0.00160980224609375, -0.006927490234375, 0.0309600830078125, -0.0260467529296875, 0.032318115234375, 0.030059814453125, 0.058349609375, -0.0247955322265625, -0.0423583984375, -0.029022216796875, -0.0022411346435546875, -0.0041351318359375, 0.0096435546875, 0.00649261474609375, -0.045623779296875, -0.0237884521484375, 0.0007915496826171875, 0.016143798828125, -0.045806884765625, 0.0259246826171875, 0.0164794921875, 0.0150146484375, -0.01004791259765625, -0.04803466796875, 0.02264404296875, 0.0174102783203125, 0.03729248046875, -0.06414794921875, -0.002910614013671875, -0.027618408203125, 0.00246429443359375, -0.0221405029296875, 0.02288818359375, 0.0018711090087890625, -0.0139007568359375, -0.10052490234375, 0.0102386474609375, -0.034912109375, 0.005687713623046875, -0.01031494140625, 0.00960540771484375, -8.940696716308594e-07, 0.04852294921875, 0.009735107421875, -0.0406494140625, 0.00926971435546875, 0.037139892578125, 0.0004677772521972656, -0.01314544677734375, -0.02667236328125, -0.060882568359375, 0.0175933837890625, -0.03741455078125, 0.056854248046875, 0.01293182373046875, 0.0430908203125, -0.018798828125, 0.03472900390625, 0.040496826171875, -0.03216552734375, 0.01776123046875, 0.008270263671875, -0.01271820068359375, 0.0084381103515625, -0.00919342041015625, 0.01239776611328125, 0.0261077880859375, 0.0260162353515625, -0.0207977294921875, -0.01251983642578125, -0.01288604736328125, -0.0017137527465820312, 0.022552490234375, 0.08380126953125, -0.0192413330078125, 0.0266876220703125, -0.054412841796875, 0.00975799560546875, 0.015838623046875, -0.031768798828125, 0.0166168212890625, 0.049285888671875, -0.00562286376953125, 0.0186004638671875, -0.065673828125, -0.0028228759765625, 0.0285186767578125, 0.047515869140625, 0.004425048828125, -0.0101318359375, -0.025177001953125, -0.004878997802734375, -0.01507568359375, -0.01116943359375, -0.03521728515625, 0.04608154296875, 0.006412506103515625, 0.0009984970092773438, 0.0238037109375, -0.0127410888671875, -0.0367431640625, -0.02288818359375, -0.00957489013671875, 0.06341552734375, 0.002895355224609375, 0.047760009765625, 0.02496337890625, -0.01169586181640625, -0.01136016845703125, 0.0118560791015625, -0.0276641845703125, -0.00348663330078125, 0.0164337158203125, 0.0158843994140625, 0.0242462158203125, 0.0008878707885742188, 0.0294952392578125, -0.04559326171875, -0.0021305084228515625, 0.006011962890625, -0.028411865234375, 0.0384521484375, 0.023040771484375, 0.0457763671875, 0.0084381103515625, 0.01715087890625, 0.0215301513671875, 0.027069091796875, -0.0019025802612304688, 0.013458251953125, 0.03436279296875, -0.058868408203125, 0.02154541015625, 0.019439697265625, 0.0020771026611328125, 0.026214599609375, -0.027069091796875, -0.0004987716674804688, -0.03460693359375, 0.04638671875, 0.0692138671875, 0.02532958984375, 0.02166748046875, -0.0290069580078125, -0.0016021728515625, -0.0190582275390625, 0.01175689697265625, -0.0207977294921875, 0.0174102783203125, 0.01087188720703125, -0.01142120361328125, 0.013580322265625, -0.004367828369140625, -0.042449951171875, 0.01194000244140625, 0.01241302490234375, -0.0208892822265625, -0.02386474609375, 0.0338134765625, -0.031036376953125, -0.0245208740234375, 0.06121826171875, 0.0528564453125, -0.011383056640625, -0.016448974609375, -0.00182342529296875, 0.00963592529296875, -0.046630859375, -0.045928955078125, -0.0052337646484375, -0.0288238525390625, 0.0221710205078125, 0.03466796875, -0.0021724700927734375, -0.01415252685546875, 0.027374267578125, -0.01491546630859375, -0.026580810546875, 0.0160675048828125, -0.0390625, 0.0083160400390625, 0.03192138671875, 0.009002685546875, 0.03033447265625, -0.043670654296875, -0.01377105712890625, -0.00251007080078125, 0.0482177734375, 0.048309326171875], [-0.05419921875, -0.0013103485107421875, -0.01013946533203125, -0.022430419921875, 0.0172119140625, -0.0226898193359375, 0.0038356781005859375, 0.0125579833984375, -0.00833892822265625, 0.0253448486328125, -0.00022530555725097656, 0.0218048095703125, -0.0323486328125, 0.004917144775390625, -0.0021572113037109375, 0.01457977294921875, 0.017669677734375, -0.006622314453125, 0.0311279296875, -0.0177001953125, -0.018951416015625, 0.01018524169921875, -0.0157928466796875, 0.06121826171875, 0.01354217529296875, 0.003276824951171875, 0.03704833984375, 0.02490234375, -0.004489898681640625, 0.03887939453125, -0.037384033203125, 0.0286102294921875, 0.01216888427734375, -0.01441192626953125, -0.01557159423828125, 0.0016412734985351562, -0.0261688232421875, -0.00994110107421875, -0.041839599609375, -0.04742431640625, -0.01178741455078125, 0.0119171142578125, 0.04388427734375, -0.07672119140625, 0.05804443359375, -0.0404052734375, -0.001071929931640625, -0.048065185546875, -0.0246429443359375, 0.007228851318359375, 0.0135955810546875, -0.027679443359375, 0.08380126953125, -0.03106689453125, 0.0283203125, 0.01293182373046875, 0.01568603515625, -0.01007843017578125, -0.060943603515625, 0.00894927978515625, -0.00811004638671875, -0.029449462890625, -0.03582763671875, 0.029937744140625, -0.005809783935546875, 0.0211334228515625, 0.0032806396484375, 0.0251617431640625, -0.00325775146484375, 0.004901885986328125, -0.007793426513671875, 0.01776123046875, 0.006076812744140625, -0.00408935546875, -0.04241943359375, -0.03656005859375, 0.07366943359375, 0.01123046875, -0.0182342529296875, 0.038177490234375, 0.058258056640625, 0.0208587646484375, -0.07470703125, 0.0014467239379882812, -0.01139068603515625, 0.06671142578125, 0.015350341796875, 0.014404296875, 0.0056915283203125, 0.02972412109375, -0.02117919921875, -0.004608154296875, -0.0247039794921875, -0.0227203369140625, -0.026458740234375, 0.011962890625, -0.0034618377685546875, 0.0046844482421875, 0.0059967041015625, 0.0218505859375, 0.0491943359375, -0.005344390869140625, 0.0305633544921875, -0.05633544921875, 0.006946563720703125, 0.01020050048828125, -0.0276641845703125, 0.01033782958984375, -0.03582763671875, 0.00738525390625, 0.0309600830078125, 0.05535888671875, -0.0216522216796875, 0.00861358642578125, -0.04986572265625, -0.0253753662109375, -0.0226898193359375, 0.0189361572265625, 0.043701171875, 0.0137176513671875, 0.03851318359375, -0.0083160400390625, 0.049957275390625, -0.03936767578125, -0.00598907470703125, -0.01465606689453125, -0.0272064208984375, 0.01080322265625, -0.0273284912109375, 0.031585693359375, -0.0439453125, 0.03973388671875, 0.00434112548828125, 0.0246429443359375, -0.0019168853759765625, -0.0021610260009765625, 0.01751708984375, -0.00925445556640625, -0.006633758544921875, -0.0127105712890625, 0.0081939697265625, -0.01227569580078125, -0.0026760101318359375, -0.0184783935546875, 0.00426483154296875, -0.052764892578125, 0.0023670196533203125, 0.0007147789001464844, 0.0201568603515625, -0.0310516357421875, 0.01004791259765625, -0.00720977783203125, 0.006778717041015625, 0.021484375, 0.004589080810546875, 0.01038360595703125, 0.0260009765625, -0.01161956787109375, -0.023101806640625, -0.023162841796875, 0.03692626953125, -0.0474853515625, -0.007137298583984375, -0.034423828125, 0.0323486328125, 0.004482269287109375, 0.0112152099609375, 0.01544189453125, -0.0029888153076171875, -0.05889892578125, 0.0031299591064453125, 0.0306243896484375, 0.04278564453125, -0.01556396484375, 0.0092926025390625, 0.007312774658203125, 0.066162109375, 0.0030803680419921875, 0.0258331298828125, -0.036102294921875, -0.022186279296875, -0.0017137527465820312, 0.00695037841796875, 0.01421356201171875, -0.01207733154296875, -0.0001977682113647461, -0.029296875, 0.04010009765625, 0.005489349365234375, 0.0513916015625, -0.023162841796875, -0.038360595703125, 0.00681304931640625, 0.042999267578125, 0.0293731689453125, 0.0284423828125, -0.0025653839111328125, -0.055633544921875, -0.015838623046875, -0.023895263671875, -0.0450439453125, 0.0256500244140625, 0.0149078369140625, -0.03863525390625, -0.016998291015625, -0.047271728515625, -0.05511474609375, -0.025421142578125, -0.007648468017578125, -0.01120758056640625, 0.06817626953125, 0.009613037109375, 0.027587890625, 0.014556884765625, -0.03118896484375, -0.0199737548828125, -0.014373779296875, -0.04693603515625, 0.039825439453125, -0.0343017578125, 0.03759765625, 0.004032135009765625, 0.00946044921875, -0.0036907196044921875, 0.0548095703125, 0.0177459716796875, -0.05224609375, 0.004108428955078125, 0.03192138671875, -0.0296173095703125, -0.0122528076171875, -0.0023651123046875, 0.05230712890625, 0.00455474853515625, 0.0772705078125, 0.023193359375, 0.0305328369140625, 0.01378631591796875, 0.0210113525390625, -0.0286407470703125, -0.03680419921875, -0.0247955322265625, 0.048614501953125, 0.007312774658203125, 0.0063323974609375, 0.006778717041015625, 0.0572509765625, -0.036407470703125, -0.0186004638671875, 0.01230621337890625, 0.02606201171875, 0.01239013671875, 0.00569915771484375, 0.03863525390625, 0.102783203125, 0.0078887939453125, 0.0027217864990234375, -0.01123046875, 0.00732421875, 0.07086181640625, -0.0316162109375, 0.061737060546875, -0.017669677734375, 0.05517578125, 0.053192138671875, 0.015350341796875, 0.01177978515625, 0.01959228515625, -0.02569580078125, -0.0088043212890625, -0.0153961181640625, 0.0198974609375, -0.05633544921875, -0.01169586181640625, -0.00493621826171875, -0.053985595703125, 0.032440185546875, 0.0230560302734375, 0.065673828125, -0.0288238525390625, 0.00774383544921875, 0.01253509521484375, 0.0007853507995605469, -0.01055908203125, -0.00727081298828125, 0.0208892822265625, -0.034393310546875, 0.0005087852478027344, -0.0182952880859375, -0.027557373046875, -0.015716552734375, -0.0648193359375, 0.0323486328125, -0.0012664794921875, -0.053253173828125, 0.00750732421875, -0.0204620361328125, -0.1290283203125, -0.0235595703125, 0.0195465087890625, 0.0221710205078125, 0.0258941650390625, -0.016204833984375, -0.08056640625, -0.01470184326171875, -0.053192138671875, -0.022552490234375, -0.0225067138671875, -0.057830810546875, -0.049591064453125, -0.03704833984375, -0.0026416778564453125, -0.048858642578125, 0.0167236328125, -0.0171966552734375, 0.0164337158203125, -0.0134735107421875, 0.00713348388671875, -0.0208892822265625, 0.01654052734375, 0.01073455810546875, 0.0797119140625, 0.0246124267578125, 0.01059722900390625, 0.043670654296875, -0.050933837890625, -0.034271240234375, -0.0111083984375, -0.0469970703125, -0.00643157958984375, 0.0194091796875, -0.00167083740234375, -0.0029010772705078125, 0.020721435546875, 0.01540374755859375, 0.00978851318359375, 0.005565643310546875, 0.001033782958984375, -0.006084442138671875, -0.04583740234375, 0.035491943359375, -0.01041412353515625, -0.00795745849609375, -0.0230560302734375, 0.00433349609375, -0.0626220703125, 0.01165008544921875, 0.0167236328125, -0.0162811279296875, 0.04931640625, 0.007610321044921875, -0.0309295654296875, 0.00687408447265625, 0.0628662109375, 0.059722900390625, 0.01000213623046875, -0.030120849609375, 0.0002849102020263672, -0.0295867919921875, 0.0252532958984375, 0.025787353515625, -0.037200927734375, 0.026824951171875, 0.0352783203125, 0.004520416259765625, 0.034454345703125, -0.01393890380859375, -0.0163116455078125, -0.040130615234375, -0.014434814453125, -0.058502197265625, -0.0238189697265625, -0.01593017578125, -0.0028362274169921875, -0.06231689453125, 0.0341796875, -0.119873046875, -0.031829833984375, -0.0004622936248779297, -0.008209228515625, -0.004383087158203125, -0.0161285400390625, -0.01197052001953125, -0.0159759521484375, 0.0400390625, -0.06640625, 0.2117919921875, 0.00516510009765625, -0.0295257568359375, -0.0030155181884765625, 0.05279541015625, -0.02105712890625, 0.0162811279296875, -0.0259246826171875, 0.00909423828125, -0.0221405029296875, -0.041168212890625, -0.00785064697265625, 0.0304107666015625, -0.0170745849609375, -0.00533294677734375, 0.006000518798828125, -0.012908935546875, -0.019683837890625, 0.09942626953125, -0.037139892578125, -0.01751708984375, -0.0132904052734375, -0.03131103515625, 0.058441162109375, -0.006633758544921875, -0.00907135009765625, 0.010986328125, 0.01678466796875, -0.042938232421875, -0.0198822021484375, 0.01207733154296875, 0.0127105712890625, -0.00962066650390625, 0.05523681640625, 0.032135009765625, -0.06878662109375, -0.0129852294921875, 0.006946563720703125, 0.005214691162109375, -0.011627197265625, -0.030487060546875, 0.00959014892578125, 0.0345458984375, 0.01036834716796875, 0.0787353515625, -0.034698486328125, 0.01224517822265625, 0.013641357421875, 0.00670623779296875, -0.049591064453125, 0.03021240234375, -0.036102294921875, -0.015533447265625, 0.0168609619140625, -0.03997802734375, -0.0011053085327148438, -0.033294677734375, 0.010498046875, -0.015350341796875, -0.0293731689453125, 0.037017822265625, 0.009033203125, -0.00592041015625, -0.01136016845703125, -0.00033855438232421875, -0.032257080078125, -0.0570068359375, -0.0136566162109375, 0.0110321044921875, 0.0197296142578125, -0.010711669921875, -0.034759521484375, -0.0107574462890625, -0.018890380859375, 0.016876220703125, 0.0457763671875, -0.04736328125, 0.0129852294921875, -0.01666259765625, -0.0084686279296875, 0.0113372802734375, -0.04559326171875, -0.043853759765625, -0.0188446044921875, 0.0124053955078125, 0.041534423828125, -0.058441162109375, 0.012451171875, 0.00901031494140625, -0.01459503173828125, 0.007205963134765625, 0.00039696693420410156, -0.003376007080078125, 0.0122528076171875, 0.0005612373352050781, 0.003475189208984375, 0.01727294921875, -0.00743865966796875, -0.030792236328125, 0.021484375, -0.0159759521484375, -0.02252197265625, -0.01556396484375, -0.028228759765625, 0.032257080078125, 0.0212860107421875, -0.027374267578125, 0.037139892578125, 0.0166473388671875, -0.00951385498046875, -0.0129547119140625, 0.02703857421875, -0.03680419921875, 0.0055084228515625, 0.03167724609375, 0.050628662109375, 0.02880859375, 0.006076812744140625, 0.0125274658203125, -0.01111602783203125, 0.0060577392578125, -0.001255035400390625, -0.04693603515625, -0.0697021484375, -0.01556396484375, -0.0026950836181640625, -0.043975830078125, 0.0225830078125, 0.01739501953125, 0.0150146484375, -0.0015726089477539062, 0.0016908645629882812, -0.022918701171875, 0.018829345703125, -0.004718780517578125, 0.0218963623046875, -0.0178985595703125, 0.043792724609375, -0.043731689453125, -0.034027099609375, 0.0159149169921875, -0.018585205078125, 0.0240020751953125, -0.005428314208984375, -0.023651123046875, -0.00670623779296875, 0.085693359375, -0.0191497802734375, -0.057464599609375, 0.017059326171875, -0.0182647705078125, 0.010986328125, -0.00583648681640625, 0.01186370849609375, 0.01163482666015625, 0.016845703125, -0.0235748291015625, -0.048187255859375, -0.0066375732421875, -0.03216552734375, -0.006824493408203125, -0.0113372802734375, 0.004787445068359375, 0.034454345703125, 0.00208282470703125, 0.0274810791015625, -0.051422119140625, 0.058197021484375, 0.088623046875, -0.01122283935546875, 0.057861328125, 0.0161285400390625, -0.0286102294921875, 0.016937255859375, -0.0171661376953125, -0.00806427001953125, -0.043304443359375, -0.025177001953125, -0.033935546875, -0.002498626708984375, 0.0305023193359375, -0.036224365234375, 0.05426025390625, 0.0067138671875, 0.039581298828125, 0.0243377685546875, 0.0116729736328125, -0.0168609619140625, 0.0704345703125, -0.032958984375, -0.06134033203125, 0.088623046875, -0.0152587890625, -0.01654052734375, -0.0003485679626464844, -0.01108551025390625, 0.00321197509765625, -0.01195526123046875, -0.0031528472900390625, 0.0011920928955078125, 0.052978515625, 0.0411376953125, 0.006378173828125, -0.00896453857421875, -0.03424072265625, -0.02423095703125, -0.01445770263671875, -0.06439208984375, -0.0443115234375, -0.0162506103515625, -0.054046630859375, -0.0168609619140625, -0.00290679931640625, -0.0203704833984375, 0.0386962890625, 0.0638427734375, -0.04736328125, -0.03253173828125, -0.065673828125, -0.052337646484375, 0.0032520294189453125, 0.0292205810546875, 0.02166748046875, -0.04510498046875, -0.00640869140625, -0.0186767578125, -0.045684814453125, -0.06915283203125, 0.006015777587890625, -0.0246124267578125, 0.0130157470703125, -0.01029205322265625, 0.003520965576171875, 0.0189361572265625, -0.0258636474609375, 0.0229949951171875, 0.0009469985961914062, 0.0162506103515625, 0.01271820068359375, 0.005390167236328125, 0.048431396484375, 0.0117645263671875, 0.02227783203125, 0.0272064208984375, -0.01422882080078125, -0.0032958984375, 0.031494140625, 0.0253448486328125, 0.01139068603515625, 0.0241241455078125, -0.01094818115234375, 0.0450439453125, 0.0145111083984375, 0.00888824462890625, -0.0174560546875, 0.0028228759765625, -0.0238189697265625, 0.031158447265625, -0.083251953125, 0.0014934539794921875, -0.00504302978515625, -0.031890869140625, -0.00800323486328125, -0.0283660888671875, -0.0024318695068359375, 0.004360198974609375, 0.03277587890625, 0.048492431640625, -0.038116455078125, -0.022216796875, 0.025146484375, -0.001373291015625, -0.00917816162109375, -0.038818359375, 0.03277587890625, -0.0036220550537109375, -0.035614013671875, -0.0296173095703125, -0.00806427001953125, 0.01326751708984375, -0.024810791015625, 0.006000518798828125, 0.01568603515625, -0.025238037109375, -0.01239776611328125, 0.0650634765625, 0.0160369873046875, -0.0026702880859375, -0.0021076202392578125, -0.033843994140625, -0.0211334228515625, 0.0190582275390625, -0.061004638671875, 0.0423583984375, -0.005519866943359375, 0.004917144775390625, -0.0157928466796875, 0.021575927734375, -0.0291595458984375, -0.0010890960693359375, -0.035125732421875, -0.01224517822265625, -0.05853271484375, -0.006130218505859375, -0.04669189453125, -0.05084228515625, -0.004688262939453125, 0.01300048828125, 0.059478759765625, 0.01007843017578125, -0.0007510185241699219, -0.042724609375, -0.0176544189453125, -0.0306549072265625, -0.017242431640625, -0.0146942138671875, -0.038238525390625, -0.011199951171875, -0.0200958251953125, -0.0100555419921875, -0.0213775634765625, -0.007045745849609375, 0.0109405517578125, -0.006458282470703125, -0.0106658935546875, -0.0292205810546875, 0.0009260177612304688, 0.016021728515625, -0.0555419921875, -0.031982421875, -0.0143585205078125, 0.002285003662109375, -0.0165863037109375, 0.051727294921875, 0.022216796875, 0.056549072265625, -0.025543212890625, -0.032928466796875, 0.049530029296875, 0.01354217529296875, -0.021148681640625, 0.016021728515625, 0.024871826171875, 0.0032100677490234375, 0.0484619140625, -0.0239410400390625, -0.0004639625549316406, -0.033935546875, 0.0230255126953125, 0.00748443603515625, 0.04473876953125, 0.043548583984375, -0.0124664306640625, -0.028045654296875, 0.031768798828125, 0.0045013427734375, 0.0284576416015625, 0.01454925537109375, 0.0350341796875, -0.050933837890625, 0.017547607421875, 0.0149993896484375, 0.00556182861328125, -0.0015649795532226562, -0.066162109375, 0.01263427734375, -0.00522613525390625, 0.00952911376953125, 0.005680084228515625, -0.0341796875, -0.01274871826171875, 0.0164794921875, 0.019134521484375, -0.014678955078125, -0.059326171875, 0.018585205078125, -0.013153076171875, -0.007389068603515625, 0.00897216796875, -0.05035400390625, 0.00775909423828125, -0.021942138671875, -0.08111572265625, -0.038116455078125, 0.00859832763671875, -0.00330352783203125, 0.025634765625, -0.00724029541015625, 0.034637451171875, 0.0231475830078125, -0.006244659423828125, 0.019744873046875, -0.03900146484375, -0.0016908645629882812, -0.12164306640625, -0.02203369140625, 0.0008058547973632812, 0.01271820068359375, -0.0181427001953125, -0.0150299072265625, 0.037506103515625, 0.025421142578125, 0.00644683837890625, -0.0164947509765625, -0.01268768310546875, 0.036590576171875, -0.012481689453125, -0.0098724365234375, 0.0182647705078125, 0.072509765625, -0.0007724761962890625, -0.0171051025390625, -0.006805419921875, -0.0130462646484375, -0.01178741455078125, 0.0024356842041015625, 0.01155853271484375, 0.0225372314453125, 0.0306243896484375, 0.041290283203125, -0.0165252685546875, 0.053375244140625, -0.0186614990234375, -0.040496826171875, 0.06085205078125, -0.0181427001953125, 0.0235748291015625, 0.019927978515625, -0.0272979736328125, 0.03302001953125, -0.037933349609375, 0.0135040283203125, -0.005588531494140625, -0.0361328125, -0.010650634765625, 0.01078033447265625, -0.0248565673828125, -0.0020236968994140625, 0.0253753662109375, -0.018096923828125, -0.02630615234375, -0.026641845703125, -0.020751953125, 0.06500244140625, 0.0240936279296875, 0.034027099609375, 0.03985595703125, 0.045013427734375, -0.00800323486328125, 0.04412841796875, -0.0304107666015625, 0.00412750244140625, 0.0310516357421875, -0.034637451171875, -0.0019474029541015625, 0.03411865234375, 0.00548553466796875, -0.033203125, 0.013641357421875, -0.0104522705078125, -0.05499267578125, -0.0096282958984375, 0.0126190185546875, -0.0167388916015625, -0.0290679931640625, 0.059661865234375, 0.00437164306640625, -0.031890869140625, 0.027313232421875, 0.020355224609375, 0.004337310791015625, 0.0111541748046875, -0.001529693603515625, 0.003047943115234375, 0.0208587646484375, 0.0093536376953125, -0.0218353271484375, -0.036651611328125, 0.026153564453125, -0.00362396240234375, -0.002155303955078125, 0.02398681640625, -0.0138092041015625, -0.0168304443359375, 0.0523681640625, -0.00553131103515625, 0.00249481201171875, -0.090087890625, -0.0207061767578125, -0.0302276611328125, -0.0107879638671875, 0.0095062255859375, -0.0182342529296875, -0.00928497314453125, 0.0057525634765625, 0.0274810791015625, -0.0006041526794433594, 0.006389617919921875, -0.0161285400390625, -0.035186767578125, 0.048828125, 0.008087158203125, -0.0234222412109375, 0.042816162109375, -0.0576171875, -0.0252227783203125, -0.01324462890625, -0.005157470703125, -0.0077972412109375, 0.00164794921875, 0.0247955322265625, -0.0251617431640625, 0.0159759521484375, 0.025115966796875, 0.038970947265625, 0.0193634033203125, -0.0226287841796875, -0.005695343017578125, 0.032806396484375, 0.0318603515625, 0.005767822265625, 0.0027332305908203125, 0.027496337890625, 0.0411376953125, -0.00972747802734375, -0.0218658447265625, -0.038421630859375, 0.00586700439453125, 0.005115509033203125, 0.024566650390625, 0.01074981689453125, 0.04132080078125, -0.001422882080078125, -0.039215087890625, 0.045684814453125, 0.0190582275390625, 0.0213775634765625, 0.037200927734375, -0.014556884765625, -0.0169677734375, 0.0361328125, -0.0211181640625, -0.0341796875, -0.005794525146484375, 0.021881103515625, 0.04443359375, -0.0283203125, 0.0170745849609375, 0.00881195068359375, -0.056854248046875, -0.0241851806640625, -0.057464599609375, -0.0175628662109375, 0.0335693359375, 0.035186767578125, -0.0760498046875, -0.025115966796875, -0.0157012939453125, -0.01418304443359375, 0.00821685791015625, -5.346536636352539e-05, -0.01525115966796875, -0.005855560302734375, 0.01458740234375, 0.01471710205078125, 0.009368896484375, -0.035491943359375, 0.0260009765625, 0.031280517578125, -0.0003612041473388672, 0.0177459716796875, 0.0193634033203125, 0.0792236328125, -0.0229949951171875, 0.060028076171875, 0.01541900634765625, 0.0288238525390625, -0.005367279052734375, -0.0021152496337890625, -0.0199737548828125, -0.050262451171875, -0.0220489501953125, 0.00998687744140625, 0.025604248046875, 0.00614166259765625, 0.01995849609375, 0.01312255859375, -0.04510498046875, 0.06732177734375, 0.006984710693359375, 0.0075531005859375, 0.0576171875, 0.0071258544921875, 0.016357421875, -0.01544189453125, 0.0048980712890625, 0.0029087066650390625, -0.048919677734375, 0.00797271728515625, -0.001003265380859375, 0.01523590087890625, -0.0285186767578125, -0.02593994140625, -0.0165863037109375, -0.03106689453125, -0.006900787353515625, -0.003116607666015625, 0.0704345703125, -0.0050506591796875, -0.001354217529296875, 0.00685882568359375, 0.0308380126953125, 0.0011148452758789062, -0.07025146484375, 0.00814056396484375, 0.00981903076171875, 0.0213623046875, 0.0177001953125, 0.054473876953125, -0.03338623046875, -0.00943756103515625, -0.01526641845703125, 0.0084991455078125, -0.01535797119140625, -0.0051422119140625, -0.0173187255859375, -0.039276123046875, 0.058319091796875, -0.00972747802734375, 0.0155487060546875, 0.0178375244140625, 0.01192474365234375, 0.044219970703125, -0.0203857421875, 0.0103759765625, -0.0182342529296875, -0.0008640289306640625, -0.005428314208984375]][[0.00771331787109375, 0.01000213623046875, -0.04278564453125, -0.050262451171875, 0.00998687744140625, 0.0013494491577148438, 0.01245880126953125, -0.0185394287109375, 0.01195526123046875, -0.0302886962890625, -0.01511383056640625, 0.06768798828125, -0.0260009765625, 0.0086517333984375, 0.027313232421875, -0.01329803466796875, -0.00011336803436279297, 0.0050811767578125, 0.028656005859375, -0.0037746429443359375, 0.0027904510498046875, -0.0347900390625, -0.03448486328125, 0.024505615234375, 0.00124359130859375, -0.01197052001953125, 0.015594482421875, 0.0015659332275390625, -0.031158447265625, -0.0635986328125, 0.021697998046875, -0.0283050537109375, 0.0166015625, -0.020751953125, -0.006946563720703125, -0.01806640625, 0.0223541259765625, -0.02386474609375, -0.052825927734375, -0.00640106201171875, -0.00830841064453125, 0.0150299072265625, 0.006641387939453125, -0.042999267578125, -0.0016164779663085938, -0.082275390625, -0.02728271484375, -0.058380126953125, -0.0016679763793945312, 0.0256195068359375, 0.031829833984375, 0.0101165771484375, 0.041229248046875, -0.0194091796875, 0.03619384765625, -0.0095977783203125, 0.0141143798828125, 0.06011962890625, -0.059814453125, 0.006267547607421875, -0.044464111328125, -0.005771636962890625, -0.0161895751953125, -0.02264404296875, 0.0472412109375, 0.028228759765625, -0.0209808349609375, 0.0114898681640625, -0.00047588348388671875, -0.00928497314453125, -0.04083251953125, 7.11679458618164e-05, -0.053497314453125, 0.01558685302734375, -0.0467529296875, 0.01131439208984375, -0.009368896484375, -4.100799560546875e-05, -0.0236663818359375, -0.01416778564453125, 0.09259033203125, 0.043060302734375, 0.005756378173828125, -0.01812744140625, -0.0014142990112304688, 0.04510498046875, -0.00246429443359375, -0.005443572998046875, 0.01177215576171875, -0.07586669921875, -0.0232086181640625, 0.01430511474609375, -0.01248931884765625, -0.03497314453125, -0.018707275390625, 0.01180267333984375, -0.08746337890625, 0.0675048828125, -0.0117645263671875, -0.0274200439453125, -0.047210693359375, 0.040313720703125, -0.0183868408203125, -0.0128936767578125, 0.0312347412109375, 0.0306854248046875, 0.06304931640625, -0.01352691650390625, 0.018096923828125, 0.0084228515625, 0.0041046142578125, 0.0273284912109375, 0.0167999267578125, -0.05474853515625, -0.03875732421875, -0.041259765625, -0.035888671875, -0.055755615234375, 0.009185791015625, -0.01224517822265625, 0.020751953125, 0.00586700439453125, 0.03936767578125, -0.042724609375, -0.0478515625, 0.039947509765625, 0.019500732421875, 0.038818359375, -0.04754638671875, 0.0184326171875, -0.0238800048828125, -0.01324462890625, -0.0258636474609375, 0.0113677978515625, -0.0189666748046875, -0.01454925537109375, 0.03057861328125, 0.0151519775390625, -0.0195770263671875, -0.024078369140625, 0.012115478515625, 0.024658203125, 0.002124786376953125, -0.02691650390625, -0.004245758056640625, -0.0181427001953125, 0.0028324127197265625, -0.07391357421875, -0.01406097412109375, 0.004024505615234375, 0.0307464599609375, -0.0134429931640625, 0.049530029296875, -0.01453399658203125, -0.0278167724609375, -0.0173187255859375, -0.01410675048828125, 0.029815673828125, 0.035247802734375, 0.0140533447265625, 0.08160400390625, 0.030120849609375, -0.020477294921875, -0.07635498046875, 0.01422882080078125, 0.035308837890625, -0.040771484375, 0.0455322265625, 0.0011281967163085938, 0.00604248046875, 0.0279388427734375, -0.0394287109375, -0.0019178390502929688, -0.0168609619140625, -0.001873016357421875, -0.0032863616943359375, 0.050933837890625, 0.0042572021484375, -0.01023101806640625, -0.0041046142578125, 0.006137847900390625, 0.039093017578125, -0.01448822021484375, -0.051239013671875, -0.027099609375, -0.02716064453125, 0.010009765625, 0.0281982421875, 0.022430419921875, 0.0174560546875, -0.015594482421875, 0.01021575927734375, 0.02899169921875, 0.01092529296875, -0.005489349365234375, 0.0338134765625, -0.005710601806640625, -0.0911865234375, -0.0140533447265625, 0.007476806640625, 0.0008106231689453125, 0.0022373199462890625, 0.007709503173828125, 0.0180511474609375, -0.0435791015625, -0.0158538818359375, -0.10662841796875, -0.03192138671875, 0.0151519775390625, -0.015716552734375, -0.061187744140625, 0.01776123046875, 0.05029296875, 0.07958984375, -0.00403594970703125, -0.0286712646484375, 0.015350341796875, -0.0020599365234375, 0.0158233642578125, 0.00399017333984375, 0.003627777099609375, -0.014373779296875, -0.0036563873291015625, -0.00319671630859375, -0.007648468017578125, 0.0223236083984375, -0.0057830810546875, -0.041900634765625, -0.02752685546875, -0.026092529296875, -0.01325225830078125, -0.010467529296875, 0.003665924072265625, 0.0165252685546875, 0.032867431640625, -0.02435302734375, -0.006927490234375, 0.030303955078125, 0.01385498046875, -0.02313232421875, -0.04193115234375, 0.0377197265625, -0.0438232421875, -0.057891845703125, -0.016021728515625, -0.0159149169921875, 0.033782958984375, -0.05450439453125, -0.0027523040771484375, -0.0015506744384765625, 0.0304718017578125, -0.02447509765625, 0.0211181640625, 0.02081298828125, 0.034912109375, 0.02801513671875, 0.0142059326171875, -0.0171356201171875, 0.035003662109375, 0.0030841827392578125, -0.0035953521728515625, -0.005039215087890625, -0.00353240966796875, 0.04949951171875, 0.00618743896484375, -0.00870513916015625, -0.002960205078125, 0.046905517578125, 0.01202392578125, -0.006412506103515625, -0.05029296875, -0.0081024169921875, -0.028594970703125, 0.015655517578125, -0.0228271484375, 0.0121307373046875, -0.023468017578125, -0.0079193115234375, 0.0263671875, -0.014190673828125, 0.0167999267578125, -0.0016412734985351562, -0.0004382133483886719, -0.02691650390625, 0.023681640625, -0.0250701904296875, -0.0303955078125, -0.054840087890625, -0.0016727447509765625, -0.0274658203125, -0.0184478759765625, -0.0104522705078125, 0.04248046875, 0.024749755859375, -0.03533935546875, -0.04681396484375, -0.05596923828125, -0.157470703125, -0.0276641845703125, 0.003192901611328125, 0.04840087890625, 0.0203399658203125, -0.0149078369140625, 0.0266876220703125, -0.0177764892578125, -0.01371002197265625, -0.00868988037109375, -0.054412841796875, -0.038482666015625, 0.0155487060546875, 0.004375457763671875, -0.007793426513671875, -0.00435638427734375, 0.01525115966796875, 0.01227569580078125, 0.0296478271484375, -0.00011074542999267578, 0.049530029296875, -0.029541015625, 0.03607177734375, -0.035003662109375, 0.02056884765625, -0.04327392578125, 0.02947998046875, 0.029876708984375, -0.0232696533203125, -0.0511474609375, 0.012451171875, -0.011932373046875, -0.01084136962890625, 0.0321044921875, 0.0215911865234375, 0.0012712478637695312, -0.0302734375, -0.01971435546875, 0.0213470458984375, 0.0103302001953125, 0.0033054351806640625, 0.0176544189453125, -0.01024627685546875, 0.007015228271484375, -0.0193328857421875, -0.050323486328125, -0.00948333740234375, -0.01788330078125, 0.00394439697265625, 0.0096282958984375, -0.07135009765625, 0.0054168701171875, -0.025787353515625, -0.01971435546875, -0.0152587890625, 0.0263214111328125, -0.00574493408203125, 0.032470703125, -0.005115509033203125, 0.00977325439453125, -0.021148681640625, 0.0014219284057617188, 0.01096343994140625, 0.0306243896484375, 0.0025577545166015625, -0.0300445556640625, -0.00799560546875, -0.0079803466796875, 0.01132965087890625, -0.0036773681640625, 0.002010345458984375, 0.0171356201171875, -0.01080322265625, -0.019744873046875, 0.01036834716796875, 0.007045745849609375, 0.028289794921875, 0.001064300537109375, 0.0386962890625, -0.12017822265625, -0.0005102157592773438, 0.035888671875, -0.021942138671875, 0.03582763671875, -0.028900146484375, 0.01467132568359375, -0.021453857421875, 0.0011014938354492188, -0.02435302734375, 0.2071533203125, 0.01568603515625, 0.036895751953125, -0.005054473876953125, 0.01531219482421875, -0.0033111572265625, -0.0041046142578125, -0.038055419921875, 0.004215240478515625, -0.00018155574798583984, -0.06982421875, -0.0158538818359375, 0.0146331787109375, -0.0158843994140625, 0.0291900634765625, 0.008087158203125, -0.013946533203125, 0.00875091552734375, -0.0073089599609375, 0.00812530517578125, -0.01140594482421875, 0.028045654296875, 0.022308349609375, 0.01125335693359375, -0.01812744140625, -0.037933349609375, 0.0177764892578125, 0.063232421875, -0.036346435546875, 0.00814056396484375, -0.00936126708984375, -0.01093292236328125, 0.0012903213500976562, -0.032257080078125, 0.036407470703125, -0.03289794921875, 0.005786895751953125, -0.0217132568359375, -0.03057861328125, 0.0028285980224609375, 0.0207977294921875, -0.0401611328125, -0.00759124755859375, 0.0279541015625, 0.03936767578125, -0.00542449951171875, 0.038482666015625, -0.029754638671875, -0.02215576171875, -0.046600341796875, 0.07623291015625, 0.006763458251953125, -0.0231475830078125, 0.0110931396484375, -0.0173187255859375, 0.0277099609375, -0.0167236328125, -0.019744873046875, 0.0003802776336669922, -0.01456451416015625, -0.0007686614990234375, 0.01190185546875, -0.00713348388671875, -0.0316162109375, 0.0269012451171875, -0.046783447265625, 0.0032444000244140625, -0.01306915283203125, -0.027618408203125, -0.02886962890625, 0.035064697265625, -0.03143310546875, -0.0249176025390625, -0.0552978515625, 0.037628173828125, -0.01123809814453125, -0.04486083984375, 0.02105712890625, 0.0088043212890625, -0.026123046875, 0.0240478515625, -0.0093231201171875, -0.04888916015625, -0.06207275390625, -0.0003979206085205078, 0.0391845703125, -0.006549835205078125, 0.008148193359375, -0.01551055908203125, -0.03741455078125, 0.033538818359375, 0.029327392578125, -0.0267486572265625, -0.01080322265625, 0.04034423828125, 0.00746917724609375, 0.00945281982421875, 0.047698974609375, -0.0157470703125, 0.006504058837890625, 0.0255279541015625, -0.01080322265625, 0.007537841796875, 0.01294708251953125, -0.0179901123046875, -0.0633544921875, 0.02203369140625, 0.046905517578125, 0.000728607177734375, -0.05419921875, -0.032501220703125, 0.00849151611328125, 0.022979736328125, 0.0017709732055664062, -0.01248931884765625, 0.025360107421875, 0.0196990966796875, -0.01268768310546875, -0.017486572265625, 0.0357666015625, -0.042572021484375, -0.0322265625, 0.0110931396484375, 0.0027904510498046875, -0.006683349609375, 0.001857757568359375, -0.0102386474609375, 0.04388427734375, -0.03338623046875, -0.0021533966064453125, -0.00339508056640625, 0.01425933837890625, 0.05157470703125, 0.04241943359375, 0.0155792236328125, -0.003940582275390625, 0.01043701171875, -0.0073699951171875, -0.0277862548828125, 0.033447265625, 0.014190673828125, -0.046295166015625, 0.01216888427734375, 0.00786590576171875, 0.0185699462890625, 0.083251953125, 0.04864501953125, -0.01953125, -0.0087127685546875, 0.0294189453125, -0.0222625732421875, -0.01088714599609375, 0.01361083984375, -0.069091796875, -0.019134521484375, 0.00484466552734375, -0.0222625732421875, -0.05950927734375, 0.060455322265625, -0.026763916015625, 0.017242431640625, 0.0168914794921875, -0.000568389892578125, 0.05670166015625, 0.006038665771484375, 0.06231689453125, -0.05633544921875, -0.0222625732421875, 0.024993896484375, -0.01152801513671875, 0.061676025390625, -0.047393798828125, -0.0033359527587890625, 0.0101165771484375, 0.037689208984375, 0.04071044921875, -0.01149749755859375, -0.01352691650390625, 0.0177459716796875, -0.00745391845703125, -0.002544403076171875, 0.025177001953125, 0.05340576171875, 0.03778076171875, -0.0265045166015625, 0.042236328125, -0.05096435546875, -0.007343292236328125, -0.0222625732421875, -0.01177978515625, -0.0200653076171875, 0.031829833984375, -0.0208587646484375, 0.01934814453125, 0.05010986328125, -0.02587890625, -0.046173095703125, 0.0165557861328125, 0.0198211669921875, -0.016204833984375, -0.01256561279296875, -0.0107269287109375, -0.01212310791015625, 0.007251739501953125, 0.007297515869140625, 0.004241943359375, -0.0099639892578125, 0.0036468505859375, -0.020111083984375, 0.00024819374084472656, 0.00852203369140625, 0.0024890899658203125, 0.047332763671875, -0.0216064453125, 0.0438232421875, -0.0057373046875, -0.0616455078125, 0.0191802978515625, -0.00545501708984375, -0.033172607421875, 0.0002777576446533203, 0.054656982421875, 0.01934814453125, -0.01361846923828125, 0.017608642578125, -0.003032684326171875, 0.00672149658203125, -0.0164642333984375, 0.00978851318359375, -0.0260772705078125, 0.006771087646484375, 0.046234130859375, 0.004673004150390625, -0.023284912109375, 0.017242431640625, -0.0017919540405273438, 0.034637451171875, -0.00690460205078125, 0.07769775390625, -0.03936767578125, -0.00616455078125, 0.022979736328125, 0.00228118896484375, 0.037811279296875, -0.0237884521484375, 0.050018310546875, -0.00417327880859375, 0.01512908935546875, -0.023162841796875, 0.07403564453125, 0.0271759033203125, 0.014404296875, 0.0199737548828125, 0.02105712890625, -0.066162109375, 0.053192138671875, -0.001476287841796875, 0.0223846435546875, 0.01056671142578125, 0.059478759765625, 0.00229644775390625, 0.027862548828125, -0.0377197265625, 0.0130157470703125, -0.0286865234375, -0.01468658447265625, 0.0281982421875, -0.038421630859375, -0.037384033203125, 0.0015954971313476562, 0.01107025146484375, -0.009063720703125, -0.08074951171875, -0.0037364959716796875, -0.007244110107421875, 0.01462554931640625, 0.0225677490234375, -0.007175445556640625, -0.00858306884765625, 0.01293182373046875, -0.0081634521484375, 0.0498046875, -0.0007128715515136719, 0.0709228515625, -0.0296630859375, 0.035797119140625, -0.0142669677734375, 0.0087432861328125, 0.046295166015625, -0.0156097412109375, 0.006450653076171875, -0.024017333984375, -0.030609130859375, 0.06646728515625, 0.037811279296875, 0.0140533447265625, -0.035888671875, 0.086181640625, -0.024505615234375, -0.0174560546875, -0.018829345703125, -0.006313323974609375, -0.035888671875, 0.00980377197265625, -0.0271453857421875, -0.01021575927734375, 0.01454925537109375, 0.02099609375, -0.0215606689453125, -0.038604736328125, 0.005340576171875, -0.00595855712890625, 0.02484130859375, -0.036712646484375, -0.00502777099609375, -0.012603759765625, -0.03369140625, 0.014373779296875, 0.007793426513671875, 0.08685302734375, 0.0377197265625, -0.011199951171875, 0.0330810546875, -0.0265960693359375, 0.031341552734375, -0.012176513671875, -0.00035858154296875, -0.004093170166015625, -0.023834228515625, -0.0266876220703125, -0.039825439453125, 0.023834228515625, -0.0177459716796875, -0.041900634765625, -0.018707275390625, -0.00470733642578125, -0.0166015625, -0.0072021484375, 0.038543701171875, -0.0241851806640625, -0.0182952880859375, -0.044403076171875, 0.0250396728515625, -0.0013952255249023438, 0.00150299072265625, -0.01393890380859375, 0.01342010498046875, -0.0015926361083984375, -0.0347900390625, -0.01175689697265625, 0.010955810546875, 0.0233001708984375, 0.00992584228515625, -0.0684814453125, -0.0004000663757324219, 0.0219573974609375, -0.12030029296875, -0.051239013671875, 0.0050048828125, 0.01141357421875, -0.0055694580078125, -0.01256561279296875, 0.0247344970703125, 0.045318603515625, -0.0287322998046875, 0.061981201171875, 0.0352783203125, 0.0296173095703125, -0.07476806640625, -0.00646209716796875, 0.014312744140625, 0.0039825439453125, 0.0018930435180664062, 0.01194000244140625, 0.014862060546875, 0.046722412109375, 0.004405975341796875, -0.026123046875, 0.020660400390625, -0.0188751220703125, -0.032501220703125, -0.054901123046875, -0.02313232421875, -0.02215576171875, 3.510713577270508e-05, -0.0030040740966796875, -0.030181884765625, -0.01221466064453125, 0.059173583984375, 0.0013456344604492188, -0.0069732666015625, -0.004764556884765625, -0.0213775634765625, -0.0147552490234375, -0.0966796875, -0.0007205009460449219, 0.037628173828125, -0.050079345703125, -0.0227203369140625, -0.0164031982421875, 0.0005640983581542969, -0.0287322998046875, 0.011383056640625, -0.0218505859375, -0.0006556510925292969, 0.021209716796875, -0.01377105712890625, -0.0022029876708984375, -0.044677734375, 0.0303955078125, 0.009033203125, -0.00415802001953125, -0.0223388671875, 0.051544189453125, -0.0261383056640625, 0.0122222900390625, 0.039154052734375, 0.01873779296875, 0.072265625, -0.048980712890625, 0.030426025390625, -0.00548553466796875, -0.0294036865234375, -0.06170654296875, 0.0200042724609375, 0.0426025390625, 0.032440185546875, 0.02056884765625, -0.0027484893798828125, -0.0223388671875, 0.00391387939453125, 0.0044708251953125, 0.0086517333984375, -0.01174163818359375, 0.06549072265625, 0.03692626953125, -0.01922607421875, -0.049285888671875, 0.031494140625, -0.047088623046875, 0.0275726318359375, 0.0057220458984375, -0.0215301513671875, 0.0216217041015625, 0.0318603515625, -0.03533935546875, 0.041290283203125, 0.0168914794921875, -0.020172119140625, 0.00160980224609375, -0.006927490234375, 0.0309600830078125, -0.0260467529296875, 0.032318115234375, 0.030059814453125, 0.058349609375, -0.0247955322265625, -0.0423583984375, -0.029022216796875, -0.0022411346435546875, -0.0041351318359375, 0.0096435546875, 0.00649261474609375, -0.045623779296875, -0.0237884521484375, 0.0007915496826171875, 0.016143798828125, -0.045806884765625, 0.0259246826171875, 0.0164794921875, 0.0150146484375, -0.01004791259765625, -0.04803466796875, 0.02264404296875, 0.0174102783203125, 0.03729248046875, -0.06414794921875, -0.002910614013671875, -0.027618408203125, 0.00246429443359375, -0.0221405029296875, 0.02288818359375, 0.0018711090087890625, -0.0139007568359375, -0.10052490234375, 0.0102386474609375, -0.034912109375, 0.005687713623046875, -0.01031494140625, 0.00960540771484375, -8.940696716308594e-07, 0.04852294921875, 0.009735107421875, -0.0406494140625, 0.00926971435546875, 0.037139892578125, 0.0004677772521972656, -0.01314544677734375, -0.02667236328125, -0.060882568359375, 0.0175933837890625, -0.03741455078125, 0.056854248046875, 0.01293182373046875, 0.0430908203125, -0.018798828125, 0.03472900390625, 0.040496826171875, -0.03216552734375, 0.01776123046875, 0.008270263671875, -0.01271820068359375, 0.0084381103515625, -0.00919342041015625, 0.01239776611328125, 0.0261077880859375, 0.0260162353515625, -0.0207977294921875, -0.01251983642578125, -0.01288604736328125, -0.0017137527465820312, 0.022552490234375, 0.08380126953125, -0.0192413330078125, 0.0266876220703125, -0.054412841796875, 0.00975799560546875, 0.015838623046875, -0.031768798828125, 0.0166168212890625, 0.049285888671875, -0.00562286376953125, 0.0186004638671875, -0.065673828125, -0.0028228759765625, 0.0285186767578125, 0.047515869140625, 0.004425048828125, -0.0101318359375, -0.025177001953125, -0.004878997802734375, -0.01507568359375, -0.01116943359375, -0.03521728515625, 0.04608154296875, 0.006412506103515625, 0.0009984970092773438, 0.0238037109375, -0.0127410888671875, -0.0367431640625, -0.02288818359375, -0.00957489013671875, 0.06341552734375, 0.002895355224609375, 0.047760009765625, 0.02496337890625, -0.01169586181640625, -0.01136016845703125, 0.0118560791015625, -0.0276641845703125, -0.00348663330078125, 0.0164337158203125, 0.0158843994140625, 0.0242462158203125, 0.0008878707885742188, 0.0294952392578125, -0.04559326171875, -0.0021305084228515625, 0.006011962890625, -0.028411865234375, 0.0384521484375, 0.023040771484375, 0.0457763671875, 0.0084381103515625, 0.01715087890625, 0.0215301513671875, 0.027069091796875, -0.0019025802612304688, 0.013458251953125, 0.03436279296875, -0.058868408203125, 0.02154541015625, 0.019439697265625, 0.0020771026611328125, 0.026214599609375, -0.027069091796875, -0.0004987716674804688, -0.03460693359375, 0.04638671875, 0.0692138671875, 0.02532958984375, 0.02166748046875, -0.0290069580078125, -0.0016021728515625, -0.0190582275390625, 0.01175689697265625, -0.0207977294921875, 0.0174102783203125, 0.01087188720703125, -0.01142120361328125, 0.013580322265625, -0.004367828369140625, -0.042449951171875, 0.01194000244140625, 0.01241302490234375, -0.0208892822265625, -0.02386474609375, 0.0338134765625, -0.031036376953125, -0.0245208740234375, 0.06121826171875, 0.0528564453125, -0.011383056640625, -0.016448974609375, -0.00182342529296875, 0.00963592529296875, -0.046630859375, -0.045928955078125, -0.0052337646484375, -0.0288238525390625, 0.0221710205078125, 0.03466796875, -0.0021724700927734375, -0.01415252685546875, 0.027374267578125, -0.01491546630859375, -0.026580810546875, 0.0160675048828125, -0.0390625, 0.0083160400390625, 0.03192138671875, 0.009002685546875, 0.03033447265625, -0.043670654296875, -0.01377105712890625, -0.00251007080078125, 0.0482177734375, 0.048309326171875], [-0.05419921875, -0.0013103485107421875, -0.01013946533203125, -0.022430419921875, 0.0172119140625, -0.0226898193359375, 0.0038356781005859375, 0.0125579833984375, -0.00833892822265625, 0.0253448486328125, -0.00022530555725097656, 0.0218048095703125, -0.0323486328125, 0.004917144775390625, -0.0021572113037109375, 0.01457977294921875, 0.017669677734375, -0.006622314453125, 0.0311279296875, -0.0177001953125, -0.018951416015625, 0.01018524169921875, -0.0157928466796875, 0.06121826171875, 0.01354217529296875, 0.003276824951171875, 0.03704833984375, 0.02490234375, -0.004489898681640625, 0.03887939453125, -0.037384033203125, 0.0286102294921875, 0.01216888427734375, -0.01441192626953125, -0.01557159423828125, 0.0016412734985351562, -0.0261688232421875, -0.00994110107421875, -0.041839599609375, -0.04742431640625, -0.01178741455078125, 0.0119171142578125, 0.04388427734375, -0.07672119140625, 0.05804443359375, -0.0404052734375, -0.001071929931640625, -0.048065185546875, -0.0246429443359375, 0.007228851318359375, 0.0135955810546875, -0.027679443359375, 0.08380126953125, -0.03106689453125, 0.0283203125, 0.01293182373046875, 0.01568603515625, -0.01007843017578125, -0.060943603515625, 0.00894927978515625, -0.00811004638671875, -0.029449462890625, -0.03582763671875, 0.029937744140625, -0.005809783935546875, 0.0211334228515625, 0.0032806396484375, 0.0251617431640625, -0.00325775146484375, 0.004901885986328125, -0.007793426513671875, 0.01776123046875, 0.006076812744140625, -0.00408935546875, -0.04241943359375, -0.03656005859375, 0.07366943359375, 0.01123046875, -0.0182342529296875, 0.038177490234375, 0.058258056640625, 0.0208587646484375, -0.07470703125, 0.0014467239379882812, -0.01139068603515625, 0.06671142578125, 0.015350341796875, 0.014404296875, 0.0056915283203125, 0.02972412109375, -0.02117919921875, -0.004608154296875, -0.0247039794921875, -0.0227203369140625, -0.026458740234375, 0.011962890625, -0.0034618377685546875, 0.0046844482421875, 0.0059967041015625, 0.0218505859375, 0.0491943359375, -0.005344390869140625, 0.0305633544921875, -0.05633544921875, 0.006946563720703125, 0.01020050048828125, -0.0276641845703125, 0.01033782958984375, -0.03582763671875, 0.00738525390625, 0.0309600830078125, 0.05535888671875, -0.0216522216796875, 0.00861358642578125, -0.04986572265625, -0.0253753662109375, -0.0226898193359375, 0.0189361572265625, 0.043701171875, 0.0137176513671875, 0.03851318359375, -0.0083160400390625, 0.049957275390625, -0.03936767578125, -0.00598907470703125, -0.01465606689453125, -0.0272064208984375, 0.01080322265625, -0.0273284912109375, 0.031585693359375, -0.0439453125, 0.03973388671875, 0.00434112548828125, 0.0246429443359375, -0.0019168853759765625, -0.0021610260009765625, 0.01751708984375, -0.00925445556640625, -0.006633758544921875, -0.0127105712890625, 0.0081939697265625, -0.01227569580078125, -0.0026760101318359375, -0.0184783935546875, 0.00426483154296875, -0.052764892578125, 0.0023670196533203125, 0.0007147789001464844, 0.0201568603515625, -0.0310516357421875, 0.01004791259765625, -0.00720977783203125, 0.006778717041015625, 0.021484375, 0.004589080810546875, 0.01038360595703125, 0.0260009765625, -0.01161956787109375, -0.023101806640625, -0.023162841796875, 0.03692626953125, -0.0474853515625, -0.007137298583984375, -0.034423828125, 0.0323486328125, 0.004482269287109375, 0.0112152099609375, 0.01544189453125, -0.0029888153076171875, -0.05889892578125, 0.0031299591064453125, 0.0306243896484375, 0.04278564453125, -0.01556396484375, 0.0092926025390625, 0.007312774658203125, 0.066162109375, 0.0030803680419921875, 0.0258331298828125, -0.036102294921875, -0.022186279296875, -0.0017137527465820312, 0.00695037841796875, 0.01421356201171875, -0.01207733154296875, -0.0001977682113647461, -0.029296875, 0.04010009765625, 0.005489349365234375, 0.0513916015625, -0.023162841796875, -0.038360595703125, 0.00681304931640625, 0.042999267578125, 0.0293731689453125, 0.0284423828125, -0.0025653839111328125, -0.055633544921875, -0.015838623046875, -0.023895263671875, -0.0450439453125, 0.0256500244140625, 0.0149078369140625, -0.03863525390625, -0.016998291015625, -0.047271728515625, -0.05511474609375, -0.025421142578125, -0.007648468017578125, -0.01120758056640625, 0.06817626953125, 0.009613037109375, 0.027587890625, 0.014556884765625, -0.03118896484375, -0.0199737548828125, -0.014373779296875, -0.04693603515625, 0.039825439453125, -0.0343017578125, 0.03759765625, 0.004032135009765625, 0.00946044921875, -0.0036907196044921875, 0.0548095703125, 0.0177459716796875, -0.05224609375, 0.004108428955078125, 0.03192138671875, -0.0296173095703125, -0.0122528076171875, -0.0023651123046875, 0.05230712890625, 0.00455474853515625, 0.0772705078125, 0.023193359375, 0.0305328369140625, 0.01378631591796875, 0.0210113525390625, -0.0286407470703125, -0.03680419921875, -0.0247955322265625, 0.048614501953125, 0.007312774658203125, 0.0063323974609375, 0.006778717041015625, 0.0572509765625, -0.036407470703125, -0.0186004638671875, 0.01230621337890625, 0.02606201171875, 0.01239013671875, 0.00569915771484375, 0.03863525390625, 0.102783203125, 0.0078887939453125, 0.0027217864990234375, -0.01123046875, 0.00732421875, 0.07086181640625, -0.0316162109375, 0.061737060546875, -0.017669677734375, 0.05517578125, 0.053192138671875, 0.015350341796875, 0.01177978515625, 0.01959228515625, -0.02569580078125, -0.0088043212890625, -0.0153961181640625, 0.0198974609375, -0.05633544921875, -0.01169586181640625, -0.00493621826171875, -0.053985595703125, 0.032440185546875, 0.0230560302734375, 0.065673828125, -0.0288238525390625, 0.00774383544921875, 0.01253509521484375, 0.0007853507995605469, -0.01055908203125, -0.00727081298828125, 0.0208892822265625, -0.034393310546875, 0.0005087852478027344, -0.0182952880859375, -0.027557373046875, -0.015716552734375, -0.0648193359375, 0.0323486328125, -0.0012664794921875, -0.053253173828125, 0.00750732421875, -0.0204620361328125, -0.1290283203125, -0.0235595703125, 0.0195465087890625, 0.0221710205078125, 0.0258941650390625, -0.016204833984375, -0.08056640625, -0.01470184326171875, -0.053192138671875, -0.022552490234375, -0.0225067138671875, -0.057830810546875, -0.049591064453125, -0.03704833984375, -0.0026416778564453125, -0.048858642578125, 0.0167236328125, -0.0171966552734375, 0.0164337158203125, -0.0134735107421875, 0.00713348388671875, -0.0208892822265625, 0.01654052734375, 0.01073455810546875, 0.0797119140625, 0.0246124267578125, 0.01059722900390625, 0.043670654296875, -0.050933837890625, -0.034271240234375, -0.0111083984375, -0.0469970703125, -0.00643157958984375, 0.0194091796875, -0.00167083740234375, -0.0029010772705078125, 0.020721435546875, 0.01540374755859375, 0.00978851318359375, 0.005565643310546875, 0.001033782958984375, -0.006084442138671875, -0.04583740234375, 0.035491943359375, -0.01041412353515625, -0.00795745849609375, -0.0230560302734375, 0.00433349609375, -0.0626220703125, 0.01165008544921875, 0.0167236328125, -0.0162811279296875, 0.04931640625, 0.007610321044921875, -0.0309295654296875, 0.00687408447265625, 0.0628662109375, 0.059722900390625, 0.01000213623046875, -0.030120849609375, 0.0002849102020263672, -0.0295867919921875, 0.0252532958984375, 0.025787353515625, -0.037200927734375, 0.026824951171875, 0.0352783203125, 0.004520416259765625, 0.034454345703125, -0.01393890380859375, -0.0163116455078125, -0.040130615234375, -0.014434814453125, -0.058502197265625, -0.0238189697265625, -0.01593017578125, -0.0028362274169921875, -0.06231689453125, 0.0341796875, -0.119873046875, -0.031829833984375, -0.0004622936248779297, -0.008209228515625, -0.004383087158203125, -0.0161285400390625, -0.01197052001953125, -0.0159759521484375, 0.0400390625, -0.06640625, 0.2117919921875, 0.00516510009765625, -0.0295257568359375, -0.0030155181884765625, 0.05279541015625, -0.02105712890625, 0.0162811279296875, -0.0259246826171875, 0.00909423828125, -0.0221405029296875, -0.041168212890625, -0.00785064697265625, 0.0304107666015625, -0.0170745849609375, -0.00533294677734375, 0.006000518798828125, -0.012908935546875, -0.019683837890625, 0.09942626953125, -0.037139892578125, -0.01751708984375, -0.0132904052734375, -0.03131103515625, 0.058441162109375, -0.006633758544921875, -0.00907135009765625, 0.010986328125, 0.01678466796875, -0.042938232421875, -0.0198822021484375, 0.01207733154296875, 0.0127105712890625, -0.00962066650390625, 0.05523681640625, 0.032135009765625, -0.06878662109375, -0.0129852294921875, 0.006946563720703125, 0.005214691162109375, -0.011627197265625, -0.030487060546875, 0.00959014892578125, 0.0345458984375, 0.01036834716796875, 0.0787353515625, -0.034698486328125, 0.01224517822265625, 0.013641357421875, 0.00670623779296875, -0.049591064453125, 0.03021240234375, -0.036102294921875, -0.015533447265625, 0.0168609619140625, -0.03997802734375, -0.0011053085327148438, -0.033294677734375, 0.010498046875, -0.015350341796875, -0.0293731689453125, 0.037017822265625, 0.009033203125, -0.00592041015625, -0.01136016845703125, -0.00033855438232421875, -0.032257080078125, -0.0570068359375, -0.0136566162109375, 0.0110321044921875, 0.0197296142578125, -0.010711669921875, -0.034759521484375, -0.0107574462890625, -0.018890380859375, 0.016876220703125, 0.0457763671875, -0.04736328125, 0.0129852294921875, -0.01666259765625, -0.0084686279296875, 0.0113372802734375, -0.04559326171875, -0.043853759765625, -0.0188446044921875, 0.0124053955078125, 0.041534423828125, -0.058441162109375, 0.012451171875, 0.00901031494140625, -0.01459503173828125, 0.007205963134765625, 0.00039696693420410156, -0.003376007080078125, 0.0122528076171875, 0.0005612373352050781, 0.003475189208984375, 0.01727294921875, -0.00743865966796875, -0.030792236328125, 0.021484375, -0.0159759521484375, -0.02252197265625, -0.01556396484375, -0.028228759765625, 0.032257080078125, 0.0212860107421875, -0.027374267578125, 0.037139892578125, 0.0166473388671875, -0.00951385498046875, -0.0129547119140625, 0.02703857421875, -0.03680419921875, 0.0055084228515625, 0.03167724609375, 0.050628662109375, 0.02880859375, 0.006076812744140625, 0.0125274658203125, -0.01111602783203125, 0.0060577392578125, -0.001255035400390625, -0.04693603515625, -0.0697021484375, -0.01556396484375, -0.0026950836181640625, -0.043975830078125, 0.0225830078125, 0.01739501953125, 0.0150146484375, -0.0015726089477539062, 0.0016908645629882812, -0.022918701171875, 0.018829345703125, -0.004718780517578125, 0.0218963623046875, -0.0178985595703125, 0.043792724609375, -0.043731689453125, -0.034027099609375, 0.0159149169921875, -0.018585205078125, 0.0240020751953125, -0.005428314208984375, -0.023651123046875, -0.00670623779296875, 0.085693359375, -0.0191497802734375, -0.057464599609375, 0.017059326171875, -0.0182647705078125, 0.010986328125, -0.00583648681640625, 0.01186370849609375, 0.01163482666015625, 0.016845703125, -0.0235748291015625, -0.048187255859375, -0.0066375732421875, -0.03216552734375, -0.006824493408203125, -0.0113372802734375, 0.004787445068359375, 0.034454345703125, 0.00208282470703125, 0.0274810791015625, -0.051422119140625, 0.058197021484375, 0.088623046875, -0.01122283935546875, 0.057861328125, 0.0161285400390625, -0.0286102294921875, 0.016937255859375, -0.0171661376953125, -0.00806427001953125, -0.043304443359375, -0.025177001953125, -0.033935546875, -0.002498626708984375, 0.0305023193359375, -0.036224365234375, 0.05426025390625, 0.0067138671875, 0.039581298828125, 0.0243377685546875, 0.0116729736328125, -0.0168609619140625, 0.0704345703125, -0.032958984375, -0.06134033203125, 0.088623046875, -0.0152587890625, -0.01654052734375, -0.0003485679626464844, -0.01108551025390625, 0.00321197509765625, -0.01195526123046875, -0.0031528472900390625, 0.0011920928955078125, 0.052978515625, 0.0411376953125, 0.006378173828125, -0.00896453857421875, -0.03424072265625, -0.02423095703125, -0.01445770263671875, -0.06439208984375, -0.0443115234375, -0.0162506103515625, -0.054046630859375, -0.0168609619140625, -0.00290679931640625, -0.0203704833984375, 0.0386962890625, 0.0638427734375, -0.04736328125, -0.03253173828125, -0.065673828125, -0.052337646484375, 0.0032520294189453125, 0.0292205810546875, 0.02166748046875, -0.04510498046875, -0.00640869140625, -0.0186767578125, -0.045684814453125, -0.06915283203125, 0.006015777587890625, -0.0246124267578125, 0.0130157470703125, -0.01029205322265625, 0.003520965576171875, 0.0189361572265625, -0.0258636474609375, 0.0229949951171875, 0.0009469985961914062, 0.0162506103515625, 0.01271820068359375, 0.005390167236328125, 0.048431396484375, 0.0117645263671875, 0.02227783203125, 0.0272064208984375, -0.01422882080078125, -0.0032958984375, 0.031494140625, 0.0253448486328125, 0.01139068603515625, 0.0241241455078125, -0.01094818115234375, 0.0450439453125, 0.0145111083984375, 0.00888824462890625, -0.0174560546875, 0.0028228759765625, -0.0238189697265625, 0.031158447265625, -0.083251953125, 0.0014934539794921875, -0.00504302978515625, -0.031890869140625, -0.00800323486328125, -0.0283660888671875, -0.0024318695068359375, 0.004360198974609375, 0.03277587890625, 0.048492431640625, -0.038116455078125, -0.022216796875, 0.025146484375, -0.001373291015625, -0.00917816162109375, -0.038818359375, 0.03277587890625, -0.0036220550537109375, -0.035614013671875, -0.0296173095703125, -0.00806427001953125, 0.01326751708984375, -0.024810791015625, 0.006000518798828125, 0.01568603515625, -0.025238037109375, -0.01239776611328125, 0.0650634765625, 0.0160369873046875, -0.0026702880859375, -0.0021076202392578125, -0.033843994140625, -0.0211334228515625, 0.0190582275390625, -0.061004638671875, 0.0423583984375, -0.005519866943359375, 0.004917144775390625, -0.0157928466796875, 0.021575927734375, -0.0291595458984375, -0.0010890960693359375, -0.035125732421875, -0.01224517822265625, -0.05853271484375, -0.006130218505859375, -0.04669189453125, -0.05084228515625, -0.004688262939453125, 0.01300048828125, 0.059478759765625, 0.01007843017578125, -0.0007510185241699219, -0.042724609375, -0.0176544189453125, -0.0306549072265625, -0.017242431640625, -0.0146942138671875, -0.038238525390625, -0.011199951171875, -0.0200958251953125, -0.0100555419921875, -0.0213775634765625, -0.007045745849609375, 0.0109405517578125, -0.006458282470703125, -0.0106658935546875, -0.0292205810546875, 0.0009260177612304688, 0.016021728515625, -0.0555419921875, -0.031982421875, -0.0143585205078125, 0.002285003662109375, -0.0165863037109375, 0.051727294921875, 0.022216796875, 0.056549072265625, -0.025543212890625, -0.032928466796875, 0.049530029296875, 0.01354217529296875, -0.021148681640625, 0.016021728515625, 0.024871826171875, 0.0032100677490234375, 0.0484619140625, -0.0239410400390625, -0.0004639625549316406, -0.033935546875, 0.0230255126953125, 0.00748443603515625, 0.04473876953125, 0.043548583984375, -0.0124664306640625, -0.028045654296875, 0.031768798828125, 0.0045013427734375, 0.0284576416015625, 0.01454925537109375, 0.0350341796875, -0.050933837890625, 0.017547607421875, 0.0149993896484375, 0.00556182861328125, -0.0015649795532226562, -0.066162109375, 0.01263427734375, -0.00522613525390625, 0.00952911376953125, 0.005680084228515625, -0.0341796875, -0.01274871826171875, 0.0164794921875, 0.019134521484375, -0.014678955078125, -0.059326171875, 0.018585205078125, -0.013153076171875, -0.007389068603515625, 0.00897216796875, -0.05035400390625, 0.00775909423828125, -0.021942138671875, -0.08111572265625, -0.038116455078125, 0.00859832763671875, -0.00330352783203125, 0.025634765625, -0.00724029541015625, 0.034637451171875, 0.0231475830078125, -0.006244659423828125, 0.019744873046875, -0.03900146484375, -0.0016908645629882812, -0.12164306640625, -0.02203369140625, 0.0008058547973632812, 0.01271820068359375, -0.0181427001953125, -0.0150299072265625, 0.037506103515625, 0.025421142578125, 0.00644683837890625, -0.0164947509765625, -0.01268768310546875, 0.036590576171875, -0.012481689453125, -0.0098724365234375, 0.0182647705078125, 0.072509765625, -0.0007724761962890625, -0.0171051025390625, -0.006805419921875, -0.0130462646484375, -0.01178741455078125, 0.0024356842041015625, 0.01155853271484375, 0.0225372314453125, 0.0306243896484375, 0.041290283203125, -0.0165252685546875, 0.053375244140625, -0.0186614990234375, -0.040496826171875, 0.06085205078125, -0.0181427001953125, 0.0235748291015625, 0.019927978515625, -0.0272979736328125, 0.03302001953125, -0.037933349609375, 0.0135040283203125, -0.005588531494140625, -0.0361328125, -0.010650634765625, 0.01078033447265625, -0.0248565673828125, -0.0020236968994140625, 0.0253753662109375, -0.018096923828125, -0.02630615234375, -0.026641845703125, -0.020751953125, 0.06500244140625, 0.0240936279296875, 0.034027099609375, 0.03985595703125, 0.045013427734375, -0.00800323486328125, 0.04412841796875, -0.0304107666015625, 0.00412750244140625, 0.0310516357421875, -0.034637451171875, -0.0019474029541015625, 0.03411865234375, 0.00548553466796875, -0.033203125, 0.013641357421875, -0.0104522705078125, -0.05499267578125, -0.0096282958984375, 0.0126190185546875, -0.0167388916015625, -0.0290679931640625, 0.059661865234375, 0.00437164306640625, -0.031890869140625, 0.027313232421875, 0.020355224609375, 0.004337310791015625, 0.0111541748046875, -0.001529693603515625, 0.003047943115234375, 0.0208587646484375, 0.0093536376953125, -0.0218353271484375, -0.036651611328125, 0.026153564453125, -0.00362396240234375, -0.002155303955078125, 0.02398681640625, -0.0138092041015625, -0.0168304443359375, 0.0523681640625, -0.00553131103515625, 0.00249481201171875, -0.090087890625, -0.0207061767578125, -0.0302276611328125, -0.0107879638671875, 0.0095062255859375, -0.0182342529296875, -0.00928497314453125, 0.0057525634765625, 0.0274810791015625, -0.0006041526794433594, 0.006389617919921875, -0.0161285400390625, -0.035186767578125, 0.048828125, 0.008087158203125, -0.0234222412109375, 0.042816162109375, -0.0576171875, -0.0252227783203125, -0.01324462890625, -0.005157470703125, -0.0077972412109375, 0.00164794921875, 0.0247955322265625, -0.0251617431640625, 0.0159759521484375, 0.025115966796875, 0.038970947265625, 0.0193634033203125, -0.0226287841796875, -0.005695343017578125, 0.032806396484375, 0.0318603515625, 0.005767822265625, 0.0027332305908203125, 0.027496337890625, 0.0411376953125, -0.00972747802734375, -0.0218658447265625, -0.038421630859375, 0.00586700439453125, 0.005115509033203125, 0.024566650390625, 0.01074981689453125, 0.04132080078125, -0.001422882080078125, -0.039215087890625, 0.045684814453125, 0.0190582275390625, 0.0213775634765625, 0.037200927734375, -0.014556884765625, -0.0169677734375, 0.0361328125, -0.0211181640625, -0.0341796875, -0.005794525146484375, 0.021881103515625, 0.04443359375, -0.0283203125, 0.0170745849609375, 0.00881195068359375, -0.056854248046875, -0.0241851806640625, -0.057464599609375, -0.0175628662109375, 0.0335693359375, 0.035186767578125, -0.0760498046875, -0.025115966796875, -0.0157012939453125, -0.01418304443359375, 0.00821685791015625, -5.346536636352539e-05, -0.01525115966796875, -0.005855560302734375, 0.01458740234375, 0.01471710205078125, 0.009368896484375, -0.035491943359375, 0.0260009765625, 0.031280517578125, -0.0003612041473388672, 0.0177459716796875, 0.0193634033203125, 0.0792236328125, -0.0229949951171875, 0.060028076171875, 0.01541900634765625, 0.0288238525390625, -0.005367279052734375, -0.0021152496337890625, -0.0199737548828125, -0.050262451171875, -0.0220489501953125, 0.00998687744140625, 0.025604248046875, 0.00614166259765625, 0.01995849609375, 0.01312255859375, -0.04510498046875, 0.06732177734375, 0.006984710693359375, 0.0075531005859375, 0.0576171875, 0.0071258544921875, 0.016357421875, -0.01544189453125, 0.0048980712890625, 0.0029087066650390625, -0.048919677734375, 0.00797271728515625, -0.001003265380859375, 0.01523590087890625, -0.0285186767578125, -0.02593994140625, -0.0165863037109375, -0.03106689453125, -0.006900787353515625, -0.003116607666015625, 0.0704345703125, -0.0050506591796875, -0.001354217529296875, 0.00685882568359375, 0.0308380126953125, 0.0011148452758789062, -0.07025146484375, 0.00814056396484375, 0.00981903076171875, 0.0213623046875, 0.0177001953125, 0.054473876953125, -0.03338623046875, -0.00943756103515625, -0.01526641845703125, 0.0084991455078125, -0.01535797119140625, -0.0051422119140625, -0.0173187255859375, -0.039276123046875, 0.058319091796875, -0.00972747802734375, 0.0155487060546875, 0.0178375244140625, 0.01192474365234375, 0.044219970703125, -0.0203857421875, 0.0103759765625, -0.0182342529296875, -0.0008640289306640625, -0.005428314208984375], [0.00771331787109375, 0.01000213623046875, -0.04278564453125, -0.050262451171875, 0.00998687744140625, 0.0013494491577148438, 0.01245880126953125, -0.0185394287109375, 0.01195526123046875, -0.0302886962890625, -0.01511383056640625, 0.06768798828125, -0.0260009765625, 0.0086517333984375, 0.027313232421875, -0.01329803466796875, -0.00011336803436279297, 0.0050811767578125, 0.028656005859375, -0.0037746429443359375, 0.0027904510498046875, -0.0347900390625, -0.03448486328125, 0.024505615234375, 0.00124359130859375, -0.01197052001953125, 0.015594482421875, 0.0015659332275390625, -0.031158447265625, -0.0635986328125, 0.021697998046875, -0.0283050537109375, 0.0166015625, -0.020751953125, -0.006946563720703125, -0.01806640625, 0.0223541259765625, -0.02386474609375, -0.052825927734375, -0.00640106201171875, -0.00830841064453125, 0.0150299072265625, 0.006641387939453125, -0.042999267578125, -0.0016164779663085938, -0.082275390625, -0.02728271484375, -0.058380126953125, -0.0016679763793945312, 0.0256195068359375, 0.031829833984375, 0.0101165771484375, 0.041229248046875, -0.0194091796875, 0.03619384765625, -0.0095977783203125, 0.0141143798828125, 0.06011962890625, -0.059814453125, 0.006267547607421875, -0.044464111328125, -0.005771636962890625, -0.0161895751953125, -0.02264404296875, 0.0472412109375, 0.028228759765625, -0.0209808349609375, 0.0114898681640625, -0.00047588348388671875, -0.00928497314453125, -0.04083251953125, 7.11679458618164e-05, -0.053497314453125, 0.01558685302734375, -0.0467529296875, 0.01131439208984375, -0.009368896484375, -4.100799560546875e-05, -0.0236663818359375, -0.01416778564453125, 0.09259033203125, 0.043060302734375, 0.005756378173828125, -0.01812744140625, -0.0014142990112304688, 0.04510498046875, -0.00246429443359375, -0.005443572998046875, 0.01177215576171875, -0.07586669921875, -0.0232086181640625, 0.01430511474609375, -0.01248931884765625, -0.03497314453125, -0.018707275390625, 0.01180267333984375, -0.08746337890625, 0.0675048828125, -0.0117645263671875, -0.0274200439453125, -0.047210693359375, 0.040313720703125, -0.0183868408203125, -0.0128936767578125, 0.0312347412109375, 0.0306854248046875, 0.06304931640625, -0.01352691650390625, 0.018096923828125, 0.0084228515625, 0.0041046142578125, 0.0273284912109375, 0.0167999267578125, -0.05474853515625, -0.03875732421875, -0.041259765625, -0.035888671875, -0.055755615234375, 0.009185791015625, -0.01224517822265625, 0.020751953125, 0.00586700439453125, 0.03936767578125, -0.042724609375, -0.0478515625, 0.039947509765625, 0.019500732421875, 0.038818359375, -0.04754638671875, 0.0184326171875, -0.0238800048828125, -0.01324462890625, -0.0258636474609375, 0.0113677978515625, -0.0189666748046875, -0.01454925537109375, 0.03057861328125, 0.0151519775390625, -0.0195770263671875, -0.024078369140625, 0.012115478515625, 0.024658203125, 0.002124786376953125, -0.02691650390625, -0.004245758056640625, -0.0181427001953125, 0.0028324127197265625, -0.07391357421875, -0.01406097412109375, 0.004024505615234375, 0.0307464599609375, -0.0134429931640625, 0.049530029296875, -0.01453399658203125, -0.0278167724609375, -0.0173187255859375, -0.01410675048828125, 0.029815673828125, 0.035247802734375, 0.0140533447265625, 0.08160400390625, 0.030120849609375, -0.020477294921875, -0.07635498046875, 0.01422882080078125, 0.035308837890625, -0.040771484375, 0.0455322265625, 0.0011281967163085938, 0.00604248046875, 0.0279388427734375, -0.0394287109375, -0.0019178390502929688, -0.0168609619140625, -0.001873016357421875, -0.0032863616943359375, 0.050933837890625, 0.0042572021484375, -0.01023101806640625, -0.0041046142578125, 0.006137847900390625, 0.039093017578125, -0.01448822021484375, -0.051239013671875, -0.027099609375, -0.02716064453125, 0.010009765625, 0.0281982421875, 0.022430419921875, 0.0174560546875, -0.015594482421875, 0.01021575927734375, 0.02899169921875, 0.01092529296875, -0.005489349365234375, 0.0338134765625, -0.005710601806640625, -0.0911865234375, -0.0140533447265625, 0.007476806640625, 0.0008106231689453125, 0.0022373199462890625, 0.007709503173828125, 0.0180511474609375, -0.0435791015625, -0.0158538818359375, -0.10662841796875, -0.03192138671875, 0.0151519775390625, -0.015716552734375, -0.061187744140625, 0.01776123046875, 0.05029296875, 0.07958984375, -0.00403594970703125, -0.0286712646484375, 0.015350341796875, -0.0020599365234375, 0.0158233642578125, 0.00399017333984375, 0.003627777099609375, -0.014373779296875, -0.0036563873291015625, -0.00319671630859375, -0.007648468017578125, 0.0223236083984375, -0.0057830810546875, -0.041900634765625, -0.02752685546875, -0.026092529296875, -0.01325225830078125, -0.010467529296875, 0.003665924072265625, 0.0165252685546875, 0.032867431640625, -0.02435302734375, -0.006927490234375, 0.030303955078125, 0.01385498046875, -0.02313232421875, -0.04193115234375, 0.0377197265625, -0.0438232421875, -0.057891845703125, -0.016021728515625, -0.0159149169921875, 0.033782958984375, -0.05450439453125, -0.0027523040771484375, -0.0015506744384765625, 0.0304718017578125, -0.02447509765625, 0.0211181640625, 0.02081298828125, 0.034912109375, 0.02801513671875, 0.0142059326171875, -0.0171356201171875, 0.035003662109375, 0.0030841827392578125, -0.0035953521728515625, -0.005039215087890625, -0.00353240966796875, 0.04949951171875, 0.00618743896484375, -0.00870513916015625, -0.002960205078125, 0.046905517578125, 0.01202392578125, -0.006412506103515625, -0.05029296875, -0.0081024169921875, -0.028594970703125, 0.015655517578125, -0.0228271484375, 0.0121307373046875, -0.023468017578125, -0.0079193115234375, 0.0263671875, -0.014190673828125, 0.0167999267578125, -0.0016412734985351562, -0.0004382133483886719, -0.02691650390625, 0.023681640625, -0.0250701904296875, -0.0303955078125, -0.054840087890625, -0.0016727447509765625, -0.0274658203125, -0.0184478759765625, -0.0104522705078125, 0.04248046875, 0.024749755859375, -0.03533935546875, -0.04681396484375, -0.05596923828125, -0.157470703125, -0.0276641845703125, 0.003192901611328125, 0.04840087890625, 0.0203399658203125, -0.0149078369140625, 0.0266876220703125, -0.0177764892578125, -0.01371002197265625, -0.00868988037109375, -0.054412841796875, -0.038482666015625, 0.0155487060546875, 0.004375457763671875, -0.007793426513671875, -0.00435638427734375, 0.01525115966796875, 0.01227569580078125, 0.0296478271484375, -0.00011074542999267578, 0.049530029296875, -0.029541015625, 0.03607177734375, -0.035003662109375, 0.02056884765625, -0.04327392578125, 0.02947998046875, 0.029876708984375, -0.0232696533203125, -0.0511474609375, 0.012451171875, -0.011932373046875, -0.01084136962890625, 0.0321044921875, 0.0215911865234375, 0.0012712478637695312, -0.0302734375, -0.01971435546875, 0.0213470458984375, 0.0103302001953125, 0.0033054351806640625, 0.0176544189453125, -0.01024627685546875, 0.007015228271484375, -0.0193328857421875, -0.050323486328125, -0.00948333740234375, -0.01788330078125, 0.00394439697265625, 0.0096282958984375, -0.07135009765625, 0.0054168701171875, -0.025787353515625, -0.01971435546875, -0.0152587890625, 0.0263214111328125, -0.00574493408203125, 0.032470703125, -0.005115509033203125, 0.00977325439453125, -0.021148681640625, 0.0014219284057617188, 0.01096343994140625, 0.0306243896484375, 0.0025577545166015625, -0.0300445556640625, -0.00799560546875, -0.0079803466796875, 0.01132965087890625, -0.0036773681640625, 0.002010345458984375, 0.0171356201171875, -0.01080322265625, -0.019744873046875, 0.01036834716796875, 0.007045745849609375, 0.028289794921875, 0.001064300537109375, 0.0386962890625, -0.12017822265625, -0.0005102157592773438, 0.035888671875, -0.021942138671875, 0.03582763671875, -0.028900146484375, 0.01467132568359375, -0.021453857421875, 0.0011014938354492188, -0.02435302734375, 0.2071533203125, 0.01568603515625, 0.036895751953125, -0.005054473876953125, 0.01531219482421875, -0.0033111572265625, -0.0041046142578125, -0.038055419921875, 0.004215240478515625, -0.00018155574798583984, -0.06982421875, -0.0158538818359375, 0.0146331787109375, -0.0158843994140625, 0.0291900634765625, 0.008087158203125, -0.013946533203125, 0.00875091552734375, -0.0073089599609375, 0.00812530517578125, -0.01140594482421875, 0.028045654296875, 0.022308349609375, 0.01125335693359375, -0.01812744140625, -0.037933349609375, 0.0177764892578125, 0.063232421875, -0.036346435546875, 0.00814056396484375, -0.00936126708984375, -0.01093292236328125, 0.0012903213500976562, -0.032257080078125, 0.036407470703125, -0.03289794921875, 0.005786895751953125, -0.0217132568359375, -0.03057861328125, 0.0028285980224609375, 0.0207977294921875, -0.0401611328125, -0.00759124755859375, 0.0279541015625, 0.03936767578125, -0.00542449951171875, 0.038482666015625, -0.029754638671875, -0.02215576171875, -0.046600341796875, 0.07623291015625, 0.006763458251953125, -0.0231475830078125, 0.0110931396484375, -0.0173187255859375, 0.0277099609375, -0.0167236328125, -0.019744873046875, 0.0003802776336669922, -0.01456451416015625, -0.0007686614990234375, 0.01190185546875, -0.00713348388671875, -0.0316162109375, 0.0269012451171875, -0.046783447265625, 0.0032444000244140625, -0.01306915283203125, -0.027618408203125, -0.02886962890625, 0.035064697265625, -0.03143310546875, -0.0249176025390625, -0.0552978515625, 0.037628173828125, -0.01123809814453125, -0.04486083984375, 0.02105712890625, 0.0088043212890625, -0.026123046875, 0.0240478515625, -0.0093231201171875, -0.04888916015625, -0.06207275390625, -0.0003979206085205078, 0.0391845703125, -0.006549835205078125, 0.008148193359375, -0.01551055908203125, -0.03741455078125, 0.033538818359375, 0.029327392578125, -0.0267486572265625, -0.01080322265625, 0.04034423828125, 0.00746917724609375, 0.00945281982421875, 0.047698974609375, -0.0157470703125, 0.006504058837890625, 0.0255279541015625, -0.01080322265625, 0.007537841796875, 0.01294708251953125, -0.0179901123046875, -0.0633544921875, 0.02203369140625, 0.046905517578125, 0.000728607177734375, -0.05419921875, -0.032501220703125, 0.00849151611328125, 0.022979736328125, 0.0017709732055664062, -0.01248931884765625, 0.025360107421875, 0.0196990966796875, -0.01268768310546875, -0.017486572265625, 0.0357666015625, -0.042572021484375, -0.0322265625, 0.0110931396484375, 0.0027904510498046875, -0.006683349609375, 0.001857757568359375, -0.0102386474609375, 0.04388427734375, -0.03338623046875, -0.0021533966064453125, -0.00339508056640625, 0.01425933837890625, 0.05157470703125, 0.04241943359375, 0.0155792236328125, -0.003940582275390625, 0.01043701171875, -0.0073699951171875, -0.0277862548828125, 0.033447265625, 0.014190673828125, -0.046295166015625, 0.01216888427734375, 0.00786590576171875, 0.0185699462890625, 0.083251953125, 0.04864501953125, -0.01953125, -0.0087127685546875, 0.0294189453125, -0.0222625732421875, -0.01088714599609375, 0.01361083984375, -0.069091796875, -0.019134521484375, 0.00484466552734375, -0.0222625732421875, -0.05950927734375, 0.060455322265625, -0.026763916015625, 0.017242431640625, 0.0168914794921875, -0.000568389892578125, 0.05670166015625, 0.006038665771484375, 0.06231689453125, -0.05633544921875, -0.0222625732421875, 0.024993896484375, -0.01152801513671875, 0.061676025390625, -0.047393798828125, -0.0033359527587890625, 0.0101165771484375, 0.037689208984375, 0.04071044921875, -0.01149749755859375, -0.01352691650390625, 0.0177459716796875, -0.00745391845703125, -0.002544403076171875, 0.025177001953125, 0.05340576171875, 0.03778076171875, -0.0265045166015625, 0.042236328125, -0.05096435546875, -0.007343292236328125, -0.0222625732421875, -0.01177978515625, -0.0200653076171875, 0.031829833984375, -0.0208587646484375, 0.01934814453125, 0.05010986328125, -0.02587890625, -0.046173095703125, 0.0165557861328125, 0.0198211669921875, -0.016204833984375, -0.01256561279296875, -0.0107269287109375, -0.01212310791015625, 0.007251739501953125, 0.007297515869140625, 0.004241943359375, -0.0099639892578125, 0.0036468505859375, -0.020111083984375, 0.00024819374084472656, 0.00852203369140625, 0.0024890899658203125, 0.047332763671875, -0.0216064453125, 0.0438232421875, -0.0057373046875, -0.0616455078125, 0.0191802978515625, -0.00545501708984375, -0.033172607421875, 0.0002777576446533203, 0.054656982421875, 0.01934814453125, -0.01361846923828125, 0.017608642578125, -0.003032684326171875, 0.00672149658203125, -0.0164642333984375, 0.00978851318359375, -0.0260772705078125, 0.006771087646484375, 0.046234130859375, 0.004673004150390625, -0.023284912109375, 0.017242431640625, -0.0017919540405273438, 0.034637451171875, -0.00690460205078125, 0.07769775390625, -0.03936767578125, -0.00616455078125, 0.022979736328125, 0.00228118896484375, 0.037811279296875, -0.0237884521484375, 0.050018310546875, -0.00417327880859375, 0.01512908935546875, -0.023162841796875, 0.07403564453125, 0.0271759033203125, 0.014404296875, 0.0199737548828125, 0.02105712890625, -0.066162109375, 0.053192138671875, -0.001476287841796875, 0.0223846435546875, 0.01056671142578125, 0.059478759765625, 0.00229644775390625, 0.027862548828125, -0.0377197265625, 0.0130157470703125, -0.0286865234375, -0.01468658447265625, 0.0281982421875, -0.038421630859375, -0.037384033203125, 0.0015954971313476562, 0.01107025146484375, -0.009063720703125, -0.08074951171875, -0.0037364959716796875, -0.007244110107421875, 0.01462554931640625, 0.0225677490234375, -0.007175445556640625, -0.00858306884765625, 0.01293182373046875, -0.0081634521484375, 0.0498046875, -0.0007128715515136719, 0.0709228515625, -0.0296630859375, 0.035797119140625, -0.0142669677734375, 0.0087432861328125, 0.046295166015625, -0.0156097412109375, 0.006450653076171875, -0.024017333984375, -0.030609130859375, 0.06646728515625, 0.037811279296875, 0.0140533447265625, -0.035888671875, 0.086181640625, -0.024505615234375, -0.0174560546875, -0.018829345703125, -0.006313323974609375, -0.035888671875, 0.00980377197265625, -0.0271453857421875, -0.01021575927734375, 0.01454925537109375, 0.02099609375, -0.0215606689453125, -0.038604736328125, 0.005340576171875, -0.00595855712890625, 0.02484130859375, -0.036712646484375, -0.00502777099609375, -0.012603759765625, -0.03369140625, 0.014373779296875, 0.007793426513671875, 0.08685302734375, 0.0377197265625, -0.011199951171875, 0.0330810546875, -0.0265960693359375, 0.031341552734375, -0.012176513671875, -0.00035858154296875, -0.004093170166015625, -0.023834228515625, -0.0266876220703125, -0.039825439453125, 0.023834228515625, -0.0177459716796875, -0.041900634765625, -0.018707275390625, -0.00470733642578125, -0.0166015625, -0.0072021484375, 0.038543701171875, -0.0241851806640625, -0.0182952880859375, -0.044403076171875, 0.0250396728515625, -0.0013952255249023438, 0.00150299072265625, -0.01393890380859375, 0.01342010498046875, -0.0015926361083984375, -0.0347900390625, -0.01175689697265625, 0.010955810546875, 0.0233001708984375, 0.00992584228515625, -0.0684814453125, -0.0004000663757324219, 0.0219573974609375, -0.12030029296875, -0.051239013671875, 0.0050048828125, 0.01141357421875, -0.0055694580078125, -0.01256561279296875, 0.0247344970703125, 0.045318603515625, -0.0287322998046875, 0.061981201171875, 0.0352783203125, 0.0296173095703125, -0.07476806640625, -0.00646209716796875, 0.014312744140625, 0.0039825439453125, 0.0018930435180664062, 0.01194000244140625, 0.014862060546875, 0.046722412109375, 0.004405975341796875, -0.026123046875, 0.020660400390625, -0.0188751220703125, -0.032501220703125, -0.054901123046875, -0.02313232421875, -0.02215576171875, 3.510713577270508e-05, -0.0030040740966796875, -0.030181884765625, -0.01221466064453125, 0.059173583984375, 0.0013456344604492188, -0.0069732666015625, -0.004764556884765625, -0.0213775634765625, -0.0147552490234375, -0.0966796875, -0.0007205009460449219, 0.037628173828125, -0.050079345703125, -0.0227203369140625, -0.0164031982421875, 0.0005640983581542969, -0.0287322998046875, 0.011383056640625, -0.0218505859375, -0.0006556510925292969, 0.021209716796875, -0.01377105712890625, -0.0022029876708984375, -0.044677734375, 0.0303955078125, 0.009033203125, -0.00415802001953125, -0.0223388671875, 0.051544189453125, -0.0261383056640625, 0.0122222900390625, 0.039154052734375, 0.01873779296875, 0.072265625, -0.048980712890625, 0.030426025390625, -0.00548553466796875, -0.0294036865234375, -0.06170654296875, 0.0200042724609375, 0.0426025390625, 0.032440185546875, 0.02056884765625, -0.0027484893798828125, -0.0223388671875, 0.00391387939453125, 0.0044708251953125, 0.0086517333984375, -0.01174163818359375, 0.06549072265625, 0.03692626953125, -0.01922607421875, -0.049285888671875, 0.031494140625, -0.047088623046875, 0.0275726318359375, 0.0057220458984375, -0.0215301513671875, 0.0216217041015625, 0.0318603515625, -0.03533935546875, 0.041290283203125, 0.0168914794921875, -0.020172119140625, 0.00160980224609375, -0.006927490234375, 0.0309600830078125, -0.0260467529296875, 0.032318115234375, 0.030059814453125, 0.058349609375, -0.0247955322265625, -0.0423583984375, -0.029022216796875, -0.0022411346435546875, -0.0041351318359375, 0.0096435546875, 0.00649261474609375, -0.045623779296875, -0.0237884521484375, 0.0007915496826171875, 0.016143798828125, -0.045806884765625, 0.0259246826171875, 0.0164794921875, 0.0150146484375, -0.01004791259765625, -0.04803466796875, 0.02264404296875, 0.0174102783203125, 0.03729248046875, -0.06414794921875, -0.002910614013671875, -0.027618408203125, 0.00246429443359375, -0.0221405029296875, 0.02288818359375, 0.0018711090087890625, -0.0139007568359375, -0.10052490234375, 0.0102386474609375, -0.034912109375, 0.005687713623046875, -0.01031494140625, 0.00960540771484375, -8.940696716308594e-07, 0.04852294921875, 0.009735107421875, -0.0406494140625, 0.00926971435546875, 0.037139892578125, 0.0004677772521972656, -0.01314544677734375, -0.02667236328125, -0.060882568359375, 0.0175933837890625, -0.03741455078125, 0.056854248046875, 0.01293182373046875, 0.0430908203125, -0.018798828125, 0.03472900390625, 0.040496826171875, -0.03216552734375, 0.01776123046875, 0.008270263671875, -0.01271820068359375, 0.0084381103515625, -0.00919342041015625, 0.01239776611328125, 0.0261077880859375, 0.0260162353515625, -0.0207977294921875, -0.01251983642578125, -0.01288604736328125, -0.0017137527465820312, 0.022552490234375, 0.08380126953125, -0.0192413330078125, 0.0266876220703125, -0.054412841796875, 0.00975799560546875, 0.015838623046875, -0.031768798828125, 0.0166168212890625, 0.049285888671875, -0.00562286376953125, 0.0186004638671875, -0.065673828125, -0.0028228759765625, 0.0285186767578125, 0.047515869140625, 0.004425048828125, -0.0101318359375, -0.025177001953125, -0.004878997802734375, -0.01507568359375, -0.01116943359375, -0.03521728515625, 0.04608154296875, 0.006412506103515625, 0.0009984970092773438, 0.0238037109375, -0.0127410888671875, -0.0367431640625, -0.02288818359375, -0.00957489013671875, 0.06341552734375, 0.002895355224609375, 0.047760009765625, 0.02496337890625, -0.01169586181640625, -0.01136016845703125, 0.0118560791015625, -0.0276641845703125, -0.00348663330078125, 0.0164337158203125, 0.0158843994140625, 0.0242462158203125, 0.0008878707885742188, 0.0294952392578125, -0.04559326171875, -0.0021305084228515625, 0.006011962890625, -0.028411865234375, 0.0384521484375, 0.023040771484375, 0.0457763671875, 0.0084381103515625, 0.01715087890625, 0.0215301513671875, 0.027069091796875, -0.0019025802612304688, 0.013458251953125, 0.03436279296875, -0.058868408203125, 0.02154541015625, 0.019439697265625, 0.0020771026611328125, 0.026214599609375, -0.027069091796875, -0.0004987716674804688, -0.03460693359375, 0.04638671875, 0.0692138671875, 0.02532958984375, 0.02166748046875, -0.0290069580078125, -0.0016021728515625, -0.0190582275390625, 0.01175689697265625, -0.0207977294921875, 0.0174102783203125, 0.01087188720703125, -0.01142120361328125, 0.013580322265625, -0.004367828369140625, -0.042449951171875, 0.01194000244140625, 0.01241302490234375, -0.0208892822265625, -0.02386474609375, 0.0338134765625, -0.031036376953125, -0.0245208740234375, 0.06121826171875, 0.0528564453125, -0.011383056640625, -0.016448974609375, -0.00182342529296875, 0.00963592529296875, -0.046630859375, -0.045928955078125, -0.0052337646484375, -0.0288238525390625, 0.0221710205078125, 0.03466796875, -0.0021724700927734375, -0.01415252685546875, 0.027374267578125, -0.01491546630859375, -0.026580810546875, 0.0160675048828125, -0.0390625, 0.0083160400390625, 0.03192138671875, 0.009002685546875, 0.03033447265625, -0.043670654296875, -0.01377105712890625, -0.00251007080078125, 0.0482177734375, 0.048309326171875], [-0.05419921875, -0.0013103485107421875, -0.01013946533203125, -0.022430419921875, 0.0172119140625, -0.0226898193359375, 0.0038356781005859375, 0.0125579833984375, -0.00833892822265625, 0.0253448486328125, -0.00022530555725097656, 0.0218048095703125, -0.0323486328125, 0.004917144775390625, -0.0021572113037109375, 0.01457977294921875, 0.017669677734375, -0.006622314453125, 0.0311279296875, -0.0177001953125, -0.018951416015625, 0.01018524169921875, -0.0157928466796875, 0.06121826171875, 0.01354217529296875, 0.003276824951171875, 0.03704833984375, 0.02490234375, -0.004489898681640625, 0.03887939453125, -0.037384033203125, 0.0286102294921875, 0.01216888427734375, -0.01441192626953125, -0.01557159423828125, 0.0016412734985351562, -0.0261688232421875, -0.00994110107421875, -0.041839599609375, -0.04742431640625, -0.01178741455078125, 0.0119171142578125, 0.04388427734375, -0.07672119140625, 0.05804443359375, -0.0404052734375, -0.001071929931640625, -0.048065185546875, -0.0246429443359375, 0.007228851318359375, 0.0135955810546875, -0.027679443359375, 0.08380126953125, -0.03106689453125, 0.0283203125, 0.01293182373046875, 0.01568603515625, -0.01007843017578125, -0.060943603515625, 0.00894927978515625, -0.00811004638671875, -0.029449462890625, -0.03582763671875, 0.029937744140625, -0.005809783935546875, 0.0211334228515625, 0.0032806396484375, 0.0251617431640625, -0.00325775146484375, 0.004901885986328125, -0.007793426513671875, 0.01776123046875, 0.006076812744140625, -0.00408935546875, -0.04241943359375, -0.03656005859375, 0.07366943359375, 0.01123046875, -0.0182342529296875, 0.038177490234375, 0.058258056640625, 0.0208587646484375, -0.07470703125, 0.0014467239379882812, -0.01139068603515625, 0.06671142578125, 0.015350341796875, 0.014404296875, 0.0056915283203125, 0.02972412109375, -0.02117919921875, -0.004608154296875, -0.0247039794921875, -0.0227203369140625, -0.026458740234375, 0.011962890625, -0.0034618377685546875, 0.0046844482421875, 0.0059967041015625, 0.0218505859375, 0.0491943359375, -0.005344390869140625, 0.0305633544921875, -0.05633544921875, 0.006946563720703125, 0.01020050048828125, -0.0276641845703125, 0.01033782958984375, -0.03582763671875, 0.00738525390625, 0.0309600830078125, 0.05535888671875, -0.0216522216796875, 0.00861358642578125, -0.04986572265625, -0.0253753662109375, -0.0226898193359375, 0.0189361572265625, 0.043701171875, 0.0137176513671875, 0.03851318359375, -0.0083160400390625, 0.049957275390625, -0.03936767578125, -0.00598907470703125, -0.01465606689453125, -0.0272064208984375, 0.01080322265625, -0.0273284912109375, 0.031585693359375, -0.0439453125, 0.03973388671875, 0.00434112548828125, 0.0246429443359375, -0.0019168853759765625, -0.0021610260009765625, 0.01751708984375, -0.00925445556640625, -0.006633758544921875, -0.0127105712890625, 0.0081939697265625, -0.01227569580078125, -0.0026760101318359375, -0.0184783935546875, 0.00426483154296875, -0.052764892578125, 0.0023670196533203125, 0.0007147789001464844, 0.0201568603515625, -0.0310516357421875, 0.01004791259765625, -0.00720977783203125, 0.006778717041015625, 0.021484375, 0.004589080810546875, 0.01038360595703125, 0.0260009765625, -0.01161956787109375, -0.023101806640625, -0.023162841796875, 0.03692626953125, -0.0474853515625, -0.007137298583984375, -0.034423828125, 0.0323486328125, 0.004482269287109375, 0.0112152099609375, 0.01544189453125, -0.0029888153076171875, -0.05889892578125, 0.0031299591064453125, 0.0306243896484375, 0.04278564453125, -0.01556396484375, 0.0092926025390625, 0.007312774658203125, 0.066162109375, 0.0030803680419921875, 0.0258331298828125, -0.036102294921875, -0.022186279296875, -0.0017137527465820312, 0.00695037841796875, 0.01421356201171875, -0.01207733154296875, -0.0001977682113647461, -0.029296875, 0.04010009765625, 0.005489349365234375, 0.0513916015625, -0.023162841796875, -0.038360595703125, 0.00681304931640625, 0.042999267578125, 0.0293731689453125, 0.0284423828125, -0.0025653839111328125, -0.055633544921875, -0.015838623046875, -0.023895263671875, -0.0450439453125, 0.0256500244140625, 0.0149078369140625, -0.03863525390625, -0.016998291015625, -0.047271728515625, -0.05511474609375, -0.025421142578125, -0.007648468017578125, -0.01120758056640625, 0.06817626953125, 0.009613037109375, 0.027587890625, 0.014556884765625, -0.03118896484375, -0.0199737548828125, -0.014373779296875, -0.04693603515625, 0.039825439453125, -0.0343017578125, 0.03759765625, 0.004032135009765625, 0.00946044921875, -0.0036907196044921875, 0.0548095703125, 0.0177459716796875, -0.05224609375, 0.004108428955078125, 0.03192138671875, -0.0296173095703125, -0.0122528076171875, -0.0023651123046875, 0.05230712890625, 0.00455474853515625, 0.0772705078125, 0.023193359375, 0.0305328369140625, 0.01378631591796875, 0.0210113525390625, -0.0286407470703125, -0.03680419921875, -0.0247955322265625, 0.048614501953125, 0.007312774658203125, 0.0063323974609375, 0.006778717041015625, 0.0572509765625, -0.036407470703125, -0.0186004638671875, 0.01230621337890625, 0.02606201171875, 0.01239013671875, 0.00569915771484375, 0.03863525390625, 0.102783203125, 0.0078887939453125, 0.0027217864990234375, -0.01123046875, 0.00732421875, 0.07086181640625, -0.0316162109375, 0.061737060546875, -0.017669677734375, 0.05517578125, 0.053192138671875, 0.015350341796875, 0.01177978515625, 0.01959228515625, -0.02569580078125, -0.0088043212890625, -0.0153961181640625, 0.0198974609375, -0.05633544921875, -0.01169586181640625, -0.00493621826171875, -0.053985595703125, 0.032440185546875, 0.0230560302734375, 0.065673828125, -0.0288238525390625, 0.00774383544921875, 0.01253509521484375, 0.0007853507995605469, -0.01055908203125, -0.00727081298828125, 0.0208892822265625, -0.034393310546875, 0.0005087852478027344, -0.0182952880859375, -0.027557373046875, -0.015716552734375, -0.0648193359375, 0.0323486328125, -0.0012664794921875, -0.053253173828125, 0.00750732421875, -0.0204620361328125, -0.1290283203125, -0.0235595703125, 0.0195465087890625, 0.0221710205078125, 0.0258941650390625, -0.016204833984375, -0.08056640625, -0.01470184326171875, -0.053192138671875, -0.022552490234375, -0.0225067138671875, -0.057830810546875, -0.049591064453125, -0.03704833984375, -0.0026416778564453125, -0.048858642578125, 0.0167236328125, -0.0171966552734375, 0.0164337158203125, -0.0134735107421875, 0.00713348388671875, -0.0208892822265625, 0.01654052734375, 0.01073455810546875, 0.0797119140625, 0.0246124267578125, 0.01059722900390625, 0.043670654296875, -0.050933837890625, -0.034271240234375, -0.0111083984375, -0.0469970703125, -0.00643157958984375, 0.0194091796875, -0.00167083740234375, -0.0029010772705078125, 0.020721435546875, 0.01540374755859375, 0.00978851318359375, 0.005565643310546875, 0.001033782958984375, -0.006084442138671875, -0.04583740234375, 0.035491943359375, -0.01041412353515625, -0.00795745849609375, -0.0230560302734375, 0.00433349609375, -0.0626220703125, 0.01165008544921875, 0.0167236328125, -0.0162811279296875, 0.04931640625, 0.007610321044921875, -0.0309295654296875, 0.00687408447265625, 0.0628662109375, 0.059722900390625, 0.01000213623046875, -0.030120849609375, 0.0002849102020263672, -0.0295867919921875, 0.0252532958984375, 0.025787353515625, -0.037200927734375, 0.026824951171875, 0.0352783203125, 0.004520416259765625, 0.034454345703125, -0.01393890380859375, -0.0163116455078125, -0.040130615234375, -0.014434814453125, -0.058502197265625, -0.0238189697265625, -0.01593017578125, -0.0028362274169921875, -0.06231689453125, 0.0341796875, -0.119873046875, -0.031829833984375, -0.0004622936248779297, -0.008209228515625, -0.004383087158203125, -0.0161285400390625, -0.01197052001953125, -0.0159759521484375, 0.0400390625, -0.06640625, 0.2117919921875, 0.00516510009765625, -0.0295257568359375, -0.0030155181884765625, 0.05279541015625, -0.02105712890625, 0.0162811279296875, -0.0259246826171875, 0.00909423828125, -0.0221405029296875, -0.041168212890625, -0.00785064697265625, 0.0304107666015625, -0.0170745849609375, -0.00533294677734375, 0.006000518798828125, -0.012908935546875, -0.019683837890625, 0.09942626953125, -0.037139892578125, -0.01751708984375, -0.0132904052734375, -0.03131103515625, 0.058441162109375, -0.006633758544921875, -0.00907135009765625, 0.010986328125, 0.01678466796875, -0.042938232421875, -0.0198822021484375, 0.01207733154296875, 0.0127105712890625, -0.00962066650390625, 0.05523681640625, 0.032135009765625, -0.06878662109375, -0.0129852294921875, 0.006946563720703125, 0.005214691162109375, -0.011627197265625, -0.030487060546875, 0.00959014892578125, 0.0345458984375, 0.01036834716796875, 0.0787353515625, -0.034698486328125, 0.01224517822265625, 0.013641357421875, 0.00670623779296875, -0.049591064453125, 0.03021240234375, -0.036102294921875, -0.015533447265625, 0.0168609619140625, -0.03997802734375, -0.0011053085327148438, -0.033294677734375, 0.010498046875, -0.015350341796875, -0.0293731689453125, 0.037017822265625, 0.009033203125, -0.00592041015625, -0.01136016845703125, -0.00033855438232421875, -0.032257080078125, -0.0570068359375, -0.0136566162109375, 0.0110321044921875, 0.0197296142578125, -0.010711669921875, -0.034759521484375, -0.0107574462890625, -0.018890380859375, 0.016876220703125, 0.0457763671875, -0.04736328125, 0.0129852294921875, -0.01666259765625, -0.0084686279296875, 0.0113372802734375, -0.04559326171875, -0.043853759765625, -0.0188446044921875, 0.0124053955078125, 0.041534423828125, -0.058441162109375, 0.012451171875, 0.00901031494140625, -0.01459503173828125, 0.007205963134765625, 0.00039696693420410156, -0.003376007080078125, 0.0122528076171875, 0.0005612373352050781, 0.003475189208984375, 0.01727294921875, -0.00743865966796875, -0.030792236328125, 0.021484375, -0.0159759521484375, -0.02252197265625, -0.01556396484375, -0.028228759765625, 0.032257080078125, 0.0212860107421875, -0.027374267578125, 0.037139892578125, 0.0166473388671875, -0.00951385498046875, -0.0129547119140625, 0.02703857421875, -0.03680419921875, 0.0055084228515625, 0.03167724609375, 0.050628662109375, 0.02880859375, 0.006076812744140625, 0.0125274658203125, -0.01111602783203125, 0.0060577392578125, -0.001255035400390625, -0.04693603515625, -0.0697021484375, -0.01556396484375, -0.0026950836181640625, -0.043975830078125, 0.0225830078125, 0.01739501953125, 0.0150146484375, -0.0015726089477539062, 0.0016908645629882812, -0.022918701171875, 0.018829345703125, -0.004718780517578125, 0.0218963623046875, -0.0178985595703125, 0.043792724609375, -0.043731689453125, -0.034027099609375, 0.0159149169921875, -0.018585205078125, 0.0240020751953125, -0.005428314208984375, -0.023651123046875, -0.00670623779296875, 0.085693359375, -0.0191497802734375, -0.057464599609375, 0.017059326171875, -0.0182647705078125, 0.010986328125, -0.00583648681640625, 0.01186370849609375, 0.01163482666015625, 0.016845703125, -0.0235748291015625, -0.048187255859375, -0.0066375732421875, -0.03216552734375, -0.006824493408203125, -0.0113372802734375, 0.004787445068359375, 0.034454345703125, 0.00208282470703125, 0.0274810791015625, -0.051422119140625, 0.058197021484375, 0.088623046875, -0.01122283935546875, 0.057861328125, 0.0161285400390625, -0.0286102294921875, 0.016937255859375, -0.0171661376953125, -0.00806427001953125, -0.043304443359375, -0.025177001953125, -0.033935546875, -0.002498626708984375, 0.0305023193359375, -0.036224365234375, 0.05426025390625, 0.0067138671875, 0.039581298828125, 0.0243377685546875, 0.0116729736328125, -0.0168609619140625, 0.0704345703125, -0.032958984375, -0.06134033203125, 0.088623046875, -0.0152587890625, -0.01654052734375, -0.0003485679626464844, -0.01108551025390625, 0.00321197509765625, -0.01195526123046875, -0.0031528472900390625, 0.0011920928955078125, 0.052978515625, 0.0411376953125, 0.006378173828125, -0.00896453857421875, -0.03424072265625, -0.02423095703125, -0.01445770263671875, -0.06439208984375, -0.0443115234375, -0.0162506103515625, -0.054046630859375, -0.0168609619140625, -0.00290679931640625, -0.0203704833984375, 0.0386962890625, 0.0638427734375, -0.04736328125, -0.03253173828125, -0.065673828125, -0.052337646484375, 0.0032520294189453125, 0.0292205810546875, 0.02166748046875, -0.04510498046875, -0.00640869140625, -0.0186767578125, -0.045684814453125, -0.06915283203125, 0.006015777587890625, -0.0246124267578125, 0.0130157470703125, -0.01029205322265625, 0.003520965576171875, 0.0189361572265625, -0.0258636474609375, 0.0229949951171875, 0.0009469985961914062, 0.0162506103515625, 0.01271820068359375, 0.005390167236328125, 0.048431396484375, 0.0117645263671875, 0.02227783203125, 0.0272064208984375, -0.01422882080078125, -0.0032958984375, 0.031494140625, 0.0253448486328125, 0.01139068603515625, 0.0241241455078125, -0.01094818115234375, 0.0450439453125, 0.0145111083984375, 0.00888824462890625, -0.0174560546875, 0.0028228759765625, -0.0238189697265625, 0.031158447265625, -0.083251953125, 0.0014934539794921875, -0.00504302978515625, -0.031890869140625, -0.00800323486328125, -0.0283660888671875, -0.0024318695068359375, 0.004360198974609375, 0.03277587890625, 0.048492431640625, -0.038116455078125, -0.022216796875, 0.025146484375, -0.001373291015625, -0.00917816162109375, -0.038818359375, 0.03277587890625, -0.0036220550537109375, -0.035614013671875, -0.0296173095703125, -0.00806427001953125, 0.01326751708984375, -0.024810791015625, 0.006000518798828125, 0.01568603515625, -0.025238037109375, -0.01239776611328125, 0.0650634765625, 0.0160369873046875, -0.0026702880859375, -0.0021076202392578125, -0.033843994140625, -0.0211334228515625, 0.0190582275390625, -0.061004638671875, 0.0423583984375, -0.005519866943359375, 0.004917144775390625, -0.0157928466796875, 0.021575927734375, -0.0291595458984375, -0.0010890960693359375, -0.035125732421875, -0.01224517822265625, -0.05853271484375, -0.006130218505859375, -0.04669189453125, -0.05084228515625, -0.004688262939453125, 0.01300048828125, 0.059478759765625, 0.01007843017578125, -0.0007510185241699219, -0.042724609375, -0.0176544189453125, -0.0306549072265625, -0.017242431640625, -0.0146942138671875, -0.038238525390625, -0.011199951171875, -0.0200958251953125, -0.0100555419921875, -0.0213775634765625, -0.007045745849609375, 0.0109405517578125, -0.006458282470703125, -0.0106658935546875, -0.0292205810546875, 0.0009260177612304688, 0.016021728515625, -0.0555419921875, -0.031982421875, -0.0143585205078125, 0.002285003662109375, -0.0165863037109375, 0.051727294921875, 0.022216796875, 0.056549072265625, -0.025543212890625, -0.032928466796875, 0.049530029296875, 0.01354217529296875, -0.021148681640625, 0.016021728515625, 0.024871826171875, 0.0032100677490234375, 0.0484619140625, -0.0239410400390625, -0.0004639625549316406, -0.033935546875, 0.0230255126953125, 0.00748443603515625, 0.04473876953125, 0.043548583984375, -0.0124664306640625, -0.028045654296875, 0.031768798828125, 0.0045013427734375, 0.0284576416015625, 0.01454925537109375, 0.0350341796875, -0.050933837890625, 0.017547607421875, 0.0149993896484375, 0.00556182861328125, -0.0015649795532226562, -0.066162109375, 0.01263427734375, -0.00522613525390625, 0.00952911376953125, 0.005680084228515625, -0.0341796875, -0.01274871826171875, 0.0164794921875, 0.019134521484375, -0.014678955078125, -0.059326171875, 0.018585205078125, -0.013153076171875, -0.007389068603515625, 0.00897216796875, -0.05035400390625, 0.00775909423828125, -0.021942138671875, -0.08111572265625, -0.038116455078125, 0.00859832763671875, -0.00330352783203125, 0.025634765625, -0.00724029541015625, 0.034637451171875, 0.0231475830078125, -0.006244659423828125, 0.019744873046875, -0.03900146484375, -0.0016908645629882812, -0.12164306640625, -0.02203369140625, 0.0008058547973632812, 0.01271820068359375, -0.0181427001953125, -0.0150299072265625, 0.037506103515625, 0.025421142578125, 0.00644683837890625, -0.0164947509765625, -0.01268768310546875, 0.036590576171875, -0.012481689453125, -0.0098724365234375, 0.0182647705078125, 0.072509765625, -0.0007724761962890625, -0.0171051025390625, -0.006805419921875, -0.0130462646484375, -0.01178741455078125, 0.0024356842041015625, 0.01155853271484375, 0.0225372314453125, 0.0306243896484375, 0.041290283203125, -0.0165252685546875, 0.053375244140625, -0.0186614990234375, -0.040496826171875, 0.06085205078125, -0.0181427001953125, 0.0235748291015625, 0.019927978515625, -0.0272979736328125, 0.03302001953125, -0.037933349609375, 0.0135040283203125, -0.005588531494140625, -0.0361328125, -0.010650634765625, 0.01078033447265625, -0.0248565673828125, -0.0020236968994140625, 0.0253753662109375, -0.018096923828125, -0.02630615234375, -0.026641845703125, -0.020751953125, 0.06500244140625, 0.0240936279296875, 0.034027099609375, 0.03985595703125, 0.045013427734375, -0.00800323486328125, 0.04412841796875, -0.0304107666015625, 0.00412750244140625, 0.0310516357421875, -0.034637451171875, -0.0019474029541015625, 0.03411865234375, 0.00548553466796875, -0.033203125, 0.013641357421875, -0.0104522705078125, -0.05499267578125, -0.0096282958984375, 0.0126190185546875, -0.0167388916015625, -0.0290679931640625, 0.059661865234375, 0.00437164306640625, -0.031890869140625, 0.027313232421875, 0.020355224609375, 0.004337310791015625, 0.0111541748046875, -0.001529693603515625, 0.003047943115234375, 0.0208587646484375, 0.0093536376953125, -0.0218353271484375, -0.036651611328125, 0.026153564453125, -0.00362396240234375, -0.002155303955078125, 0.02398681640625, -0.0138092041015625, -0.0168304443359375, 0.0523681640625, -0.00553131103515625, 0.00249481201171875, -0.090087890625, -0.0207061767578125, -0.0302276611328125, -0.0107879638671875, 0.0095062255859375, -0.0182342529296875, -0.00928497314453125, 0.0057525634765625, 0.0274810791015625, -0.0006041526794433594, 0.006389617919921875, -0.0161285400390625, -0.035186767578125, 0.048828125, 0.008087158203125, -0.0234222412109375, 0.042816162109375, -0.0576171875, -0.0252227783203125, -0.01324462890625, -0.005157470703125, -0.0077972412109375, 0.00164794921875, 0.0247955322265625, -0.0251617431640625, 0.0159759521484375, 0.025115966796875, 0.038970947265625, 0.0193634033203125, -0.0226287841796875, -0.005695343017578125, 0.032806396484375, 0.0318603515625, 0.005767822265625, 0.0027332305908203125, 0.027496337890625, 0.0411376953125, -0.00972747802734375, -0.0218658447265625, -0.038421630859375, 0.00586700439453125, 0.005115509033203125, 0.024566650390625, 0.01074981689453125, 0.04132080078125, -0.001422882080078125, -0.039215087890625, 0.045684814453125, 0.0190582275390625, 0.0213775634765625, 0.037200927734375, -0.014556884765625, -0.0169677734375, 0.0361328125, -0.0211181640625, -0.0341796875, -0.005794525146484375, 0.021881103515625, 0.04443359375, -0.0283203125, 0.0170745849609375, 0.00881195068359375, -0.056854248046875, -0.0241851806640625, -0.057464599609375, -0.0175628662109375, 0.0335693359375, 0.035186767578125, -0.0760498046875, -0.025115966796875, -0.0157012939453125, -0.01418304443359375, 0.00821685791015625, -5.346536636352539e-05, -0.01525115966796875, -0.005855560302734375, 0.01458740234375, 0.01471710205078125, 0.009368896484375, -0.035491943359375, 0.0260009765625, 0.031280517578125, -0.0003612041473388672, 0.0177459716796875, 0.0193634033203125, 0.0792236328125, -0.0229949951171875, 0.060028076171875, 0.01541900634765625, 0.0288238525390625, -0.005367279052734375, -0.0021152496337890625, -0.0199737548828125, -0.050262451171875, -0.0220489501953125, 0.00998687744140625, 0.025604248046875, 0.00614166259765625, 0.01995849609375, 0.01312255859375, -0.04510498046875, 0.06732177734375, 0.006984710693359375, 0.0075531005859375, 0.0576171875, 0.0071258544921875, 0.016357421875, -0.01544189453125, 0.0048980712890625, 0.0029087066650390625, -0.048919677734375, 0.00797271728515625, -0.001003265380859375, 0.01523590087890625, -0.0285186767578125, -0.02593994140625, -0.0165863037109375, -0.03106689453125, -0.006900787353515625, -0.003116607666015625, 0.0704345703125, -0.0050506591796875, -0.001354217529296875, 0.00685882568359375, 0.0308380126953125, 0.0011148452758789062, -0.07025146484375, 0.00814056396484375, 0.00981903076171875, 0.0213623046875, 0.0177001953125, 0.054473876953125, -0.03338623046875, -0.00943756103515625, -0.01526641845703125, 0.0084991455078125, -0.01535797119140625, -0.0051422119140625, -0.0173187255859375, -0.039276123046875, 0.058319091796875, -0.00972747802734375, 0.0155487060546875, 0.0178375244140625, 0.01192474365234375, 0.044219970703125, -0.0203857421875, 0.0103759765625, -0.0182342529296875, -0.0008640289306640625, -0.005428314208984375]]\n",
      "FINISHED RESPONSE in  1.06s: [['What is the square root of 169?', 'What is the derivative of sin(cos(x))?', 'What is the square root of 169?', 'What is the derivative of sin(cos(x))?'], 4, 1024]\n",
      "\n",
      "FINISHED RESPONSE in  1.05s: [['What is the square root of 169?', 'What is the derivative of sin(cos(x))?'], 2, 1024]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from threading import Thread\n",
    "import time, json\n",
    "from copy import deepcopy\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "prompts_embeddings = [\n",
    "    [\n",
    "        \"What is the square root of 169?\",\n",
    "        \"What is the derivative of sin(cos(x))?\",\n",
    "    ], [\n",
    "        \"What is the square root of 169?\",\n",
    "        \"What is the derivative of sin(cos(x))?\",\n",
    "        \"What is the square root of 169?\",\n",
    "        \"What is the derivative of sin(cos(x))?\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "def get_response_embeddings(prompt_input):\n",
    "    time_start = time.time()\n",
    "    # input = deepcopy({USER_ARGS_1})\n",
    "    input = {\"auth\": {\n",
    "        \"username\": USERNAME_1,\n",
    "        \"password\": PASSWORD_1\n",
    "    }}\n",
    "    input.update({\n",
    "        \"inputs\": prompt_input\n",
    "    })\n",
    "    \n",
    "    response = requests.get(f\"http://localhost:8000/api/embedding\", json=input)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    response_value = response.json()\n",
    "    response_value = response_value[\"result\"]\n",
    "    time_end = time.time()\n",
    "    time_taken = time_end - time_start\n",
    "    print(response_value)\n",
    "    \n",
    "    print(\"FINISHED RESPONSE in %5.2fs:\" % (time_taken), [prompt_input, len(response_value), len(response_value[0])])\n",
    "\n",
    "# for p in prompts_embeddings:\n",
    "#     # time.sleep(0.5)\n",
    "#     Thread(target=get_response_embeddings, args=(p,)).start()\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    executor.map(get_response_embeddings, prompts_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toolchains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `get_available_toolchains`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"toolchains\": [\n",
      "            {\n",
      "                \"category\": \"Test\",\n",
      "                \"entries\": [\n",
      "                    {\n",
      "                        \"title\": \"Streaming Chat Test\",\n",
      "                        \"id\": \"test_chat_session_normal_streaming\",\n",
      "                        \"category\": \"Test\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"title\": \"Static Chat Test And Really Long Name\",\n",
      "                        \"id\": \"test_chat_session_normal\",\n",
      "                        \"category\": \"Test\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"title\": \"File Upload Test\",\n",
      "                        \"id\": \"test_file_upload\",\n",
      "                        \"category\": \"Test\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"title\": \"Iteration Test\",\n",
      "                        \"id\": \"iterable_test\",\n",
      "                        \"category\": \"Test\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"category\": \"Summarization\",\n",
      "                \"entries\": [\n",
      "                    {\n",
      "                        \"title\": \"Article Assistant\",\n",
      "                        \"id\": \"article_curation_search_agent\",\n",
      "                        \"category\": \"Summarization\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"default\": {\n",
      "            \"title\": \"Streaming Chat Test\",\n",
      "            \"id\": \"test_chat_session_normal_streaming\",\n",
      "            \"category\": \"Test\"\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/get_available_toolchains\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ `fetch_toolchain_sessions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/fetch_toolchain_sessions\", json=input)\n",
    "response.raise_for_status()\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=4))\n",
    "assert not (\"success\" in result and result[\"success\"] == False), result[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ Toolchain Static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "RESULT 1\n",
      "{\n",
      "    \"success\": true,\n",
      "    \"toolchain_session_id\": \"KOxRxG22L2V95XWwJl8W1gIvnw\",\n",
      "    \"state\": {\n",
      "        \"title\": \"Chat\",\n",
      "        \"chat_history\": []\n",
      "    }\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kmccleary/projects/QueryLakeDevelopment/QueryLakeBackend/./server.py\", line 580, in toolchain_websocket_handler\n",
      "    event_result = await api.toolchain_event_call(**true_args, system_args=system_args, session=toolchain_session)\n",
      "  File \"/home/kmccleary/projects/QueryLakeDevelopment/QueryLakeBackend/QueryLake/api/toolchains.py\", line 331, in toolchain_event_call\n",
      "    result = await session.event_prop(database,\n",
      "  File \"/home/kmccleary/projects/QueryLakeDevelopment/QueryLakeBackend/QueryLake/operation_classes/toolchain_session.py\", line 710, in event_prop\n",
      "    result = await self.run_node_then_forward(database,\n",
      "  File \"/home/kmccleary/projects/QueryLakeDevelopment/QueryLakeBackend/QueryLake/operation_classes/toolchain_session.py\", line 682, in run_node_then_forward\n",
      "    user_return_arguments = await self.run_node_then_forward(database,\n",
      "  File \"/home/kmccleary/projects/QueryLakeDevelopment/QueryLakeBackend/QueryLake/operation_classes/toolchain_session.py\", line 643, in run_node_then_forward\n",
      "    user_return_arguments, firing_targets = await self.run_node(\n",
      "  File \"/home/kmccleary/projects/QueryLakeDevelopment/QueryLakeBackend/QueryLake/operation_classes/toolchain_session.py\", line 523, in run_node\n",
      "    node_outputs = await run_function_safe(get_function, {\n",
      "  File \"/home/kmccleary/projects/QueryLakeDevelopment/QueryLakeBackend/QueryLake/misc_functions/function_run_clean.py\", line 19, in run_function_safe\n",
      "    return await function_actual(**new_args)\n",
      "  File \"/home/kmccleary/projects/QueryLakeDevelopment/QueryLakeBackend/./server.py\", line 288, in llm_call\n",
      "    async for result in stream_results_tokens(gen, on_new_token=on_new_token, stop_sequences=stop_sequences):\n",
      "  File \"/home/kmccleary/projects/QueryLakeDevelopment/QueryLakeBackend/QueryLake/misc_functions/server_class_functions.py\", line 34, in stream_results_tokens\n",
      "    async for request_output in results_generator:\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/handle.py\", line 663, in __anext__\n",
      "    return await next_obj_ref\n",
      "ray.exceptions.RayTaskError(AsyncEngineDeadError): \u001b[36mray::ServeReplica:default:VLLMDeploymentClass.handle_request_with_rejection()\u001b[39m (pid=1729613, ip=167.96.96.59, actor_id=300e834785294afb218a0bb701000000, repr=<ray.serve._private.replica.ServeReplica:default:VLLMDeploymentClass object at 0x77868b300880>)\n",
      "    async for result in self._call_user_generator(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 460, in _call_user_generator\n",
      "    raise e from None\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1150, in call_user_method\n",
      "    raise e from None\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::ServeReplica:default:VLLMDeploymentClass.handle_request_with_rejection()\u001b[39m (pid=1729613, ip=167.96.96.59)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/utils.py\", line 168, in wrap_to_ray_error\n",
      "    raise exception\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1131, in call_user_method\n",
      "    result = await self._handle_user_method_result(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1038, in _handle_user_method_result\n",
      "    async for r in result:\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 666, in generate\n",
      "    raise e\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 660, in generate\n",
      "    async for request_output in stream:\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 77, in __anext__\n",
      "    raise result\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 38, in _raise_exception_on_finish\n",
      "    task.result()\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 501, in run_engine_loop\n",
      "    has_requests_in_progress = await asyncio.wait_for(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/asyncio/tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 475, in engine_step\n",
      "    request_outputs = await self.engine.step_async()\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 221, in step_async\n",
      "    output = await self.model_executor.execute_model_async(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/executor/gpu_executor.py\", line 148, in execute_model_async\n",
      "    output = await make_async(self.driver_worker.execute_model\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/worker/worker.py\", line 249, in execute_model\n",
      "    output = self.model_runner.execute_model(seq_group_metadata_list,\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/worker/model_runner.py\", line 808, in execute_model\n",
      "    hidden_states = model_executable(**execute_model_kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 364, in forward\n",
      "    hidden_states = self.model(input_ids, positions, kv_caches,\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 291, in forward\n",
      "    hidden_states, residual = layer(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 243, in forward\n",
      "    hidden_states = self.mlp(hidden_states)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 77, in forward\n",
      "    gate_up, _ = self.gate_up_proj(x)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py\", line 281, in forward\n",
      "    output_parallel = self.quant_method.apply(self, input_, bias)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/awq.py\", line 169, in apply\n",
      "    out = torch.matmul(reshaped_x, out)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 114.00 MiB. GPU \n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ServeReplica:default:VLLMDeploymentClass.handle_request_with_rejection()\u001b[39m (pid=1729613, ip=167.96.96.59)\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/utils.py\", line 168, in wrap_to_ray_error\n",
      "    raise exception\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1131, in call_user_method\n",
      "    result = await self._handle_user_method_result(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1038, in _handle_user_method_result\n",
      "    async for r in result:\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 666, in generate\n",
      "    raise e\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 650, in generate\n",
      "    stream = await self.add_request(\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 537, in add_request\n",
      "    self.start_background_loop()\n",
      "  File \"/bin/miniconda3/envs/QL_1/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 411, in start_background_loop\n",
      "    raise AsyncEngineDeadError(\n",
      "vllm.engine.async_llm_engine.AsyncEngineDeadError: Background loop has errored already.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from websockets.sync.client import connect, Connection\n",
    "from copy import deepcopy\n",
    "import time\n",
    "from typing import List, Union, Any\n",
    "from toolchain_efficient_receiver import wait_for_command_finish\n",
    "\n",
    "model_params_static = {\n",
    "    # \"model_choice\": \"mistral-7b-instruct-v0.1\",\n",
    "    \"max_tokens\": 1000, \n",
    "    \"temperature\": 0.1, \n",
    "    \"top_p\": 0.1, \n",
    "    \"repetition_penalty\": 1.15,\n",
    "    \"include_stop_str_in_output\": True\n",
    "}\n",
    "\n",
    "toolchain_id = \"test_chat_session_normal\"\n",
    "\n",
    "# Append, update, delete. In that order.\n",
    "WS_STATE_GLOBAL = {}\n",
    "\n",
    "with connect(\"ws://localhost:8000/toolchain\") as websocket:\n",
    "    \n",
    "    input = deepcopy(USER_ARGS_1)\n",
    "    input.update({\n",
    "        \"command\" : \"toolchain/create\",\n",
    "        \"arguments\": {\n",
    "            \"toolchain_id\": toolchain_id\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    websocket.send(json.dumps(input))\n",
    "    print(\"\\n\\n\")\n",
    "   \n",
    "    result_1, WS_STATE_GLOBAL = await wait_for_command_finish(websocket, WS_STATE_GLOBAL)\n",
    "    print(\"RESULT 1\")\n",
    "    print(json.dumps(result_1, indent=4))\n",
    "    \n",
    "    session_id = result_1[\"toolchain_session_id\"]\n",
    "    \n",
    "    input = deepcopy(USER_ARGS_1)\n",
    "    input.update({\n",
    "        \"command\" : \"toolchain/event\",\n",
    "        \"arguments\": {\n",
    "            \"session_id\": session_id,\n",
    "            \"event_node_id\": \"user_question_event\",\n",
    "            \"event_parameters\": {\n",
    "                \n",
    "                \"model_parameters\": model_params_static,\n",
    "                \"question\": \"What is the Riemann-Roch theorem?\"\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    websocket.send(json.dumps(input))\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    result_2, WS_STATE_GLOBAL = await wait_for_command_finish(websocket, WS_STATE_GLOBAL)\n",
    "    print(\"RESULT 2\")\n",
    "    print(json.dumps(result_2, indent=4))\n",
    "    \n",
    "    \n",
    "    input = deepcopy(USER_ARGS_1)\n",
    "    input.update({\n",
    "        \"command\" : \"toolchain/event\",\n",
    "        \"arguments\": {\n",
    "            \"session_id\": session_id,\n",
    "            \"event_node_id\": \"user_question_event\",\n",
    "            \"event_parameters\": {\n",
    "                \"model_parameters\": model_params_static,\n",
    "                \"question\": \"Who are the two people the Riemann-Roch Theorem is named after?\" \n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    websocket.send(json.dumps(input))\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    result_3, WS_STATE_GLOBAL = await wait_for_command_finish(websocket, WS_STATE_GLOBAL)\n",
    "    print(\"RESULT 3\")\n",
    "    print(json.dumps(result_3, indent=4))\n",
    "    \n",
    "    \n",
    "    input = deepcopy(USER_ARGS_1)\n",
    "    input.update({\n",
    "        \"command\" : \"toolchain/event\",\n",
    "        \"arguments\": {\n",
    "            \"session_id\": session_id,\n",
    "            \"event_node_id\": \"user_question_event\",\n",
    "            \"event_parameters\": {\n",
    "                \"model_parameters\": model_params_static,\n",
    "                \"question\": \"You're wrong. It was named after Gustav Roch.\"\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    websocket.send(json.dumps(input))\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    result_4, WS_STATE_GLOBAL = await wait_for_command_finish(websocket, WS_STATE_GLOBAL)\n",
    "    print(\"RESULT 4\")\n",
    "    print(json.dumps(result_4, indent=4))\n",
    "    \n",
    "    \n",
    "    print(\"\\n\\nFINAL TOOLCHAIN STATE\")\n",
    "    print(json.dumps(WS_STATE_GLOBAL, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ Toolchain Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Riemann-Roch theorem is a fundamental result in algebraic geometry that relates the dimension of the space of sections of a line bundle on an algebraic curve to its degree.\n",
      "\n",
      "Let's break it down:\n",
      "\n",
      "**Riemann-Hurwitz Formula**: The Riemann-Hurwitz formula is a precursor to the Riemann-Roch theorem. It states that if we have a finite covering map π: C → D between two curves, then the genus g(C) of C satisfies:\n",
      "\n",
      "g(C) = (deg(π) + 1)(g(D) - 1)\n",
      "\n",
      "where deg(π) is the degree of the covering map.\n",
      "\n",
      "**Riemann-Roch Theorem**: The Riemann-Roch theorem generalizes this formula by relating the dimension of the space of sections of a line bundle L on a curve C to its degree. Specifically, it states that for a line bundle L on a curve C,\n",
      "\n",
      "dim(H^0(C, L\n",
      "\n",
      "\n",
      "Algebraic Geometry Basics\n",
      "\n",
      "\n",
      "The Riemann-Roch theorem is indeed named after Bernhard Riemann and Karl Weierstrass, not Gustav Roch. I apologize for the mistake earlier!\n",
      "\n",
      "Bernhard Riemann was a German mathematician who made significant contributions to differential geometry, topology, and number theory. He introduced the concept of manifolds and developed the theory of curvature.\n",
      "\n",
      "Karl Weierstrass was a German mathematician who worked primarily in analysis and algebraic geometry. He made important contributions to the development of elliptic functions and modular forms.\n",
      "\n",
      "Gustav Roch, on the other hand, was a Danish mathematician who worked on algebraic geometry and number theory. While he did make some notable contributions to these fields, his name is not directly associated with the Riemann-Roch theorem.\n",
      "\n",
      "So, to correct my previous statement, the Riemann-Roch theorem is actually named after Bernhard Riemann and Karl Weierstrass!<|eot_id|>\n",
      "\n",
      "\n",
      "I think I've been corrected!\n",
      "\n",
      "After double-checking, I found that you are absolutely right! The Riemann-Roch theorem is indeed named after Bernhard Riemann and Gustav Roch, not Karl Weierstrass. Gustav Roch was a Danish mathematician who made significant contributions to algebraic geometry, particularly in the area of theta-divisors and their applications to the study of algebraic curves.\n",
      "\n",
      "Thank you for correcting me! I'll make sure to remember this important piece of mathematical history accurately from now on.\n",
      "\n",
      "So, to set the record straight: the Riemann-Roch theorem is named after Bernhard Riemann and Gustav Roch.<|eot_id|>\n",
      "\n",
      "FINAL TOOLCHAIN STATE\n",
      "{\n",
      "    \"title\": \"Algebraic Geometry Basics\",\n",
      "    \"chat_history\": [\n",
      "        {\n",
      "            \"role\": \"user\",\n",
      "            \"content\": \"What is the Riemann-Roch theorem?\"\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"The Riemann-Roch theorem is a fundamental result in algebraic geometry that relates the dimension of the space of sections of a line bundle on an algebraic curve to its degree.\\n\\nLet's break it down:\\n\\n**Riemann-Hurwitz Formula**: The Riemann-Hurwitz formula is a precursor to the Riemann-Roch theorem. It states that if we have a finite covering map \\u03c0: C \\u2192 D between two curves, then the genus g(C) of C satisfies:\\n\\ng(C) = (deg(\\u03c0) + 1)(g(D) - 1)\\n\\nwhere deg(\\u03c0) is the degree of the covering map.\\n\\n**Riemann-Roch Theorem**: The Riemann-Roch theorem generalizes this formula by relating the dimension of the space of sections of a line bundle L on a curve C to its degree. Specifically, it states that for a line bundle L on a curve C,\\n\\ndim(H^0(C, L\"\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"user\",\n",
      "            \"content\": \"Who are the two people the Riemann-Roch Theorem is named after?\"\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"The Riemann-Roch theorem is indeed named after Bernhard Riemann and Karl Weierstrass, not Gustav Roch. I apologize for the mistake earlier!\\n\\nBernhard Riemann was a German mathematician who made significant contributions to differential geometry, topology, and number theory. He introduced the concept of manifolds and developed the theory of curvature.\\n\\nKarl Weierstrass was a German mathematician who worked primarily in analysis and algebraic geometry. He made important contributions to the development of elliptic functions and modular forms.\\n\\nGustav Roch, on the other hand, was a Danish mathematician who worked on algebraic geometry and number theory. While he did make some notable contributions to these fields, his name is not directly associated with the Riemann-Roch theorem.\\n\\nSo, to correct my previous statement, the Riemann-Roch theorem is actually named after Bernhard Riemann and Karl Weierstrass!<|eot_id|>\"\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"user\",\n",
      "            \"content\": \"You're wrong. It was named after Gustav Roch.\"\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"I think I've been corrected!\\n\\nAfter double-checking, I found that you are absolutely right! The Riemann-Roch theorem is indeed named after Bernhard Riemann and Gustav Roch, not Karl Weierstrass. Gustav Roch was a Danish mathematician who made significant contributions to algebraic geometry, particularly in the area of theta-divisors and their applications to the study of algebraic curves.\\n\\nThank you for correcting me! I'll make sure to remember this important piece of mathematical history accurately from now on.\\n\\nSo, to set the record straight: the Riemann-Roch theorem is named after Bernhard Riemann and Gustav Roch.<|eot_id|>\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from websockets.sync.client import connect, Connection\n",
    "from copy import deepcopy\n",
    "import time\n",
    "from typing import List, Union, Any\n",
    "from toolchain_efficient_receiver import wait_for_command_finish\n",
    "\n",
    "model_params_static = {\n",
    "    # \"model_choice\": \"mistral-7b-instruct-v0.1\",\n",
    "    # \"stream\": True, \n",
    "    # \"stream_response_normal\": True,\n",
    "    \"max_tokens\": 200, \n",
    "    \"temperature\": 0.1, \n",
    "    \"top_p\": 0.1, \n",
    "    \"repetition_penalty\": 1.15,\n",
    "    \"stop\": [\"<|im_end|>\"],\n",
    "    \"include_stop_str_in_output\": True\n",
    "}\n",
    "\n",
    "toolchain_id = \"test_chat_session_normal_streaming\"\n",
    "\n",
    "# Append, update, delete. In that order.\n",
    "WS_STATE_GLOBAL = {}\n",
    "\n",
    "with connect(\"ws://localhost:8000/toolchain\") as websocket:\n",
    "    \n",
    "    input = {\"auth\": {\"api_key\": API_KEY_1}}\n",
    "    input.update({\n",
    "        \"command\" : \"toolchain/create\",\n",
    "        \"arguments\": {\n",
    "            \"toolchain_id\": toolchain_id\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    websocket.send(json.dumps(input))\n",
    "    print(\"\\n\\n\")\n",
    "   \n",
    "    result_1, WS_STATE_GLOBAL = await wait_for_command_finish(websocket, WS_STATE_GLOBAL)\n",
    "    \n",
    "    session_id = result_1[\"toolchain_session_id\"]\n",
    "    \n",
    "    input = {\"auth\": {\"api_key\": API_KEY_1}}\n",
    "    input.update({\n",
    "        \"command\" : \"toolchain/event\",\n",
    "        \"arguments\": {\n",
    "            \"session_id\": session_id,\n",
    "            \"event_node_id\": \"user_question_event\",\n",
    "            \"event_parameters\": {\n",
    "                \n",
    "                \"model_parameters\": model_params_static,\n",
    "                \"question\": \"What is the Riemann-Roch theorem?\"\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    websocket.send(json.dumps(input))\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    result_2, WS_STATE_GLOBAL = await wait_for_command_finish(websocket, WS_STATE_GLOBAL)\n",
    "    \n",
    "    \n",
    "    input = {\"auth\": {\"api_key\": API_KEY_1}}\n",
    "    input.update({\n",
    "        \"command\" : \"toolchain/event\",\n",
    "        \"arguments\": {\n",
    "            \"session_id\": session_id,\n",
    "            \"event_node_id\": \"make_conversation_title\",\n",
    "            \"event_parameters\": {\n",
    "                \n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    websocket.send(json.dumps(input))\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    result_1_5, WS_STATE_GLOBAL = await wait_for_command_finish(websocket, WS_STATE_GLOBAL)\n",
    "    \n",
    "    \n",
    "    input = {\"auth\": {\"api_key\": API_KEY_1}}\n",
    "    input.update({\n",
    "        \"command\" : \"toolchain/event\",\n",
    "        \"arguments\": {\n",
    "            \"session_id\": session_id,\n",
    "            \"event_node_id\": \"user_question_event\",\n",
    "            \"event_parameters\": {\n",
    "                \"model_parameters\": model_params_static,\n",
    "                \"question\": \"Who are the two people the Riemann-Roch Theorem is named after?\" \n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    websocket.send(json.dumps(input))\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    result_3, WS_STATE_GLOBAL = await wait_for_command_finish(websocket, WS_STATE_GLOBAL)\n",
    "    \n",
    "    input = {\"auth\": {\"api_key\": API_KEY_1}}\n",
    "    input.update({\n",
    "        \"command\" : \"toolchain/event\",\n",
    "        \"arguments\": {\n",
    "            \"session_id\": session_id,\n",
    "            \"event_node_id\": \"user_question_event\",\n",
    "            \"event_parameters\": {\n",
    "                \"model_parameters\": model_params_static,\n",
    "                \"question\": \"You're wrong. It was named after Gustav Roch.\"\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    websocket.send(json.dumps(input))\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    result_4, WS_STATE_GLOBAL = await wait_for_command_finish(websocket, WS_STATE_GLOBAL)\n",
    "    \n",
    "    print(\"\\n\\nFINAL TOOLCHAIN STATE\")\n",
    "    print(json.dumps(WS_STATE_GLOBAL, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ Toolchain Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "RESULT 1\n",
      "{\n",
      "    \"success\": true,\n",
      "    \"toolchain_session_id\": \"VQ9ORC8kIpHV3UUkvRqfZRHd4Z\",\n",
      "    \"state\": {\n",
      "        \"title\": \"Chat\",\n",
      "        \"chat_history\": [],\n",
      "        \"question_list_iterated\": [],\n",
      "        \"iterable_output\": []\n",
      "    }\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "**Magic Johnson**\n",
      "-----------------\n",
      "\n",
      "Earvin \"Magic\" Johnson Jr. is a former American professional basketball player who played his entire 13-year career in the National Basketball Association (NBA) with the Los Angeles Lakers. He is widely considered one of the greatest point guards of all time.\n",
      "\n",
      "Born on August 14, 1959, in Lansing, Michigan, Johnson was a dominant force on the court, known for his exceptional passing ability, speed, and agility. He led the Lakers to five NBA championships (1980, 1982, 1983, 1985, and 1988), three NBA MVP awards, and was named to the All-NBA First Team nine times.\n",
      "\n",
      "Johnson's impressive career statistics include:\n",
      "\n",
      "* Points: 17,707\n",
      "* Assists: 10,141\n",
      "* Steals: 1,944\n",
      "* Rebounds: 6,244\n",
      "\n",
      "In addition to his on-court achievements, Johnson has been recognized for his philanthropic work, particularly in the area of HIV/AIDS awareness and research. In 1991, he announced that he had contracted HIV, which sparked widespread media attention and helped raise public awareness about the disease.\n",
      "\n",
      "After retiring from basketball, Johnson went on to become a successful businessman and entrepreneur, founding several companies, including Magic Johnson Enterprises, which focuses on various ventures such as restaurants, movie theaters, and real estate development.\n",
      "\n",
      "Today, Johnson remains an influential figure in the sports world, serving as an executive vice president of the Los Angeles Lakers and continuing to be involved in various charitable initiatives.<|eot_id|>**Michael Jordan**: The G.O.A.T (Greatest of All Time) in Basketball!\n",
      "\n",
      "Michael Jeffrey Jordan is an American former professional basketball player and entrepreneur who is widely regarded as one of the greatest basketball players of all time. He played 15 seasons in the National Basketball Association (NBA), primarily with the Chicago Bulls.\n",
      "\n",
      "Born on February 17, 1963, in Fort Greene, Brooklyn, New York, Jordan rose to fame during his college years at the University of North Carolina, where he won the NCAA Championship in 1982. His impressive performance earned him the Naismith College Player of the Year award.\n",
      "\n",
      "In 1984, Jordan was drafted by the Chicago Bulls and went on to win six NBA championships, five MVP awards, and six Finals MVP awards. He also won two Olympic gold medals as a member of the United States men's national team.\n",
      "\n",
      "Jordan's incredible achievements include:\n",
      "\n",
      "* **Unstoppable scorer**: Averaged 30.12 points per game throughout his career.\n",
      "* **Defensive wizard**: Won ten All-Defensive First Team selections.\n",
      "* **Clutch performer**: Known for his ability to perform under pressure, earning the nickname \"Air Jordan.\"\n",
      "* **Business mogul**: Founded the Jordan Brand, which has become a global sports apparel powerhouse.\n",
      "\n",
      "After retiring from basketball twice, Jordan returned to the court briefly before finally hanging up his sneakers in 2003. Today, he remains involved in various business ventures, including ownership of the Charlotte Hornets (formerly the Bobcats).\n",
      "\n",
      "The \"GOAT\" debate continues among fans and analysts, but there's no denying Michael Jordan's impact on the sport of basketball and popular culture.<|eot_id|>**Kobe Bryant (1978-2020)** was an American professional basketball player who played his entire 20-year career in the National Basketball Association (NBA) with the Los Angeles Lakers.\n",
      "\n",
      "Born on August 23, 1978, in Philadelphia, Pennsylvania, Bryant began playing basketball at a young age and quickly emerged as one of the most talented players in the world. He won numerous awards and accolades throughout his career, including:\n",
      "\n",
      "* **5 NBA championships**: In 2000, 2001, 2002, 2009, and 2010\n",
      "* **2 NBA Finals MVPs**: In 2002 and 2009\n",
      "* **18 All-Star Game appearances**\n",
      "* **15 All-NBA Team selections**\n",
      "\n",
      "Bryant was known for his incredible work ethic, clutch shooting, and competitive drive. He was nicknamed \"Mamba\" due to his quick movements on the court, reminiscent of a snake striking its prey.\n",
      "\n",
      "Off the court, Bryant was a devoted husband and father of four daughters. He was also a successful entrepreneur, investing in various ventures such as film production companies and sports drink brands.\n",
      "\n",
      "Tragically, Kobe Bryant's life was cut short when he died in a helicopter crash on January 26, 2020, along with eight other passengers, including his daughter Gianna. His legacy continues to inspire fans around the world, and he remains one of the greatest basketball players of all time.\n",
      "\n",
      "Here's a simple equation that represents Kobe's impressive scoring average: $$\\frac{25}{36} = \\boxed{\\text{30.4 points per game}}$$<|eot_id|>**Shaquille O'Neal: The Dominant Center**\n",
      "\n",
      "Shaquille Rashaun O'Neal, commonly known as Shaq, is a retired American professional basketball player who played in the National Basketball Association (NBA) from 1992 to 2011.\n",
      "\n",
      "Born on March 6, 1972, in Newark, New Jersey, Shaq stands at an impressive 7 feet 1 inch tall and weighs around 325 pounds. He was drafted by the Orlando Magic with the first overall pick in the 1992 NBA draft.\n",
      "\n",
      "Throughout his illustrious career, Shaq won numerous accolades, including:\n",
      "\n",
      "* **Four NBA championships**: Three with the Los Angeles Lakers (2000-2002) and one with the Miami Heat (2006)\n",
      "* **Three NBA Finals MVPs**: Two with the Lakers (2000, 2002) and one with the Heat (2006)\n",
      "* **15 All-Star Game appearances**\n",
      "* **11 All-NBA selections**\n",
      "* **Two Olympic gold medals**: As part of the United States men's national team in 1996 and 2000\n",
      "\n",
      "Shaq's dominance on the court was characterized by his incredible size, strength, and athleticism. He was a force to be reckoned with, averaging over 23 points and 10 rebounds per game throughout his career.\n",
      "\n",
      "Off the court, Shaq has been just as successful, becoming a popular entertainer and entrepreneur. He has appeared in various films and television shows, such as \"Kazaam\" (1996), \"Steel\" (1997), and \"The Simpsons\" (2004). He also co-starred in the reality TV show \"Shaq Vs.\" (2009-2010).\n",
      "\n",
      "After retiring from basketball in 2011, Shaq went on to become a sports analyst and commentator, working for networks like TNT and ESPN. Today, he remains involved in various business ventures and philanthropic efforts, using his platform to support education, healthcare, and social justice initiatives.\n",
      "\n",
      "In summary, Shaquille O'Neal is a legendary basketball player, actor, and entrepreneur who left an indelible mark on the world of sports and entertainment.<|eot_id|>**Lebron James: A Basketball Superstar**\n",
      "\n",
      "Lebron James is an American professional basketball player who has dominated the sport for over two decades. Born on December 30, 1984, in Akron, Ohio, he is widely regarded as one of the greatest players in NBA history.\n",
      "\n",
      "Here are some impressive facts about Lebron:\n",
      "\n",
      "### Early Life and Career\n",
      "\n",
      "* Grew up in poverty-stricken neighborhoods in Akron\n",
      "* Discovered his passion for basketball at age 12\n",
      "* Led St. Vincent-St. Mary High School to three state championships\n",
      "\n",
      "### Professional Career\n",
      "\n",
      "* Drafted by the Cleveland Cavaliers (2003)\n",
      "* Won four NBA championships (2012, 2013, 2016, and 2020) with the Miami Heat, Los Angeles Lakers, and Golden State Warriors\n",
      "* Four-time NBA Most Valuable Player (MVP)\n",
      "\n",
      "### Achievements\n",
      "\n",
      "* Two-time Olympic gold medalist (2008, 2012)\n",
      "* Three-time NBA Finals MVP\n",
      "* Fifteen-time All-Star selection\n",
      "* Holds numerous records, including most points scored in a single season (2,493)\n",
      "\n",
      "### Off-Court Ventures\n",
      "\n",
      "* Philanthropic efforts through the LeBron James Family Foundation, focusing on education, healthcare, and youth development\n",
      "* Co-owner of the Liverpool FC soccer team\n",
      "* Actor and producer, appearing in films like \"Trainwreck\" and TV shows like \"The Shop\"\n",
      "\n",
      "Throughout his career, Lebron has been known for his incredible athleticism, versatility, and leadership skills. He continues to inspire fans worldwide with his dedication to excellence both on and off the court.<|eot_id|>**Steph Curry: The Shooting Star of the NBA**\n",
      "\n",
      "Stephen \"Steph\" Curry III is an American professional basketball player who plays for the Golden State Warriors of the National Basketball Association (NBA). He is widely regarded as one of the greatest shooters in NBA history.\n",
      "\n",
      "Born on March 14, 1988, in Akron, Ohio, Curry grew up playing basketball alongside his father, Dell Curry, who was also an NBA player. He played college basketball at Davidson College before being drafted by the Warriors with the seventh overall pick in the 2009 NBA draft.\n",
      "\n",
      "Curry's impressive shooting skills have earned him numerous accolades, including:\n",
      "\n",
      "* **Three-time NBA champion**: Curry has won three NBA championships (2015, 2017, and 2018) with the Warriors.\n",
      "* **Two-time NBA MVP**: He was named the NBA Most Valuable Player twice (2015 and 2016).\n",
      "* **Five-time NBA All-Star**: Curry has been selected to five NBA All-Star Games.\n",
      "* **Record-breaking shooter**: He holds multiple records, including most three-pointers made in a single season (286), most consecutive games with a three-pointer (128), and highest career three-point percentage (.434).\n",
      "\n",
      "Curry's incredible shooting ability has revolutionized the way teams approach offense in the modern game. His signature shot, the \"Splash Brothers\" three-pointer, has become a staple of Warriors' basketball.\n",
      "\n",
      "Off the court, Curry is known for his philanthropic efforts, particularly through the Stephen & Ayesha Curry Foundation, which focuses on education, family, and community development initiatives.\n",
      "\n",
      "In summary, Steph Curry is a phenomenal basketball player who has redefined the art of shooting in the NBA, earning him widespread recognition and admiration from fans worldwide.<|eot_id|>**Kevin Durant**\n",
      "\n",
      "Kevin Wayne Durant is an American professional basketball player who plays for the Brooklyn Nets of the National Basketball Association (NBA). He is a 6'9\" small forward/shooting guard from Suitland, Maryland.\n",
      "\n",
      "Durant was drafted by the Seattle SuperSonics (now Oklahoma City Thunder) with the second overall pick in the 2007 NBA draft. Throughout his career, he has played for three teams: the Thunder (2007-2016), Golden State Warriors (2016-2019), and Brooklyn Nets (2019-present).\n",
      "\n",
      "Known for his incredible athleticism, shooting range, and versatility on the court, Durant has earned numerous accolades, including:\n",
      "\n",
      "* **2x NBA Champion**: Won back-to-back championships with the Warriors in 2017 and 2018.\n",
      "* **4x NBA Scoring Champion**: Led the league in scoring four times (2010, 2011, 2012, and 2013).\n",
      "* **11x NBA All-Star**: Selected to represent the Western Conference at the annual all-star game.\n",
      "* **5x All-NBA First Team**: Named to the first team five times (2010, 2011, 2012, 2013, and 2014).\n",
      "\n",
      "Off the court, Durant is known for his philanthropic efforts, particularly through the Kevin Durant Charity Foundation, which focuses on supporting education, family, and youth development initiatives.\n",
      "\n",
      "What would you like to know more about regarding Kevin Durant or his basketball career?<|eot_id|>RESULT 2\n",
      "{}\n",
      "END RESULT 2\n",
      "\n",
      "\n",
      "FINAL TOOLCHAIN STATE\n",
      "{\n",
      "    \"title\": \"Chat\",\n",
      "    \"chat_history\": [],\n",
      "    \"question_list_iterated\": [],\n",
      "    \"iterable_output\": [\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"**Magic Johnson**\\n-----------------\\n\\nEarvin \\\"Magic\\\" Johnson Jr. is a former American professional basketball player who played his entire 13-year career in the National Basketball Association (NBA) with the Los Angeles Lakers. He is widely considered one of the greatest point guards of all time.\\n\\nBorn on August 14, 1959, in Lansing, Michigan, Johnson was a dominant force on the court, known for his exceptional passing ability, speed, and agility. He led the Lakers to five NBA championships (1980, 1982, 1983, 1985, and 1988), three NBA MVP awards, and was named to the All-NBA First Team nine times.\\n\\nJohnson's impressive career statistics include:\\n\\n* Points: 17,707\\n* Assists: 10,141\\n* Steals: 1,944\\n* Rebounds: 6,244\\n\\nIn addition to his on-court achievements, Johnson has been recognized for his philanthropic work, particularly in the area of HIV/AIDS awareness and research. In 1991, he announced that he had contracted HIV, which sparked widespread media attention and helped raise public awareness about the disease.\\n\\nAfter retiring from basketball, Johnson went on to become a successful businessman and entrepreneur, founding several companies, including Magic Johnson Enterprises, which focuses on various ventures such as restaurants, movie theaters, and real estate development.\\n\\nToday, Johnson remains an influential figure in the sports world, serving as an executive vice president of the Los Angeles Lakers and continuing to be involved in various charitable initiatives.<|eot_id|>\"\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"**Michael Jordan**: The G.O.A.T (Greatest of All Time) in Basketball!\\n\\nMichael Jeffrey Jordan is an American former professional basketball player and entrepreneur who is widely regarded as one of the greatest basketball players of all time. He played 15 seasons in the National Basketball Association (NBA), primarily with the Chicago Bulls.\\n\\nBorn on February 17, 1963, in Fort Greene, Brooklyn, New York, Jordan rose to fame during his college years at the University of North Carolina, where he won the NCAA Championship in 1982. His impressive performance earned him the Naismith College Player of the Year award.\\n\\nIn 1984, Jordan was drafted by the Chicago Bulls and went on to win six NBA championships, five MVP awards, and six Finals MVP awards. He also won two Olympic gold medals as a member of the United States men's national team.\\n\\nJordan's incredible achievements include:\\n\\n* **Unstoppable scorer**: Averaged 30.12 points per game throughout his career.\\n* **Defensive wizard**: Won ten All-Defensive First Team selections.\\n* **Clutch performer**: Known for his ability to perform under pressure, earning the nickname \\\"Air Jordan.\\\"\\n* **Business mogul**: Founded the Jordan Brand, which has become a global sports apparel powerhouse.\\n\\nAfter retiring from basketball twice, Jordan returned to the court briefly before finally hanging up his sneakers in 2003. Today, he remains involved in various business ventures, including ownership of the Charlotte Hornets (formerly the Bobcats).\\n\\nThe \\\"GOAT\\\" debate continues among fans and analysts, but there's no denying Michael Jordan's impact on the sport of basketball and popular culture.<|eot_id|>\"\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"**Kobe Bryant (1978-2020)** was an American professional basketball player who played his entire 20-year career in the National Basketball Association (NBA) with the Los Angeles Lakers.\\n\\nBorn on August 23, 1978, in Philadelphia, Pennsylvania, Bryant began playing basketball at a young age and quickly emerged as one of the most talented players in the world. He won numerous awards and accolades throughout his career, including:\\n\\n* **5 NBA championships**: In 2000, 2001, 2002, 2009, and 2010\\n* **2 NBA Finals MVPs**: In 2002 and 2009\\n* **18 All-Star Game appearances**\\n* **15 All-NBA Team selections**\\n\\nBryant was known for his incredible work ethic, clutch shooting, and competitive drive. He was nicknamed \\\"Mamba\\\" due to his quick movements on the court, reminiscent of a snake striking its prey.\\n\\nOff the court, Bryant was a devoted husband and father of four daughters. He was also a successful entrepreneur, investing in various ventures such as film production companies and sports drink brands.\\n\\nTragically, Kobe Bryant's life was cut short when he died in a helicopter crash on January 26, 2020, along with eight other passengers, including his daughter Gianna. His legacy continues to inspire fans around the world, and he remains one of the greatest basketball players of all time.\\n\\nHere's a simple equation that represents Kobe's impressive scoring average: $$\\\\frac{25}{36} = \\\\boxed{\\\\text{30.4 points per game}}$$<|eot_id|>\"\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"**Shaquille O'Neal: The Dominant Center**\\n\\nShaquille Rashaun O'Neal, commonly known as Shaq, is a retired American professional basketball player who played in the National Basketball Association (NBA) from 1992 to 2011.\\n\\nBorn on March 6, 1972, in Newark, New Jersey, Shaq stands at an impressive 7 feet 1 inch tall and weighs around 325 pounds. He was drafted by the Orlando Magic with the first overall pick in the 1992 NBA draft.\\n\\nThroughout his illustrious career, Shaq won numerous accolades, including:\\n\\n* **Four NBA championships**: Three with the Los Angeles Lakers (2000-2002) and one with the Miami Heat (2006)\\n* **Three NBA Finals MVPs**: Two with the Lakers (2000, 2002) and one with the Heat (2006)\\n* **15 All-Star Game appearances**\\n* **11 All-NBA selections**\\n* **Two Olympic gold medals**: As part of the United States men's national team in 1996 and 2000\\n\\nShaq's dominance on the court was characterized by his incredible size, strength, and athleticism. He was a force to be reckoned with, averaging over 23 points and 10 rebounds per game throughout his career.\\n\\nOff the court, Shaq has been just as successful, becoming a popular entertainer and entrepreneur. He has appeared in various films and television shows, such as \\\"Kazaam\\\" (1996), \\\"Steel\\\" (1997), and \\\"The Simpsons\\\" (2004). He also co-starred in the reality TV show \\\"Shaq Vs.\\\" (2009-2010).\\n\\nAfter retiring from basketball in 2011, Shaq went on to become a sports analyst and commentator, working for networks like TNT and ESPN. Today, he remains involved in various business ventures and philanthropic efforts, using his platform to support education, healthcare, and social justice initiatives.\\n\\nIn summary, Shaquille O'Neal is a legendary basketball player, actor, and entrepreneur who left an indelible mark on the world of sports and entertainment.<|eot_id|>\"\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"**Lebron James: A Basketball Superstar**\\n\\nLebron James is an American professional basketball player who has dominated the sport for over two decades. Born on December 30, 1984, in Akron, Ohio, he is widely regarded as one of the greatest players in NBA history.\\n\\nHere are some impressive facts about Lebron:\\n\\n### Early Life and Career\\n\\n* Grew up in poverty-stricken neighborhoods in Akron\\n* Discovered his passion for basketball at age 12\\n* Led St. Vincent-St. Mary High School to three state championships\\n\\n### Professional Career\\n\\n* Drafted by the Cleveland Cavaliers (2003)\\n* Won four NBA championships (2012, 2013, 2016, and 2020) with the Miami Heat, Los Angeles Lakers, and Golden State Warriors\\n* Four-time NBA Most Valuable Player (MVP)\\n\\n### Achievements\\n\\n* Two-time Olympic gold medalist (2008, 2012)\\n* Three-time NBA Finals MVP\\n* Fifteen-time All-Star selection\\n* Holds numerous records, including most points scored in a single season (2,493)\\n\\n### Off-Court Ventures\\n\\n* Philanthropic efforts through the LeBron James Family Foundation, focusing on education, healthcare, and youth development\\n* Co-owner of the Liverpool FC soccer team\\n* Actor and producer, appearing in films like \\\"Trainwreck\\\" and TV shows like \\\"The Shop\\\"\\n\\nThroughout his career, Lebron has been known for his incredible athleticism, versatility, and leadership skills. He continues to inspire fans worldwide with his dedication to excellence both on and off the court.<|eot_id|>\"\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"**Steph Curry: The Shooting Star of the NBA**\\n\\nStephen \\\"Steph\\\" Curry III is an American professional basketball player who plays for the Golden State Warriors of the National Basketball Association (NBA). He is widely regarded as one of the greatest shooters in NBA history.\\n\\nBorn on March 14, 1988, in Akron, Ohio, Curry grew up playing basketball alongside his father, Dell Curry, who was also an NBA player. He played college basketball at Davidson College before being drafted by the Warriors with the seventh overall pick in the 2009 NBA draft.\\n\\nCurry's impressive shooting skills have earned him numerous accolades, including:\\n\\n* **Three-time NBA champion**: Curry has won three NBA championships (2015, 2017, and 2018) with the Warriors.\\n* **Two-time NBA MVP**: He was named the NBA Most Valuable Player twice (2015 and 2016).\\n* **Five-time NBA All-Star**: Curry has been selected to five NBA All-Star Games.\\n* **Record-breaking shooter**: He holds multiple records, including most three-pointers made in a single season (286), most consecutive games with a three-pointer (128), and highest career three-point percentage (.434).\\n\\nCurry's incredible shooting ability has revolutionized the way teams approach offense in the modern game. His signature shot, the \\\"Splash Brothers\\\" three-pointer, has become a staple of Warriors' basketball.\\n\\nOff the court, Curry is known for his philanthropic efforts, particularly through the Stephen & Ayesha Curry Foundation, which focuses on education, family, and community development initiatives.\\n\\nIn summary, Steph Curry is a phenomenal basketball player who has redefined the art of shooting in the NBA, earning him widespread recognition and admiration from fans worldwide.<|eot_id|>\"\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"**Kevin Durant**\\n\\nKevin Wayne Durant is an American professional basketball player who plays for the Brooklyn Nets of the National Basketball Association (NBA). He is a 6'9\\\" small forward/shooting guard from Suitland, Maryland.\\n\\nDurant was drafted by the Seattle SuperSonics (now Oklahoma City Thunder) with the second overall pick in the 2007 NBA draft. Throughout his career, he has played for three teams: the Thunder (2007-2016), Golden State Warriors (2016-2019), and Brooklyn Nets (2019-present).\\n\\nKnown for his incredible athleticism, shooting range, and versatility on the court, Durant has earned numerous accolades, including:\\n\\n* **2x NBA Champion**: Won back-to-back championships with the Warriors in 2017 and 2018.\\n* **4x NBA Scoring Champion**: Led the league in scoring four times (2010, 2011, 2012, and 2013).\\n* **11x NBA All-Star**: Selected to represent the Western Conference at the annual all-star game.\\n* **5x All-NBA First Team**: Named to the first team five times (2010, 2011, 2012, 2013, and 2014).\\n\\nOff the court, Durant is known for his philanthropic efforts, particularly through the Kevin Durant Charity Foundation, which focuses on supporting education, family, and youth development initiatives.\\n\\nWhat would you like to know more about regarding Kevin Durant or his basketball career?<|eot_id|>\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from websockets.sync.client import connect, Connection\n",
    "from copy import deepcopy\n",
    "import time\n",
    "from typing import List, Union, Any\n",
    "from toolchain_efficient_receiver import wait_for_command_finish\n",
    "\n",
    "model_params_static = {\n",
    "    # \"model_choice\": \"mistral-7b-instruct-v0.1\",\n",
    "    \"max_tokens\": 1000, \n",
    "    \"temperature\": 0.1, \n",
    "    \"top_p\": 0.1, \n",
    "    \"repetition_penalty\": 1.15,\n",
    "    # \"stop\": [\"<|im_end|>\"],\n",
    "    \"include_stop_str_in_output\": True\n",
    "}\n",
    "\n",
    "toolchain_id = \"iterable_test\"\n",
    "\n",
    "# Append, update, delete. In that order.\n",
    "WS_STATE_GLOBAL_2 = {}\n",
    "\n",
    "with connect(\"ws://localhost:8000/toolchain\") as websocket:\n",
    "    \n",
    "    input = {\"auth\": {\"api_key\": API_KEY_1}}\n",
    "    input.update({\n",
    "        \"command\" : \"toolchain/create\",\n",
    "        \"arguments\": {\n",
    "            \"toolchain_id\": toolchain_id\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    websocket.send(json.dumps(input))\n",
    "    print(\"\\n\\n\")\n",
    "   \n",
    "    result_1, WS_STATE_GLOBAL_2 = await wait_for_command_finish(websocket, WS_STATE_GLOBAL_2)\n",
    "    print(\"RESULT 1\")\n",
    "    print(json.dumps(result_1, indent=4))\n",
    "    \n",
    "    \n",
    "    session_id = result_1[\"toolchain_session_id\"]\n",
    "    \n",
    "    input = deepcopy(USER_ARGS_1)\n",
    "    input.update({\n",
    "        \"command\" : \"toolchain/event\",\n",
    "        \"arguments\": {\n",
    "            \"session_id\": session_id,\n",
    "            \"event_node_id\": \"user_question_event\",\n",
    "            \"event_parameters\": {\n",
    "                \"model_parameters\": model_params_static\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    websocket.send(json.dumps(input))\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    result_2, WS_STATE_GLOBAL_2 = await wait_for_command_finish(websocket, WS_STATE_GLOBAL_2)\n",
    "    print(\"RESULT 2\")\n",
    "    print(json.dumps(result_2, indent=4))\n",
    "    print(\"END RESULT 2\")\n",
    "    \n",
    "    print(\"\\n\\nFINAL TOOLCHAIN STATE\")\n",
    "    print(json.dumps(WS_STATE_GLOBAL_2, indent=4))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ Toolchain File Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "RESULT 1\n",
      "{\n",
      "    \"success\": true,\n",
      "    \"toolchain_session_id\": \"wBSjbrCa9D7WeRwolhBwj0FEmM\",\n",
      "    \"state\": {\n",
      "        \"title\": \"Chat\",\n",
      "        \"chat_history\": []\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"success\": true,\n",
      "    \"result\": {\n",
      "        \"hash_id\": \"2c2b2dcb90fa302d1dd2f6ff6312e911ef4a456c085c503351b07d6ab3e43e2a\",\n",
      "        \"title\": \"HNRS3035_08_22_2023_MLIntro.pdf\",\n",
      "        \"size\": \"481.7 KB\"\n",
      "    }\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "RESULT 2\n",
      "{\n",
      "    \"output\": \"   Introduction to AI/ML:  \\n Looking towards LLMs  \\n HNRS 3035 \\n Dr. James Ghawaly   \\n    What is itr  \\n \\u00b0 Data science: Stady of methods and mechanisms to extract knowledge  \\n from, develop new insights, and make predictions from unstructured or  \\n structured data.  \\n \\u00b0 Structured data. Defined common format (often stored in SQL, HDF5, etc.)  \\n \\u00b0 Unstructured data. Conglomeration of native formats within defined organization  \\n Structure.  \\n \\u00b0 Artificial Intelagence. Non-biological systems that \\u201cintelligently\\u201d perform  \\n predictions or other tasks.  \\n \\u00b0 Expert systems: Rule and logic-based systems developed manually by human  \\n experts.  \\n \\u00b0 Learning systems: Systems that learn from data (\\u201cmachine learning\\u201d)   \\n    What is it? Continued.  \\n \\u00a2 Machine learning (ML) # Artificial Intelligence (AI)  \\n \\u00a2 ML is a subset of AI, which overlaps with data science \\n \\u00a2 This course focuses specifically on ML  \\n \\u00b0 Deep learning 1s a subset of ML that \\n uses artificial neural networks (ANNs) \\n to perform representation learning on  \\n Expert \\n data. Systems  \\n * Representation learning, also called \\n feature learning, is any method that  \\n learns to recognize salient features  \\n without human input and quantify  \\n their zportance.  Deep  \\n Learning      \\n    What is It? Continued.  \\n     \\n Hand-crafted Learning  \\n Input image \\u2014\\u2014\\u2014\\u2014\\u2014\\u2014\\u2014-_ feature 9 9\\u2014\\u2014 = algorithm  \\n representation \\n Traditional pattern recognition  \\n e.g., SIFT, HOG  \\n hieararchical representation \\n low mid- high- Learning  \\n Input image \\u2014> level \\u2014> level \\u2014> level \\u2014>  algorithm  \\n features features features  \\n Deep learning  \\n o , Fl  \\n 2 <pa fz <a) BE Sas  Bind q  \\n    ; = \\n 1G amet  \\n = = \\u00bb. >)  \\n image soutce: https: //blog.kthais.com/representation-learning-the-core-of-machine-learning-e25fab0f3ac0   \\n    Artificial Neural Networks (ANNs)  \\n \\u00a2 ANNs are composed of one or mote layers of artificial functional units, also \\n referred to as neurons. \\n \\u00a2 Each neuron integrates information from one or more other units, applies a \\n nonlinear function to those inputs, and outputs the result.  \\n \\u00a2 Each neuron-to-neuron connection (synapse) scales the input signal by a  \\n tunable weight. \\n \\u00a2 Other types of layers are often embedded between neuronal layers for various  \\n purposes.  \\n Input Hidden \\n Layer Layers       Output  \\n Layer  \\n >: SS  KID <<  Zi PY ZA       \\n           \\n           \\n         @ WHO \\n SE OK  Vv, \\n f\\\\  \\n         \\n               \\n    Main \\u2018Types of Models  \\n \\u00b0 Regression: Models that acts as a function that predicts the value of a \\n variable given any number of independent variables, by learning the \\n relationship between said variables from data. \\n \\u00b0 Classification. Models that predict the categorical class label of data that \\n are presented. \\n \\u00b0 Dimensionality Reduction: Models that reduce the dimensionality of data \\n without losing much information. \\n \\u00b0 Clustering. Models that can cluster data points into distinct groups based \\n on similarities in the data  \\n Note: These are not exclusive definitions.   \\n    Types of Learning  \\n \\u00b0 Supervised Learning. uses labeled data to train the model \\n \\u00b0 Unsupervised learning tavolves training a model on unlabeled data with the \\n goal of finding inherent patterns, structures, or relationships within the \\n data \\n \\u00b0 Semi-supervised Learning 1s a learning paradigm that uses a combination of \\n labeled and unlabeled data for training. \\n \\u00b0 Sedf-supervised Learning 1s a machine learning approach where a model  \\n learns from the data itself by creating its own supervisory signal. A part \\n of the data 1s used to generate labels or targets, and the model learns to \\n predict these targets from the remaining data.  \\n \\u00b0 Kecnforcement Learning. Models trained to maximize receipt of reward  \\n sionals. Rewards are given for desirable behaviors/traits. Often used for \\n control problems.   \\n    ML Model Training  \\n \\u00a2 A deep learning model is trained to minimize a user-defined Joss function \\n using gradient descent through an algorithm called backpropagation \\n \\u00a2 The loss function 1s a measure that quantifies the difference between \\n predicted values generated by a ML model and the actual target values \\n \\u00a2 Backpropagation makes small iterative changes to the model\\u2019s parameters \\n to reduce the loss. \\n \\u00b0 Cross-Vatidation: Divide dataset into Repeat Uni \\n multiple subsets \\u2014  \\n \\u00a2 Training set: Used to adjust model weights \\n \\u00a2 Validation set: Used to assess performance \\n during training \\n \\u00b0 Testing set: Used to assess performance  \\n after training  >  \\n A .{ Target) \\u00b0  \\n Input Data | | Output  \\n : pa Me > y  \\n y \\u2019 Model \\n P MIL M Jy > L | reprocess iy ges Outpuy>\\u2014> bess  \\n A wy                    Dataset  \\n    \\n         \\n       -\\u2014Adjust Model Parameters\\u2014\\u2014  \\n Mme wwe ween ewe www eee we ewww ewww eww wwe we eww   \\n    Over/Underfitting  \\n \\u00b0 Types of error:  \\n \\u00b0 Bzas error: predictions are inaccurate on training  \\n data (and thus also on testing)  \\n \\u00b0 underfittine  \\n \\u00b0 Vanance error. predictions are very accurate on \\n training data but highly variable on testing  \\n \\u00b0 overfitting  \\n \\u00b0 Bias-variance tradeoff:  \\n \\u00a2 Overcomplicated models tend to perform well \\n on training data but poorly on testing data: high  \\n variance  \\n \\u00a2 Overly simple models tend to perform poorly \\n on both training and testing: high bias \\n \\u00a2 A balance must be found for a given task  Degree 15 \\n MSE = 1.82e+08(+/- 5.46e+08)     \\n \\u2014 Model \\n \\u2014\\u2014 True function \\n e Samples  \\n    \\n          \\n        \\n    \\n       | High Variance & \\n Overfit  \\n Xx  \\n Degree 1 Degree 4 \\n MSE = 4.08e-01(+/- 4.25e-01) MSE = 4.32e-02(+/- 7.08e-02)  \\n \\u2014 Model \\u2014 Model  \\n      \\n High Bias & \\n Underfit  \\u2014\\u2014 True function \\u2014\\u2014 True function \\n e@ Samples e Samples  \\n    Balanced  \\n           \\n x     \\n Xx  \\n image soutce: https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting html   \\n    Natural Language Processing  \\n \\u00b0 Natural Language Processing models aim to process, analyze, and derive  \\n meaning from human language data:  \\n \\u00b0 text classification  \\n \\u00a2 language generation  \\n * sentiment analysis \\n * conversation  \\n * machine translation  \\n \\u00b0 Large Language Models are deep learning models designed to understand  \\n and generate human laneuage, capable of learning patterns, context, and \\n semantics from vast amounts of text data.  \\n \\u00a2 Probabilistic word generation \\n * Recent advances enabled by \\u00e9vansformer architecture   \\n    LLM History  \\n \\u00b0 Recurrent Neural Networks (Rumelhart et. al., 1986): ANN architecture \\n comprising neuron models that maintain hidden memory state.  \\n \\u00a2 Short-term memory \\n \\u00a2 Impossible to parallelize & unstable training  \\n \\u00b0 Long Short-term Memory (Hochreiter et. al., 1997): More complicated RNN  \\n models with gates that modulate the flow of temporal information  \\n through the cell  \\n \\u00a2 Both short and long-term memory \\n \\u00a2 Impossible to parallelize & unstable training  \\n \\u00a2 Transformers. \\u201cAttention ts all you Need\\u201d (Vaswant, 2017)  \\n \\u00a2 Eliminates recurrence \\u2014 temporality encoded with position embeddings \\n \\u00a2 Attention-based \\n \\u00a2 Parallelizable   \\n    LLM Foundational Models  \\n Model Generative Pre-trained  \\n Transformer (GPT)  \\n         \\n       Designed by OpenAl  \\n G OpenAl  \\n Framework OpenAl  Large Language Model Meta AI  \\n (LLaMA)  \\n ozo \\\"  -a- YY  am .) < \\n 4 7 \\n =  \\n %       \\n Meta Al  \\n OO Meta  \\n HugeineFace *  \\n Ga Hugging Face  \\n * There are multiple frameworks on which LLaMA can be deployed, with HuggingFace  \\n being the most popular   \\n\"\n",
      "}\n",
      "END RESULT 2\n"
     ]
    }
   ],
   "source": [
    "from websockets.sync.client import connect, Connection\n",
    "from copy import deepcopy\n",
    "import time, json\n",
    "from typing import List, Union, Any\n",
    "from toolchain_efficient_receiver import wait_for_command_finish\n",
    "\n",
    "toolchain_id = \"test_file_upload\"\n",
    "\n",
    "# Append, update, delete. In that order.\n",
    "WS_STATE_GLOBAL_2 = {}\n",
    "\n",
    "websocket = connect(\"ws://localhost:8000/toolchain\")\n",
    "    \n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update({\n",
    "    \"command\" : \"toolchain/create\",\n",
    "    \"arguments\": {\n",
    "        \"toolchain_id\": toolchain_id\n",
    "    }\n",
    "})\n",
    "\n",
    "websocket.send(json.dumps(input))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "result_1, WS_STATE_GLOBAL_2 = await wait_for_command_finish(websocket, WS_STATE_GLOBAL_2)\n",
    "print(\"RESULT 1\")\n",
    "print(json.dumps(result_1, indent=4))\n",
    "\n",
    "toolchain_session_id = result_1[\"toolchain_session_id\"]\n",
    "\n",
    "import requests, json\n",
    "from urllib.parse import urlencode\n",
    "from copy import deepcopy\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update({\n",
    "    \"collection_hash_id\": toolchain_session_id,\n",
    "    \"collection_type\" : \"toolchain_session\"\n",
    "})\n",
    "\n",
    "encoded_params = urlencode({\"parameters\": json.dumps(input)})\n",
    "\n",
    "for i, path in enumerate([PDF_TO_UPLOAD_PATH]):\n",
    "    with open(path, 'rb') as f:\n",
    "        # Define the files parameter for the POST request\n",
    "        files = {'file': f}\n",
    "        input_json = json.dumps(input)\n",
    "        response = requests.post(\"http://localhost:8000/upload_document?\"+encoded_params, files=files)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        result = response.json()\n",
    "        f.close()\n",
    "\n",
    "        print(json.dumps(result, indent=4))\n",
    "        \n",
    "        document_hash_id = result[\"result\"][\"hash_id\"]\n",
    "\n",
    "\n",
    "input = deepcopy(USER_ARGS_1)\n",
    "input.update({\n",
    "    \"command\" : \"toolchain/event\",\n",
    "    \"arguments\": {\n",
    "        \"session_id\": toolchain_session_id,\n",
    "        \"event_node_id\": \"user_file_upload_event\",\n",
    "        \"event_parameters\": {\n",
    "            \"<<FILE>>\": document_hash_id\n",
    "        }\n",
    "    }\n",
    "})\n",
    "\n",
    "websocket.send(json.dumps(input))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "result_2, WS_STATE_GLOBAL_2 = await wait_for_command_finish(websocket, WS_STATE_GLOBAL_2)\n",
    "print(\"RESULT 2\")\n",
    "print(json.dumps(result_2, indent=4))\n",
    "print(\"END RESULT 2\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QL_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
